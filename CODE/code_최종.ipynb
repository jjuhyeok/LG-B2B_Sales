{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 영업 성공 여부 분류 경진대회 (본선)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "5d10b376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pycountry in ./.local/lib/python3.10/site-packages (23.12.11)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kmodes in ./.local/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./.local/lib/python3.10/site-packages (from kmodes) (1.23.5)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.10/site-packages (from kmodes) (1.3.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in ./.local/lib/python3.10/site-packages (from kmodes) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in ./.local/lib/python3.10/site-packages (from kmodes) (1.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.22.0->kmodes) (3.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: catboost in ./.local/lib/python3.10/site-packages (1.2.3)\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.10/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./.local/lib/python3.10/site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from catboost) (3.8.2)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in ./.local/lib/python3.10/site-packages (from catboost) (5.20.0)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.local/lib/python3.10/site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (4.50.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.local/lib/python3.10/site-packages (from plotly->catboost) (8.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pycountry\n",
    "!pip install kmodes\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "bb3498b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "62e976b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f98cc",
   "metadata": {},
   "source": [
    "### 데이터 셋 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "4c8ce273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 59299  / test : 21341\n",
      "중복 값 : 2234\n",
      "중복 제거 후 : 57065\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train.csv\") # 학습용 데이터\n",
    "df_test = pd.read_csv(\"submission.csv\") # 테스트 데이터(제출파일의 데이터)\n",
    "print('train :',len(df_train), ' / test :',len(df_test))\n",
    "print('중복 값 :',len(df_train[df_train.duplicated()]))\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "print('중복 제거 후 :',len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cbba2a",
   "metadata": {},
   "source": [
    "모든 컬럼 동일하지만 타겟 값이 다른 값 이상치 판단."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "cbf66b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 값 : 26\n",
      "중복 제거 후 : 57039\n"
     ]
    }
   ],
   "source": [
    "print('중복 값 :',len(df_train[df_train.drop(columns = 'is_converted').duplicated(keep=False)]))\n",
    "df_train = df_train.drop(df_train[df_train.drop(columns = 'is_converted').duplicated(keep=False)].index)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "print('중복 제거 후 :',len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5071242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_train.copy()\n",
    "df_test_raw = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d9a03d",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f2236f",
   "metadata": {},
   "source": [
    "# 2. EDA & Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbbdf5",
   "metadata": {},
   "source": [
    "* [1. bant_submit](#1.-bant_submit)\n",
    "* [2. customer_country](#2.-customer_country)\n",
    "* [3. business_unit](#3.-business_unit)\n",
    "* [4. com_reg_ver_win_rate](#4.-com_reg_ver_win_rate)\n",
    "* [5. customer_idx](#5.-customer_idx)\n",
    "* [6. customer_type](#6.-customer_type)\n",
    "* [7. enterprise](#7.-enterprise)\n",
    "* [8. historical_existing_cnt](#8.-historical_existing_cnt)\n",
    "* [9. id_strategic_ver](#9.-id_strategic_ver)\n",
    "* [10. it_strategic_ver](#10.-it_strategic_ver)\n",
    "* [11. idit_strategic_ver](#11.-idit_strategic_ver)\n",
    "* [12. customer_job](#12.-customer_job)\n",
    "* [13. lead_desc_length](#13.-lead_desc_length)\n",
    "* [14. inquiry_type](#14.-inquiry_type)\n",
    "* [15. product_category](#15.-product_category)\n",
    "* [16. product_subcategory](#16.-product_subcategory)\n",
    "* [17. product_modelname](#17.-product_modelname)\n",
    "* [18. customer_country.1](#18.-customer_country.1)\n",
    "* [19. customer_position](#19.-customer_position)\n",
    "* [20. response_corporate](#20.-response_corporate)\n",
    "* [21. expected_timeline](#21.-expected_timeline)\n",
    "* [22. ver_cus](#22.-ver_cus)\n",
    "* [23. ver_pro](#23.-ver_pro)\n",
    "* [24. ver_win_rate_x](#24.-ver_win_rate_x)\n",
    "* [25. ver_win_ratio_per_bu](#25.-ver_win_ratio_per_bu)\n",
    "* [26. business_area](#26.-business_area)\n",
    "* [27. business_subarea](#27.-business_subarea)\n",
    "* [28. lead_owner](#28.-lead_owner)\n",
    "* [29. is_converted](#29.-is_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf5ebac",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413e4a4",
   "metadata": {},
   "source": [
    "## ***1. bant_submit***\n",
    "MQL 구성 요소들 중 [1]Budget(예산), [2]Title(고객의 직책/직급), [3]Needs(요구사항), [4]Timeline(희망 납기일) 4가지 항목에 대해서 작성된 값의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e8808365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['bant_submit'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "71bd1c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bant_submit\n",
       "0.50    16739\n",
       "1.00    16592\n",
       "0.25    11694\n",
       "0.75    11507\n",
       "0.00      507\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['bant_submit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d134e0d",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecfc8ab",
   "metadata": {},
   "source": [
    "## ***2. customer_country***\n",
    "고객의 국적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453c4b6",
   "metadata": {},
   "source": [
    "결측값 대체 불가 -> 'unknown'으로 지정  \n",
    "type str로 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "79e74124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['customer_country'] = df_train['customer_country'].apply(lambda x: re.sub(r'\\s+', ' ', x) if isinstance(x, str) else x)\n",
    "df_test['customer_country'] = df_test['customer_country'].apply(lambda x: re.sub(r'\\s+', ' ', x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "7248a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['customer_country'] = df_train['customer_country'].apply(lambda x: re.sub(r'\\s*/\\s*', '/', x) if isinstance(x, str) else x)\n",
    "df_test['customer_country'] = df_test['customer_country'].apply(lambda x: re.sub(r'\\s*/\\s*', '/', x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2cff83",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f5bf9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['customer_country2'] = df_train['customer_country'].copy()\n",
    "df_test['customer_country2'] = df_test['customer_country'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4dfab890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "976"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_country'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "4cb36687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer_country NAN\n",
    "df_train['customer_country'] = df_train['customer_country'].fillna('Unknown')\n",
    "df_test['customer_country'] = df_test['customer_country'].fillna('Unknown')\n",
    "\n",
    "df_train['customer_country'] = df_train['customer_country'].astype(str)\n",
    "df_test['customer_country'] = df_test['customer_country'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3763cbc5",
   "metadata": {},
   "source": [
    "* Email 정리."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "31e835b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['customer_country'].str.contains('@', case=True, na=False)) & (df_train['customer_country'].str.contains('India', case=True, na=False)),'customer_country'] = 'India'\n",
    "df_train.loc[(df_train['customer_country'].str.contains('@', case=True, na=False)) & (df_train['customer_country'].str.contains('Brazil', case=True, na=False)),'customer_country'] = 'Brazil'\n",
    "df_train.loc[(df_train['customer_country'].str.contains('@', case=True, na=False)) & (df_train['customer_country'].str.contains('Chile', case=True, na=False)),'customer_country'] = 'Chile'\n",
    "df_train.loc[(df_train['customer_country'].str.contains('@', case=True, na=False)) & (df_train['customer_country'].str.contains('Colombia', case=True, na=False)),'customer_country'] = 'Colombia'\n",
    "df_train.loc[(df_train['customer_country'].str.contains('@', case=True, na=False)) & (df_train['customer_country'].str.contains('Italy', case=True, na=False)),'customer_country'] = 'Italy'\n",
    "df_train.loc[(df_train['customer_country'].str.contains('@', case=True, na=False)) & (df_train['customer_country'].str.contains('Mexico', case=True, na=False)),'customer_country'] = 'Mexico'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "d6ca275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[(df_test['customer_country'].str.contains('@', case=True, na=False)) & (df_test['customer_country'].str.contains('India', case=True, na=False)),'customer_country'] = 'India'\n",
    "df_test.loc[(df_test['customer_country'].str.contains('@', case=True, na=False)) & (df_test['customer_country'].str.contains('Brazil', case=True, na=False)),'customer_country'] = 'Brazil'\n",
    "df_test.loc[(df_test['customer_country'].str.contains('@', case=True, na=False)) & (df_test['customer_country'].str.contains('Chile', case=True, na=False)),'customer_country'] = 'Chile'\n",
    "df_test.loc[(df_test['customer_country'].str.contains('@', case=True, na=False)) & (df_test['customer_country'].str.contains('Colombia', case=True, na=False)),'customer_country'] = 'Colombia'\n",
    "df_test.loc[(df_test['customer_country'].str.contains('@', case=True, na=False)) & (df_test['customer_country'].str.contains('Italy', case=True, na=False)),'customer_country'] = 'Italy'\n",
    "df_test.loc[(df_test['customer_country'].str.contains('@', case=True, na=False)) & (df_test['customer_country'].str.contains('Mexico', case=True, na=False)),'customer_country'] = 'Mexico'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ece3d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['customer_country'].str.contains('@', case=True, na=False), 'customer_country'] = 'Egypt'\n",
    "df_test.loc[df_test['customer_country'].str.contains('@', case=True, na=False), 'customer_country'] = 'Egypt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f16e71",
   "metadata": {},
   "source": [
    "* 국가명으로 정리."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "e34de28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "# 모든 국가 정보 얻기\n",
    "all_countries = list(pycountry.countries)\n",
    "country_names_lst = [country.name for country in all_countries]\n",
    "\n",
    "country_names_lst = [name.replace('Türkiye', 'Turkey') for name in country_names_lst]\n",
    "country_names_lst = [name.replace('Viet Nam', 'VietNam') for name in country_names_lst]\n",
    "country_names_lst = [name.replace('Tanzania, United Republic of', 'Tanzania') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Korea, Republic of\", 'Korea') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Czechia\", 'Czech') for name in country_names_lst]\n",
    "country_names_lst = [name.replace('Bolivia, Plurinational State of', 'Bolivia') for name in country_names_lst]\n",
    "# virgin island 는 통일\n",
    "country_names_lst.remove('Virgin Islands, British')\n",
    "country_names_lst.remove('Virgin Islands, U.S.')\n",
    "country_names_lst.remove('Niger')\n",
    "country_names_lst.remove('Dominican Republic')\n",
    "country_names_lst.append('Virgin Islands')\n",
    "###\n",
    "country_names_lst = [name.replace(\"Venezuela, Bolivarian Republic of\", 'Venezuela') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Iran, Islamic Republic of\", 'Iran') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Taiwan, Province of China\", 'Taiwan') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Russian Federation\", 'Russia') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Côte d'Ivoire\", 'Ivory Coast') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"North Macedonia\", 'Macedonia') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Brunei Darussalam\", 'Brunei') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Palestine, State of\", 'Palestine') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Antigua and Barbuda\", 'Antigua') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Syrian Arab Republic\", 'Syria') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Lao People's Democratic Republic\", 'Laos') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Saint Kitts and Nevis\", 'Saint Kitts') for name in country_names_lst]\n",
    "country_names_lst = [name.replace(\"Saint Martin (French part)\", 'Saint Martin') for name in country_names_lst]\n",
    "country_names_lst.append('Kosovo')\n",
    "country_names_lst.append('Swaziland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "914c480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:09<00:00, 27.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for country_name in tqdm(country_names_lst):\n",
    "    condition = df_train['customer_country'].str.contains(country_name, case=False, na=False)\n",
    "    df_train.loc[condition, 'customer_country'] = country_name\n",
    "\n",
    "    condition = df_test['customer_country'].str.contains(country_name, case=False, na=False)\n",
    "    df_test.loc[condition, 'customer_country'] = country_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617e7e2",
   "metadata": {},
   "source": [
    "### *주요도시 기반 cleansing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0b694672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튀르키예\n",
    "df_train.loc[df_train['customer_country'].str.contains('Türkiye', case=False, na=False), 'customer_country'] = 'Turkey'\n",
    "df_test.loc[df_test['customer_country'].str.contains('Türkiye', case=False, na=False), 'customer_country'] = 'Turkey'\n",
    "\n",
    "# 미국 EE. UU. 로 표기\n",
    "df_train.loc[df_train['customer_country'].str.contains('EE. UU.', case=True, na=False), 'customer_country'] = 'United States'\n",
    "df_test.loc[df_test['customer_country'].str.contains('EE. UU.', case=True, na=False), 'customer_country'] = 'United States'\n",
    "\n",
    "# 발렌수엘라 (필리핀 섬)\n",
    "df_train.loc[df_train['customer_country'].str.contains('Valenzuela', case=True, na=False), 'customer_country'] = 'Philippines'\n",
    "df_test.loc[df_test['customer_country'].str.contains('Valenzuela', case=True, na=False), 'customer_country'] = 'Philippines'\n",
    "\n",
    "# 중국 상해\n",
    "df_train.loc[df_train['customer_country'].str.contains('上海', case=True, na=False), 'customer_country'] = 'China'\n",
    "df_test.loc[df_test['customer_country'].str.contains('上海', case=True, na=False), 'customer_country'] = 'China'\n",
    "\n",
    "# 아랍에미리트\n",
    "df_train.loc[df_train['customer_country'].str.contains('U\\.A\\.E', case=True, na=False), 'customer_country'] = 'United Arab Emirates'\n",
    "df_test.loc[df_test['customer_country'].str.contains('U\\.A\\.E', case=True, na=False), 'customer_country'] = 'United Arab Emirates'\n",
    "\n",
    "#코트디부아르\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Cote d'Ivoire\", case=True, na=False), 'customer_country'] = 'Ivory Coast'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Cote d'Ivoire\", case=True, na=False), 'customer_country'] = 'Ivory Coast'\n",
    "\n",
    "#세인트루시아\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Soufriere\", case=True, na=False), 'customer_country'] = 'Saint Lucia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Soufriere\", case=True, na=False), 'customer_country'] = 'Saint Lucia'\n",
    "\n",
    "# 대만\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Taipei\", case=True, na=False), 'customer_country'] = 'Taiwan'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Taipei\", case=True, na=False), 'customer_country'] = 'Taiwan'\n",
    "\n",
    "#세인트키츠\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"St Kitts\", case=True, na=False), 'customer_country'] = 'Saint Kitts'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"St Kitts\", case=True, na=False), 'customer_country'] = 'Saint Kitts'\n",
    "\n",
    "#세인트 마르턴\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"St Maarten\", case=True, na=False), 'customer_country'] = 'Saint Martin'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"St Maarten\", case=True, na=False), 'customer_country'] = 'Saint Martin'\n",
    "\n",
    "# Australia\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Daydream Island\", case=True, na=False), 'customer_country'] = 'Australia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Daydream Island\", case=True, na=False), 'customer_country'] = 'Australia'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Kelvin Grove\", case=True, na=False), 'customer_country'] = 'Australia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Kelvin Grove\", case=True, na=False), 'customer_country'] = 'Australia'\n",
    "\n",
    "# Fiji\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Suva\", case=True, na=False), 'customer_country'] = 'Fiji'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Suva\", case=True, na=False), 'customer_country'] = 'Fiji'\n",
    "\n",
    "# Hungary\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Budapest\", case=True, na=False), 'customer_country'] = 'Hungary'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Budapest\", case=True, na=False), 'customer_country'] = 'Hungary'\n",
    "\n",
    "# Armenia\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"AVAN\", case=True, na=False), 'customer_country'] = 'Armenia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"AVAN\", case=True, na=False), 'customer_country'] = 'Armenia'\n",
    "\n",
    "# Singapore\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Kallang Place\", case=True, na=False), 'customer_country'] = 'Singapore'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Kallang Place\", case=True, na=False), 'customer_country'] = 'Singapore'\n",
    "\n",
    "# Jojia\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"rbilisi\", case=True, na=False), 'customer_country'] = 'Jojia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"rbilisi\", case=True, na=False), 'customer_country'] = 'Jojia'\n",
    "\n",
    "# VietNam\n",
    "df_train.loc[df_train['customer_country'].str.contains('Ha Noi', case=True, na=False), 'customer_country'] = 'VietNam'\n",
    "df_test.loc[df_test['customer_country'].str.contains('Ha Noi', case=True, na=False), 'customer_country'] = 'VietNam'\n",
    "\n",
    "# Colombia\n",
    "df_train.loc[df_train['customer_country'].str.contains('Cartagena', case=True, na=False), 'customer_country'] = 'Colombia'\n",
    "df_test.loc[df_test['customer_country'].str.contains('Cartagena', case=True, na=False), 'customer_country'] = 'Colombia'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains('Bucaramanga', case=True, na=False), 'customer_country'] = 'Colombia'\n",
    "df_test.loc[df_test['customer_country'].str.contains('Bucaramanga', case=True, na=False), 'customer_country'] = 'Colombia'\n",
    "\n",
    "# Greece\n",
    "df_train.loc[df_train['customer_country'].str.contains('Θέση', case=True, na=False), 'customer_country'] = 'Greece'\n",
    "df_test.loc[df_test['customer_country'].str.contains('Θέση', case=True, na=False), 'customer_country'] = 'Greece'\n",
    "\n",
    "# UAE\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Dubai\", case=True, na=False), 'customer_country'] = 'United Arab Emirates'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Dubai\", case=True, na=False), 'customer_country'] = 'United Arab Emirates'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"DUBAI\", case=True, na=False), 'customer_country'] = 'United Arab Emirates'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"DUBAI\", case=True, na=False), 'customer_country'] = 'United Arab Emirates'\n",
    "\n",
    "# Namibia\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Windhoek\", case=True, na=False), 'customer_country'] = 'Namibia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Windhoek\", case=True, na=False), 'customer_country'] = 'Namibia'\n",
    "\n",
    "# China\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"shenzhen\", case=True, na=False), 'customer_country'] = 'China'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"shenzhen\", case=True, na=False), 'customer_country'] = 'China'\n",
    "\n",
    "# Japan\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Tokyo\", case=True, na=False), 'customer_country'] = 'Japan'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Tokyo\", case=True, na=False), 'customer_country'] = 'Japan'\n",
    "\n",
    "# Switzerland\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Bergdietikon\", case=True, na=False), 'customer_country'] = 'Switzerland'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Bergdietikon\", case=True, na=False), 'customer_country'] = 'Switzerland'\n",
    "\n",
    "# South Africa\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Midrand\", case=True, na=False), 'customer_country'] = 'South Africa'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Midrand\", case=True, na=False), 'customer_country'] = 'South Africa'\n",
    "\n",
    "# Egypt\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Mohandessein\", case=True, na=False), 'customer_country'] = 'Egypt'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Mohandessein\", case=True, na=False), 'customer_country'] = 'Egypt'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Cairo\", case=True, na=False), 'customer_country'] = 'Egypt'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Cairo\", case=True, na=False), 'customer_country'] = 'Egypt'\n",
    "\n",
    "# Indonesia\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Jakarta\", case=True, na=False), 'customer_country'] = 'Indonesia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Jakarta\", case=True, na=False), 'customer_country'] = 'Indonesia'\n",
    "\n",
    "# Nigeria\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Ikoyi\", case=True, na=False), 'customer_country'] = 'Nigeria'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Ikoyi\", case=True, na=False), 'customer_country'] = 'Nigeria'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Abuja\", case=True, na=False), 'customer_country'] = 'Nigeria'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Abuja\", case=True, na=False), 'customer_country'] = 'Nigeria'\n",
    "\n",
    "# Luxembourg\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Esch-sur-Alzette\", case=True, na=False), 'customer_country'] = 'Luxembourg'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Esch-sur-Alzette\", case=True, na=False), 'customer_country'] = 'Luxembourg'\n",
    "\n",
    "# Dominica\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Arroyo Hondo Viejo\", case=True, na=False), 'customer_country'] = 'Dominica'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Arroyo Hondo Viejo\", case=True, na=False), 'customer_country'] = 'Dominica'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Santo Domingo\", case=True, na=False), 'customer_country'] = 'Dominica'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Santo Domingo\", case=True, na=False), 'customer_country'] = 'Dominica'\n",
    "\n",
    "# Poland\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Olsztyn\", case=True, na=False), 'customer_country'] = 'Poland'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Olsztyn\", case=True, na=False), 'customer_country'] = 'Poland'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Kielce\", case=True, na=False), 'customer_country'] = 'Poland'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Kielce\", case=True, na=False), 'customer_country'] = 'Poland'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Stalowa Wola\", case=True, na=False), 'customer_country'] = 'Poland'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Stalowa Wola\", case=True, na=False), 'customer_country'] = 'Poland'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Warszawska\", case=True, na=False), 'customer_country'] = 'Poland'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Warszawska\", case=True, na=False), 'customer_country'] = 'Poland'\n",
    "\n",
    "# Norway\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Oslo\", case=True, na=False), 'customer_country'] = 'Norway'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Oslo\", case=True, na=False), 'customer_country'] = 'Norway'\n",
    "\n",
    "# Jamaica\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Portmore\", case=True, na=False), 'customer_country'] = 'Jamaica'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Portmore\", case=True, na=False), 'customer_country'] = 'Jamaica'\n",
    "\n",
    "# Mongolia\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Ulaanbaatar\", case=True, na=False), 'customer_country'] = 'Mongolia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Ulaanbaatar\", case=True, na=False), 'customer_country'] = 'Mongolia'\n",
    "\n",
    "# Germany\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Berlin\", case=True, na=False), 'customer_country'] = 'Germany'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Berlin\", case=True, na=False), 'customer_country'] = 'Germany'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Hamburg\", case=True, na=False), 'customer_country'] = 'Germany'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Hamburg\", case=True, na=False), 'customer_country'] = 'Germany'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Herdwangen-Schönach\", case=True, na=False), 'customer_country'] = 'Germany'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Herdwangen-Schönach\", case=True, na=False), 'customer_country'] = 'Germany'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Weikersheim\", case=True, na=False), 'customer_country'] = 'Germany'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Weikersheim\", case=True, na=False), 'customer_country'] = 'Germany'\n",
    "\n",
    "# Bahamas\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Nassau\", case=True, na=False), 'customer_country'] = 'Bahamas'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Nassau\", case=True, na=False), 'customer_country'] = 'Bahamas'\n",
    "\n",
    "# Uzbekistan\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Tashkent\", case=True, na=False), 'customer_country'] = 'Uzbekistan'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Tashkent\", case=True, na=False), 'customer_country'] = 'Uzbekistan'\n",
    "\n",
    "# Qatar\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Almirqab\", case=True, na=False), 'customer_country'] = 'Qatar'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Almirqab\", case=True, na=False), 'customer_country'] = 'Qatar'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Doha\", case=True, na=False), 'customer_country'] = 'Qatar'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Doha\", case=True, na=False), 'customer_country'] = 'Qatar'\n",
    "\n",
    "# Czech\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Králův Dvůr Levín\", case=True, na=False), 'customer_country'] = 'Czech'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Králův Dvůr Levín\", case=True, na=False), 'customer_country'] = 'Czech'\n",
    "\n",
    "# Thailand\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Buengkum\", case=True, na=False), 'customer_country'] = 'Thailand'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Buengkum\", case=True, na=False), 'customer_country'] = 'Thailand'\n",
    "\n",
    "# Iceland\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Gardabaer\", case=True, na=False), 'customer_country'] = 'Iceland'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Gardabaer\", case=True, na=False), 'customer_country'] = 'Iceland'\n",
    "\n",
    "# Malaysia\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Shah Alam\", case=True, na=False), 'customer_country'] = 'Malaysia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Shah Alam\", case=True, na=False), 'customer_country'] = 'Malaysia'\n",
    "\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Kuala Lumpur\", case=True, na=False), 'customer_country'] = 'Malaysia'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Kuala Lumpur\", case=True, na=False), 'customer_country'] = 'Malaysia'\n",
    "\n",
    "# Lesotho\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Maseru\", case=True, na=False), 'customer_country'] = 'Lesotho'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Maseru\", case=True, na=False), 'customer_country'] = 'Lesotho'\n",
    "\n",
    "# Sri Lanka\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Colombo 03\", case=True, na=False), 'customer_country'] = 'Sri Lanka'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Colombo 03\", case=True, na=False), 'customer_country'] = 'Sri Lanka'\n",
    "\n",
    "# Austria\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Klagenfurt\", case=True, na=False), 'customer_country'] = 'Austria'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Klagenfurt\", case=True, na=False), 'customer_country'] = 'Austria'\n",
    "\n",
    "# Netherlands\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Den Haag\", case=True, na=False), 'customer_country'] = 'Netherlands'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Den Haag\", case=True, na=False), 'customer_country'] = 'Netherlands'\n",
    "\n",
    "# Uganda\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Kampala\", case=True, na=False), 'customer_country'] = 'Uganda'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Kampala\", case=True, na=False), 'customer_country'] = 'Uganda'\n",
    "\n",
    "# Aruba\n",
    "df_train.loc[df_train['customer_country'].str.contains(\"Paradera\", case=True, na=False), 'customer_country'] = 'Aruba'\n",
    "df_test.loc[df_test['customer_country'].str.contains(\"Paradera\", case=True, na=False), 'customer_country'] = 'Aruba'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56341a0e",
   "metadata": {},
   "source": [
    "### *각국 도시 기반 Cleansing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "a22f38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brazil 도시\n",
    "Brazil_lst = ['Sao Paulo', 'São Paulo', 'João Pessoa', 'Capão da canoa', 'Cuiabá', 'Buzios', 'Aparecida',\n",
    "             'Manaus', 'Foz de Iguaçu', 'Dourados', 'Recife', 'Rio de Janeiro']\n",
    "for i in Brazil_lst:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Brazil'\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Brazil'\n",
    "    \n",
    "# Spain 도시\n",
    "Spain_lst = ['Madrid', 'MADRID', 'Barrio Viejo De Callosa De Segura', 'CACERES', 'VALENCIA', 'GRAN CANARIAS PLAYA DEL INGLES',\n",
    "             'ALICANTE'\n",
    "            ]\n",
    "for i in Spain_lst:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Spain'\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Spain'\n",
    "    \n",
    "# Saudi Arabia 도시\n",
    "Saudi_Arabia_lst = ['Riyadh', 'riyadh', 'Makkah', 'Qatif'\n",
    "            ]\n",
    "for i in Saudi_Arabia_lst:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Saudi Arabia'\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Saudi Arabia'\n",
    "    \n",
    "# Canada 도시\n",
    "Canada_lst = ['Dubreuilville', 'Port Renfrew', 'Alliston', 'Montreal', 'Etobicoke', 'Hamilton', 'Sandford'\n",
    "            ]\n",
    "for i in Canada_lst:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Canada'\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Canada'\n",
    "    \n",
    "# VietNam 도시\n",
    "VietNam_lst = ['Hai Duong','Thai Binh'\n",
    "            ]\n",
    "for i in VietNam_lst:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'VietNam'\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'VietNam'\n",
    "    \n",
    "# India 도시\n",
    "India_lst = ['Mumbai','mumbai','ROURKELA','udupi','bhilai','Ajmer','Satana','Jodhpur City','Bangalore','surat','BANGALORE','Ammanabrolu',\n",
    "             'Mysore','Muzaffarpur','Lucknow','Bemetara','Buldana','sangli','Kanpur','ahemdabad','Davangere','raipur','Dhanbad',\n",
    "             'bathinda','Jalgaon','namakkal', 'Guna mp', 'Hosapete','indore','Noida','hyderabad','Ludhiana', 'GUWAHATI','Delhi',\n",
    "             'Ahmedabad', 'Madurai', 'SOLAN', 'Bengaluru', 'Kanchipuram', 'Sangamner', 'Rajkot', 'Raichur', 'Bhubaneswar', 'Malur',\n",
    "             'Faridabad', 'Mathura', 'Vasai', 'kanpur', 'Ballia','MADURAI'\n",
    "            ]\n",
    "for i in India_lst:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'India'\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'India'\n",
    "    \n",
    "# Philippines 도시\n",
    "Philippines_lst = ['Angeles City','Paranaque','Cavite','CITY OF MARIKINA', 'San Juan', 'Quezon City', 'Qc', 'QUEZON CITY',\n",
    "                   'Bulacan', 'Makati', 'manila', 'Cebu', 'Pasig', 'CALOOCAN CITY', 'dasmarinas city', 'Mandaluyong', 'makati', 'Bataan', 'TAYTAY', 'Las Piñas - Muntinlupa', 'PASIG CITY', 'Manila', 'San Fernando City, La Union',\n",
    "                   'Parañaque','Rizal','CITY OF IMUS','San Pedro', 'Camarines Sur'\n",
    "            ]\n",
    "for i in Philippines_lst:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Philippines'\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Philippines'\n",
    "    \n",
    "# Jordan 도시\n",
    "Jordan_lst = ['Amman']\n",
    "\n",
    "for i in Jordan_lst:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Jordan'\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'Jordan'\n",
    "    \n",
    "# UK 도시\n",
    "UK_lst = ['Liss','Manchester','Providencaies','buckley', 'Newport', 'Windermere'\n",
    "            ]\n",
    "for i in UK_lst:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'United Kingdom'\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'customer_country'] = 'United Kingdom'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718302d3",
   "metadata": {},
   "source": [
    "### *미국 따로 처리*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "995bdcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities = [\n",
    "    \"New York City\", \"New York\", \"Los Angeles\", \"California\", \"Chicago\", \"Illinois\", \"Houston\", \"Texas\", \"Philadelphia\", \"Pennsylvania\",    \"Phoenix\", \"Arizona\", \"San Antonio\", \"Texas\", \"San Francisco\", \"California\", \"Boston\", \"Massachusetts\", \"Washington, D.C.\", \"Dallas\", \"Texas\", \"Atlanta\", \"Georgia\", \"Miami\", \"Florida\",\"Seattle\", \"Washington\",\"Denver\", \"Colorado\",\"Austin\", \"Texas\",\"Detroit\", \"Michigan\",\"Charlotte\", \"North Carolina\",\"San Diego\", \"California\",    \"Minneapolis\", \"Minnesota\",\"Tampa\", \"Florida\",\"Orlando\", \"Florida\",\"Portland\", \"Oregon\",\"St. Louis\", \"Missouri\",\"Pittsburgh\", \"Pennsylvania\",\n",
    "    \"Sacramento\", \"California\",\"Las Vegas\", \"Nevada\",\"Cincinnati\", \"Ohio\",\"Kansas City\", \"Missouri\",\"Cleveland\", \"Ohio\",\"San Jose\", \"California\",\"Nashville\", \"Tennessee\",\"Indianapolis\", \"Indiana\",\"Columbus\", \"Ohio\"]\n",
    "us_cities += [\n",
    "    \"Phoenix\",\"CARPINTERIA\",\"BROOKLYN\",\"COLUMBUS\", \"Arizona\",\"San Antonio\", \"Texas\",\"San Diego\", \"California\",\"Dallas\", \"Texas\",\"San Jose\", \"California\",\"Austin\", \"Texas\",\"Jacksonville\", \"Florida\",\"Fort Worth\", \"Texas\",\"Columbus\", \"Ohio\",\"Charlotte\", \"North Carolina\",\"Indianapolis\", \"Indiana\",\"San Francisco\", \"California\",    \"Seattle\", \"Washington\",\"Denver\", \"Colorado\",\"Washington\", \"Boston\", \"Massachusetts\",\"El Paso\", \"Texas\",\"Nashville\", \"Tennessee\",\"Portland\", \"Oregon\",\"Oklahoma City\", \"Oklahoma\",\"Las Vegas\", \"Nevada\",\"Baltimore\", \"Maryland\",\"Louisville\", \"Kentucky\", \"Milwaukee\", \"Wisconsin\",\"Albuquerque\", \"New Mexico\",\"Tucson\", \"Arizona\",\"Fresno\", \"California\",\"Sacramento\", \"California\",\"Kansas City\", \"Missouri\",\"Long Beach\", \"California\",\"Mesa\", \"Arizona\",\"Atlanta\", \"Georgia\",\"Colorado Springs\", \"Colorado\",\"Raleigh\", \"North Carolina\", \"Miami\", \"Florida\",\"Oakland\", \"California\",\"Tulsa\", \"Oklahoma\",\"Cleveland\", \"Ohio\",\"Wichita\", \"Kansas\",\"Arlington\", \"Texas\",\"New Orleans\", \"Louisiana\",\"Bakersfield\", \"California\",\"Tampa\", \"Florida\",\"Honolulu\", \"Hawaii\",\"Aurora\", \"Colorado\", \"Anaheim\", \"California\",\"Santa Ana\", \"California\",\"St. Louis\", \"Missouri\",\"Riverside\", \"California\",\"Corpus Christi\", \"Texas\",\"Lexington\", \"Kentucky\",\"Pittsburgh\", \"Pennsylvania\",\"Anchorage\", \"Alaska\",\"Stockton\", \"California\",\"Cincinnati\", \"Ohio\",\"St. Paul\", \"Minnesota\",\n",
    "    \"Toledo\", \"Ohio\",\"Greensboro\", \"North Carolina\",\"Newark\", \"New Jersey\",\"Plano\", \"Texas\",\"Henderson\", \"Nevada\",\"Lincoln\", \"Nebraska\",\"Buffalo\", \"New York\",\"Fort Wayne\", \"Indiana\",\"Jersey City\", \"New Jersey\",\"Chula Vista\", \"California\",\"Orlando\", \"Florida\", \"St. Petersburg\", \"Florida\",\"Norfolk\", \"Virginia\",\"Chandler\", \"Arizona\",\"Laredo\", \"Texas\",\"Madison\", \"Wisconsin\",\"Durham\", \"North Carolina\",\"Lubbock\", \"Texas\",\"Winston-Salem\", \"North Carolina\",\"Garland\", \"Texas\",\"Glendale\", \"Arizona\",\"Hialeah\", \"Florida\",\"Reno\", \"Nevada\",\"Baton Rouge\", \"Louisiana\",\"Irvine\", \"California\",]\n",
    "us_cities += [\n",
    "    \"Chesapeake\", \"Virginia\",\"Irving\", \"Texas\",\"Scottsdale\", \"Arizona\",\"North Las Vegas\", \"Nevada\",\"Fremont\", \"California\",\"Gilbert\", \"Arizona\",\"San Bernardino\", \"California\",\"Boise\", \"Idaho\",\"Birmingham\", \"Alabama\",\"Rochester\", \"New York\",\"Richmond\", \"Virginia\",\"Spokane\", \"Washington\", \"Des Moines\", \"Iowa\",\"Montgomery\", \"Alabama\",\"Modesto\", \"California\",\"Fayetteville\", \"North Carolina\",\"Tacoma\", \"Washington\",\"Shreveport\", \"Louisiana\",\"Fontana\", \"California\",\"Oxnard\", \"California\",\"Aurora\", \"Illinois\",\"Moreno Valley\", \"California\",\"Akron\", \"Ohio\", \"Yonkers\", \"New York\",\"Columbus\", \"Georgia\",\"Little Rock\", \"Arkansas\",\"Augusta\", \"Georgia\",\"Amarillo\", \"Texas\",\"Mobile\", \"Alabama\",\"Huntington Beach\", \"California\",\"Glendale\", \"California\",\"Grand Rapids\", \"Michigan\",\"Salt Lake City\", \"Utah\",\"Tallahassee\", \"Florida\", \"Huntsville\", \"Alabama\",\"Grand Prairie\", \"Texas\",\"Overland Park\", \"Kansas\",\"Knoxville\", \"Tennessee\",\"Worcester\", \"Massachusetts\",\"Brownsville\", \"Texas\",\"Newport News\", \"Virginia\",\"Santa Clarita\", \"California\",\"Port St. Lucie\", \"Florida\",\"Providence\", \"Rhode Island\",\"Fort Lauderdale\", \"Florida\",\n",
    "    \"Chattanooga\", \"Tennessee\",\"Tempe\", \"Arizona\",\"Oceanside\", \"California\",\"Garden Grove\", \"California\",\"Rancho Cucamonga\", \"California\",\"Cape Coral\", \"Florida\",\"Santa Rosa\", \"California\",\"Vancouver\", \"Washington\",\"Sioux Falls\", \"South Dakota\",\"Peoria\", \"Arizona\",\"Ontario\", \"California\", \"Jackson\", \"Mississippi\",\"Elk Grove\", \"California\",\"Springfield\", \"Missouri\",\"Pembroke Pines\", \"Florida\",\"Salem\", \"Oregon\",\"Corona\", \"California\",\"Eugene\", \"Oregon\",\"McKinney\", \"Texas\",\"Fort Collins\", \"Colorado\",\"Lancaster\", \"California\",\"Cary\", \"North Carolina\",\"Palmdale\", \"California\",\"Hayward\", \"California\",\"Salinas\", \"California\",\"Frisc\", \"Texas\",]\n",
    "us_cities += [\n",
    "    \"Philadelphia\", \"Pittsburgh\",\"Allentown\",\"Erie\",\"Reading\",\"Scranton\",\"Bethlehem\",\"Lancaster\",\"Harrisburg\",\"Altoona\",\"York\",\"Wilkes-Barre\",\"Chester\",\"Williamsport\",\"Easton\",\"Lebanon\",\"Hazleton\",\"New Castle\",\"Johnstown\",\"McKeesport\",\"Pottstown\",\"Sharon\",\"West Chester\", \"Norristown\",\"Hermitage\",\"Monroeville\",\"Plum\",\"State College\",\"Easton\",\"Baldwin\",\"Wilkinsburg\",\"Hanover\",\"Bethel Park\",\"Franklin Park\",\"Levittown\",\"Phoenixville\",\"Lansdale\",\"Warminster\",\"Butler\",\"Murrysville\",\"Carlisle\",\"Greensburg\",\"West Mifflin\",\"Chambersburg\", \"McKees Rocks\",\"Pottsville\",\"Wilkins\",\"King of Prussia\",\"Shaler\",\"McKeesport\",\"Meadville\",\"New Kensington\",\"Stowe\",\"Nanticoke\",\"Uniontown\", \"Ellwood City\",\"Montgomeryville\",\"Jeannette\",\"South Park\",\"Limerick\",\"Fernway\",\"Haverford\",\"Bristol\",\"Brentwood\",\"Whitehall\",\"Leacock\", \"Yeadon\",\"Cranberry\",\"Baldwin\",\"Lower Burrell\",\"Bristol\",\"West Norriton\",\"Moon\",\"Bloomsburg\",\"Horsham\",\"East Hempfield\",\"Wayne\",\"Bethel\",\"Monessen\",\"Elizabethtown\",\"Ephrata\",\"Willow Grove\",\"Kingston\",\"Kennett\",\"Coraopolis\",\"Exeter\",\"Northampton\", \"North Huntingdon\",\"Millcreek\",\"South Williamsport\",\"Springfield\",\"Bristol\",\"Westtown\",\"Warren\",\"South Middleton\",\"Upper Providence\",\"McCandless\",\"Hanover\", \"South Whitehall\",\"Manheim\",\"Lancaster\",\"East Hempfield\",\"Upper Darby\",\"West Goshen\",\"Newtown\",\"Upper Merion\",\"Whitehall\",\"Whitemarsh\",\"West Lampeter\",\"Lower Macungie\",\"North Huntingdon\",\"Concord\",\"Upper Southampton\",\"Radnor\",\"Middletown\",\"East Bradford\",\"Springfield\",\"West Whiteland\",\"Whitpain\", \"East Brandywine\",\"West Hempfield\",\"Upper Providence\",\"East Cocalico\",\"Lower Southampton\",\"East Norriton\",\"Whitfield\",\"Lower Merion\",\"Murrysville\",\"Springfield\",\"Newtown\",\"Lower Paxton\",\"West Manchester\",\"East Lampeter\",\"Warminster\",\"Hampden\",\"Lower Providence\",\"Lower Makefield\",\"Spring Garden\",\"Lebanon\",\"North Middleton\",\n",
    "    \"Swatara\",\"Palmer\",\"Manheim\",\"Upper Macungie\",\"Springettsbury\",\"West Hanover\",\"South Fayette\",\"East Hempfield\",\"Marple\",\"East Pikeland\",\"Upper Dublin\",\"West Earl\",\"East Marlborough\",\"Lower Southampton\",\"South Middleton\",\"Horsham\",\"Lower Saucon\",\"North Strabane\",\"Warwick\",\"Spring\",\"South Whitehall\", \"West Vincent\",\"West Hempfield\",\"Hempfield\",\"North Fayette\",\"Upper Makefield\",\"Plumstead\",\"Springfield\",\"Robeson\",\"Whitemarsh\",\"West Manchester\",\"Londonderry\",\"North Lebanon\",\"East Goshen\",\"Middletown\",\"West Brandywine\",\"Susquehanna\",\"Lebanon\",\"Warrington\",\"Sadsbury\",\"Mount Joy\",\"Lower Gwynedd\", \"Richland\",\"East Pennsboro\",\"West Whiteland\",\"Plumstead\",\"South Park\",\"Warminster\",\"East Vincent\",\"Newberry\",\"Springfield\",\"Tredyffrin\",\"Westtown\",\"North Codorus\",\"Silver Spring\",\"Franklin\",\"Whitehall\",\"Windsor\",\"Cranberry\",\"West Cocalico\",\"Ferguson\",\"North Middleton\",\"Mount Lebanon\",\"East Bradford\",\"Richland\",\"Easttown\", \"Springfield\",\"East Norriton\",\"Concord\",\"West Bradford\",\"Manheim\",\"Spring Garden\",\"Hanover\",\"West Goshen\",\"Lower Makefield\",\"North Lebanon\",\"Exeter\",\"West Donegal\",\"Economy\",\"Cranberry\",\"Upper Uwchlan\",\"Londonderry\",\"West Nantmeal\",\"North Cornwall\",\"Springfield\",\"East Brandywine\",\"New Hanover\",\"Lebanon\",\"West Pikeland\",\"Upper Providence\",\"Palmer\",\"Sadsbury\",\"South Londonderry\"]\n",
    "us_cities += [\n",
    "    'San Francisco', ' US', ' USA', 'Boston', 'Chicago', 'U.S.', 'Southfield', 'San Diego', 'New York', 'Los Angeles','Washington DC', 'Houston', 'St. Louis', 'Newton', 'Harrisburg', 'SOUTH SAN FRANCISCO','Hollywood', 'HOUSTON', 'Los Angelos', 'Greenville', 'Clinton', 'Charleston','Batavi', 'Omaha', 'Rockleigh', 'Spirit Lake', 'Draper', 'Hot Springs', 'Schaumburg','Kenner', 'Plainfield', 'Mentor', 'Monterey', 'Stowe', 'Hawthorne', 'Encino', 'Fargo','Elysburg', 'Newberry Springs', 'Ashland', 'Newark', 'Waukegan', 'Ocean Shores', 'Phoenix', 'Sterling', 'Fairfax', 'Garden Grove', 'DRAPER', 'NEWARK', 'Silver Spring',\n",
    "    'Manhattan', 'utica', 'Mashantucket', 'phoenix', 'Houghton', 'Cambridge', 'Topeka', 'Richland', 'chicago','Dexter', 'Danbury', 'ocean shores', 'Hyannis', 'Kihei', 'Mountville', 'Frederick', 'Naperville', 'Malvern', 'Palo Alto', 'Bellevue', 'Mooresville', 'Norwalk', 'Leesburg', 'Cicero', 'Coffeyville', 'garden grove', 'Orrville', 'Fair Oaks', 'ANAHEIM', 'Kuna', 'Not Hispanic or Latino', 'washington', 'Westfield', 'san antonio', 'Dayton', 'miami', 'Shawnee', 'Slidell','Swink', 'Reston', 'Los banos', 'Salida', 'Marina Del Rey', 'APO', 'PHOENIX', 'Houlton','miami','Durango', 'El paso', 'Beloit', 'Fort Bragg', 'Latham','Snellville','Davison', 'Lewisville', 'Sierra Vista','Hemlock','Soda Springs','Godley','Colonty', 'Post Falls', 'Myrtle Beach', 'Monrovia', 'Douglas', 'Bloomington', 'Zip 98433', 'Archbald', 'Twinsburg', 'Woodhaven','Sunnyvale', 'Chico', 'Nogales', 'Morrow','Nicholasville','Bradenton', 'costa mesa','Holly Springs','Carlsbad','Goodland','Reading','Peachtree Corners','Statesville','Upper Saint Clair','Fenton','Ladson','Saint Maries','5503 major blvd','Lander','Wilkes Barre', 'Altamonte Spg', 'Boulder', 'Bowie', 'Santa Barbara', 'Maple Grove', 'Merrifield', 'Sandusky', 'Hacienda Heights', 'Shepherdstown', 'El Segundo', 'Troy', 'Lafayette', 'Versailles','St Augustine Beach', 'Federal Way', 'Santa Monica', 'Independence', 'Offutt AFB', 'Logan', 'Coral Gables', 'Blue Bell', 'Odessa', 'Bloomingdale', 'Andersen AFB', 'Morristown', 'Lenoir City', 'Bridgeville', 'Marietta']\n",
    "us_cities += [\n",
    "    'Federal Way','Federal way', 'Wixom', 'Fort Pierce', 'Boca Raton', 'Mt Laurel Township', 'Stamford', 'Lakewood','Lake Ozark', 'Ann Arbor', 'Uniondale', 'Chuluota', 'CLIFTON', 'East Syracuse', 'Walnut Creek', 'Pasadena', 'Edmond', 'DeKalb', 'Bismarck', 'Torrance','Jefferson', 'Coalgate', 'Schriever Space Force Base', 'Maywood', 'Inglewood', 'South Bend', 'Woodside', 'Smoketown', 'Ellensburg','Agoura Hills', 'Eufaula', 'Randolph', 'Laurel', 'Dublin',\"Diamond Point\",\"Bellevue\",\"Ridgefield\",\"Gallipolis\",\"Liverpool\",'liverpool',\"Eagle Creek\",\"Topeka\",\"Monroe Township\",\"Lake Buena Vista\",\"Otis\",\"Mountainside\",'Olympia', 'topeka', 'pasadena', 'edmond', 'dublin', 'laurel', 'stamford','Prattville','inglewood','Bridgeport','bellevue','mountainside','Lewis Center','Alpharetta','Delray Beach','Ipswich','Ashburn','Largo','Farmers Branch','new york','Keshena','Waunakee','Blackville','Haverhill','Skokie','Carson','Cloverdale','Cypress','Vandenberg SFB','Brooklyn','City of Industry','Wellsboro','gardena','Saipan', 'Friendswood','Canton','Auburn','Wildwood','Maryville','Hapeville','La Jolla','The Colony','Fort Belvoir','Mankato','El Dorado Hills','Pismo Beach','White Plains','Fishkill','Stennis Space Center','Mill Valley','Annapolis','Chantilly','Los Gatos','Camden','Lambertville','Hyattsville','Sunrise','Peachtree City','Saint Petersburg','Basin','College Place','Decatur','phila','Columbs','Covington','Gig Harbor','Watertown','St. Cloud','Lac Du Flambeau','ridgeville','South Burlington','Beavercreek','Marysville','La Grande','Bandon','Normal','Weatherford','Moab','Lowell', 'Midlothian', 'Centerville', 'plymouth meeting', 'El Cajon', 'Gulf Shores', 'Biloxi', 'Lindenhurst', 'Jupiter', 'Grand Canyon','Plainsboro', 'East Rutherford', 'Rexburg', 'Oak Brook', 'Bell Gardens','Woodstock', 'Bensalem', 'Yreka', 'Lenexa', 'Summerfield', 'Burbank','Palm Valley', 'Orange', 'Massapequa', 'Lagrange', 'detroit', 'Laughlin','Danville', 'san rafael', 'Severance', 'Poughkeepsie', 'Danville','Eglin AFB', 'houston', 'Palmetto', 'Connellsville', 'Marion', 'port Orange','Wallace', 'athens', 'Lansing', 'Delavan', 'Niles', 'Goleta', 'Olathe','Joliet', 'Eva', 'woodbury', 'Montecito', 'Riverton', 'springdale','Farmington', 'Norcross', 'Eagan', 'Duncan', 'Rodeville', 'Rockville','Castle Rock', 'La Mirada', 'Manassas', 'Cupertino', 'Arkport','Taunton','Camp Hill','Santa Clara','Humboldt','Pooler','Palm Coast','Hackensack','San Leandro','Mission Hills','debary','austin','14700 Caribbean Way', '3 Nasson Avenue',\n",
    "    'Romulus','Renton','Doral','Kaysville','Meridian','Pompano Beac','Ferndale','St George','Hackensack','Ardmore','Staten Island','Opa-Locka','Great Falls','Champaign','North Babylon','Goldsboro','Kahului','Provo','South bend', 'Mount Juliet','Deptford','Terlingua','Hogansburg','Davenport','Eden Prairie','Morgantown','Oyster Bay','Westwood','Fortuna','Isle Of Palms','Kiawah Island','Eldersburg','Mandeville','Lewiston','Tyerl','Dover','brooklyn','Haltom City','Forney','Kennebunkport','pigeon forge','Cedarville','College Station','Alhambra','Weldon','North Smithfield','Ronkonkoma','barstow','Yuma','Monroe','Cathedral City','Nyack','Glencoe','Andover','Altamont springs','New Bedford','Miramar','Cashmere','Joint Base Lewis McChord','Homestead','Novi','Hunt Valley','Melbourne','Acworth','Nellis AFB','Kent','Kimberly','Mountain Lakes','FT HUACHUCA','Shelbyville','Bothell','montclair','Broken Arrow','Moffett Field','Youngstown','Roseville','Piscataway','Battle Mountain','Roswell','Curtis Bay','laGrange','Sanford','Chilhowie','Amherst','winston','Mahopac','Tinley Park','Kingsville','Manhasset','Abidjan','New Iberia','Holland','Elmsford','Owings mills','Ankeny','Lake Mary','Petersburg','trenton','Oxon Hill','Mableton','Tusayan','Ackerman','Mesquite','Round Rock','North Have','Seagoville','Kingwood','Dyersburg','Oroville','Wheatland','Littleton','League City','Flushing','Dearborn Heights','Speedway','Bell gardens','Lanham','Ft. Myers','Sparta','Stoughton','Charlevoix','Glenndale','Ridgewood','Carthage','Katy','South Shore','Ks','Rehoboth Beach','Bangor','Benbrook','Hastings','Middleburg Heights','Wylie','Edina','Sedona','Missoula','Litleton','lauderhill','Wilton','Flushing','Solana beach','Alameda', '3 Nasson Avenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c13a0948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1115/1115 [00:29<00:00, 37.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(us_cities):\n",
    "    condition = df_train['customer_country'].str.contains(i, case=True, na=False)\n",
    "    df_train.loc[condition, 'customer_country'] = 'United States'\n",
    "\n",
    "    condition = df_test['customer_country'].str.contains(i, case=True, na=False)\n",
    "    df_test.loc[condition, 'customer_country'] = 'United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "f0fd6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['customer_country'].str.contains(r'\\d', na=False)) & (df_train['response_corporate'] == 'LGEUS'), 'customer_country'] = 'United States'\n",
    "df_test.loc[(df_test['customer_country'].str.contains(r'\\d', na=False)) & (df_test['response_corporate'] == 'LGEUS'), 'customer_country'] = 'United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ba5ee400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['customer_country'].str.contains(r'\\d', na=False)) & (df_train['response_corporate'] == 'LGEIS'), 'customer_country'] = 'Italy'\n",
    "df_test.loc[(df_test['customer_country'].str.contains(r'\\d', na=False)) & (df_test['response_corporate'] == 'LGEIS'), 'customer_country'] = 'Italy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e9d9d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['customer_country'].str.contains(r'\\d', na=False)) & (df_train['response_corporate'] == 'LGEIL'), 'customer_country'] = 'India'\n",
    "df_test.loc[(df_test['customer_country'].str.contains(r'\\d', na=False)) & (df_test['response_corporate'] == 'LGEIL'), 'customer_country'] = 'India'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "738d2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['customer_country'].str.contains(r'\\d', na=False)) & (df_train['response_corporate'] == 'LGECB'), 'customer_country'] = 'Colombia'\n",
    "df_test.loc[(df_test['customer_country'].str.contains(r'\\d', na=False)) & (df_test['response_corporate'] == 'LGECB'), 'customer_country'] = 'Colombia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "2e563823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '/' 포함되면 unknown으로 간주.\n",
    "df_train.loc[df_train['customer_country'].str.contains(r'\\/', na=False), 'customer_country'] = 'Unknown'\n",
    "df_test.loc[df_test['customer_country'].str.contains(r'\\/', na=False), 'customer_country'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "20c83a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_train[df_train['customer_country'] != 'Unknown']\n",
    "df_tmp = df_tmp.groupby('lead_owner')['customer_country'].apply(lambda x: x.mode().iloc[0] if not x.mode().empty else None).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "00bfb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_tmp)):\n",
    "    lead = df_tmp.loc[i, 'lead_owner']\n",
    "    co = df_tmp.loc[i, 'customer_country']\n",
    "    df_train.loc[(df_train['lead_owner'] == lead) & (df_train['customer_country'] == 'Unknown'), 'customer_country'] = co\n",
    "    df_test.loc[(df_test['lead_owner'] == lead) & (df_test['customer_country'] == 'Unknown'), 'customer_country'] = co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb6dec",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbdc56e",
   "metadata": {},
   "source": [
    "## ***3. business_unit***\n",
    "MQL 요청 상품에 대응되는 사업부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "08646706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['business_unit'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "244062de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_unit\n",
       "ID          25161\n",
       "AS          23416\n",
       "IT           8166\n",
       "Solution      295\n",
       "CM              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['business_unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "69e2cc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업전환_확률</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_unit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <td>0.058891</td>\n",
       "      <td>23416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0.101943</td>\n",
       "      <td>25161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>0.083517</td>\n",
       "      <td>8166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solution</th>\n",
       "      <td>0.010169</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                영업전환_확률  Count\n",
       "business_unit                 \n",
       "AS             0.058891  23416\n",
       "CM             0.000000      1\n",
       "ID             0.101943  25161\n",
       "IT             0.083517   8166\n",
       "Solution       0.010169    295"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = pd.concat([pd.DataFrame(df_train.groupby('business_unit')['is_converted'].mean()), pd.DataFrame(df_train.groupby('business_unit')['is_converted'].count())], axis=1)\n",
    "tmp_df.columns = ['영업전환_확률', 'Count']\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75dbbfb",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b16ad3",
   "metadata": {},
   "source": [
    "## ***4. com_reg_ver_win_rate***\n",
    "(Vertical Level 1, business unit, region을 기준으로 oppty 비율을 계산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d17c185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42848"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['com_reg_ver_win_rate'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "46cacc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14191.000000\n",
       "mean         0.086192\n",
       "std          0.141167\n",
       "min          0.003788\n",
       "25%          0.019900\n",
       "50%          0.049180\n",
       "75%          0.074949\n",
       "max          1.000000\n",
       "Name: com_reg_ver_win_rate, dtype: float64"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['com_reg_ver_win_rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494ff09",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d0251",
   "metadata": {},
   "source": [
    "## ***5. customer_idx***\n",
    "고객의 회사명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "8b4e3a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_idx'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "246ee4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.concat([pd.DataFrame(df_train.groupby('customer_idx')['is_converted'].mean()), pd.DataFrame(df_train.groupby('customer_idx')['is_converted'].count())], axis=1)\n",
    "tmp_df.columns = ['영업전환_확률', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "c63f1c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업전환_확률</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25096</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              영업전환_확률  Count\n",
       "customer_idx                \n",
       "9324              1.0     14\n",
       "9857              1.0     11\n",
       "25096             1.0   2416"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df[(tmp_df['Count'] > 10) & (tmp_df['영업전환_확률'] > 0.95)].sort_values('영업전환_확률', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "32f7cacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업전환_확률</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25309</th>\n",
       "      <td>0.0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31864</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33350</th>\n",
       "      <td>0.0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37654</th>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              영업전환_확률  Count\n",
       "customer_idx                \n",
       "25309             0.0     87\n",
       "29370             0.0     61\n",
       "31864             0.0     70\n",
       "33350             0.0    102\n",
       "33763             0.0     88\n",
       "37654             0.0     76"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df[(tmp_df['Count'] > 50) & (tmp_df['영업전환_확률'] == 0.00)].sort_values('영업전환_확률', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8405f1",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd6417",
   "metadata": {},
   "source": [
    "## ***6. customer_type***\n",
    "고객 유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "31f5c6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42496"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_type'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "1a1a0b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "4de5d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['customer_type'].str.contains('end', case=False, na=False), 'customer_type'] = 'End-Customer'\n",
    "df_test.loc[df_test['customer_type'].str.contains('end', case=False, na=False), 'customer_type'] = 'End-Customer'\n",
    "\n",
    "df_train.loc[df_train['customer_type'].str.contains('Specifier', case=False, na=False), 'customer_type'] = 'Specifier/Influencer'\n",
    "df_test.loc[df_test['customer_type'].str.contains('Specifier', case=False, na=False), 'customer_type'] = 'Specifier/Influencer'\n",
    "\n",
    "df_train.loc[df_train['customer_type'].str.contains('other', case=False, na=False), 'customer_type'] = 'other'\n",
    "df_test.loc[df_test['customer_type'].str.contains('other', case=False, na=False), 'customer_type'] = 'other'\n",
    "\n",
    "# df_train.loc[df_train['customer_type'] == \"Etc.\", \"customer_type\"] = 'other'\n",
    "# df_test.loc[df_test['customer_type'] == \"Etc.\", \"customer_type\"] = 'other'\n",
    "\n",
    "df_train.loc[df_train['customer_type'].str.contains('home', case=False, na=False), 'customer_type'] = 'Home Owner'\n",
    "df_test.loc[df_test['customer_type'].str.contains('home', case=False, na=False), 'customer_type'] = 'Home Owner'\n",
    "\n",
    "df_train.loc[df_train['customer_type'].str.contains('Software', case=False, na=False), 'customer_type'] = 'Software/Solution Provider'\n",
    "df_test.loc[df_test['customer_type'].str.contains('Software', case=False, na=False), 'customer_type'] = 'Software/Solution Provider'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "15448a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['customer_type'] = df_train['customer_type'].fillna('Unknown')\n",
    "df_test['customer_type'] = df_test['customer_type'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "18c9258a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_type'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259efeb5",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c7199",
   "metadata": {},
   "source": [
    "## ***7. enterprise***\n",
    "Global 기업인지, Small/Medium 규모의 기업인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "123ab0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['enterprise'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "35baee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enterprise\n",
       "Enterprise    36643\n",
       "SMB           20396\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['enterprise'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b9d85e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업전환_확률</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enterprise</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enterprise</th>\n",
       "      <td>0.056709</td>\n",
       "      <td>36643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.125074</td>\n",
       "      <td>20396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             영업전환_확률  Count\n",
       "enterprise                 \n",
       "Enterprise  0.056709  36643\n",
       "SMB         0.125074  20396"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = pd.concat([pd.DataFrame(df_train.groupby('enterprise')['is_converted'].mean()), pd.DataFrame(df_train.groupby('enterprise')['is_converted'].count())], axis=1)\n",
    "tmp_df.columns = ['영업전환_확률', 'Count']\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62c528",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da68182",
   "metadata": {},
   "source": [
    "## ***8. historical_existing_cnt***\n",
    "이전에 Converted(영업 전환) 되었던 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "cb946894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43953"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['historical_existing_cnt'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "00c280fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13086.000000\n",
       "mean        19.578022\n",
       "std         44.679204\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          4.000000\n",
       "75%         19.000000\n",
       "max       1394.000000\n",
       "Name: historical_existing_cnt, dtype: float64"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['historical_existing_cnt'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f8ea11",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff7904",
   "metadata": {},
   "source": [
    "## ***9. id_strategic_ver***\n",
    "(도메인 지식) 특정 사업부(Business Unit이 ID일 때), 특정 사업 영역(Vertical Level1)에 대해 가중치를 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d22ea1",
   "metadata": {},
   "source": [
    "> 특정 사업부 -> ID / 특정 사업 영역 -> ['corporate / office', 'hotel & accommodation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "80f24642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53692"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['id_strategic_ver'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ac486eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_strategic_ver\n",
       "1.0    3347\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['id_strategic_ver'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "95ae2f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['corporate / office', 'hotel & accommodation'], dtype=object)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['id_strategic_ver'].notna()]['business_area'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992efb4a",
   "metadata": {},
   "source": [
    "결측치 0으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "8fde66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['id_strategic_ver'] = df_train['id_strategic_ver'].fillna(0)\n",
    "df_test['id_strategic_ver'] = df_test['id_strategic_ver'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd9b70",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7bd20",
   "metadata": {},
   "source": [
    "## ***10. it_strategic_ver***\n",
    "(도메인 지식) 특정 사업부(Business Unit이 IT일 때), 특정 사업 영역(Vertical Level1)에 대해 가중치를 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8f53d",
   "metadata": {},
   "source": [
    "> 특정 사업부 -> IT / 특정 사업 영역 -> ['corporate / office', 'hotel & accommodation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "512f3c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55925"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['it_strategic_ver'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "244e9241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "it_strategic_ver\n",
       "1.0    1114\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['it_strategic_ver'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "32678b73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hotel & accommodation', 'corporate / office'], dtype=object)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['it_strategic_ver'].notna()]['business_area'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d66a4f",
   "metadata": {},
   "source": [
    "결측치 0으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "edd7c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['it_strategic_ver'] = df_train['it_strategic_ver'].fillna(0)\n",
    "df_test['it_strategic_ver'] = df_test['it_strategic_ver'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180255d0",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e23516",
   "metadata": {},
   "source": [
    "## ***11. idit_strategic_ver***\n",
    "Id_strategic_ver이나 it_strategic_ver 값 중 하나라도 1의 값을 가지면 1 값으로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b2763cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52578"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['idit_strategic_ver'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "9cd3a782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idit_strategic_ver\n",
       "1.0    4461\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['idit_strategic_ver'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1240e5",
   "metadata": {},
   "source": [
    "결측치 0으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "7ecdea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['idit_strategic_ver'] = df_train['idit_strategic_ver'].fillna(0)\n",
    "df_test['idit_strategic_ver'] = df_test['idit_strategic_ver'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4adf54",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2fb954",
   "metadata": {},
   "source": [
    "## ***12. customer_job***\n",
    "고객의 직업군"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "8e699087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17544"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_job'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "eb7472a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_job\n",
       "engineering                     6130\n",
       "other                           4616\n",
       "administrative                  3310\n",
       "education                       2282\n",
       "sales                           2165\n",
       "                                ... \n",
       "waiter                             1\n",
       "design/build                       1\n",
       "installer/ system integrater       1\n",
       "designer/ engineer                 1\n",
       "kreation und design                1\n",
       "Name: count, Length: 560, dtype: int64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "bd0e7459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_job'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d83af1",
   "metadata": {},
   "source": [
    "결측치 Unknown으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "addae8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer_job NAN\n",
    "df_train['customer_job'] = df_train['customer_job'].fillna('Unknown')\n",
    "df_test['customer_job'] = df_test['customer_job'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7861184",
   "metadata": {},
   "source": [
    "일부 오탈자 및 비슷한 직업 묶기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "ec841fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineering\n",
    "engineering_lst = df_train.loc[df_train['customer_job'].str.contains('engine', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in engineering_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'engineering'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'engineering'\n",
    "    \n",
    "# administrative\n",
    "administrative_lst = df_train.loc[df_train['customer_job'].str.contains('admin', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in administrative_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'administrative'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'administrative'\n",
    "    \n",
    "#education\n",
    "education_lst = list(df_train.loc[df_train['customer_job'].str.contains('edu', case=False, na=False), 'customer_job'].unique())\n",
    "\n",
    "for i in education_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'education'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'education'\n",
    "    \n",
    "# administrative\n",
    "administrative_lst = df_train.loc[df_train['customer_job'].str.contains('admin', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in administrative_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'administrative'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'administrative'\n",
    "\n",
    "#healthcare services\n",
    "healthcare_services_lst = list(df_train.loc[df_train['customer_job'].str.contains('health', case=False, na=False), 'customer_job'].unique())\n",
    "\n",
    "for i in healthcare_services_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'healthcare services'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'healthcare services'\n",
    "    \n",
    "# sales\n",
    "sales_lst = df_train.loc[df_train['customer_job'].str.contains('sale', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in sales_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'sales'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'sales'\n",
    "    \n",
    "# operations\n",
    "operations_lst = df_train.loc[df_train['customer_job'].str.contains('sale', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in operations_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'operations'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'operations'\n",
    "\n",
    "# information technology\n",
    "information_technology_lst = df_train.loc[df_train['customer_job'].str.contains('inform', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in information_technology_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'information technology'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'information technology'\n",
    "    \n",
    "# purchasing\n",
    "purchasing_lst = df_train.loc[df_train['customer_job'].str.contains('purchas', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in purchasing_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'purchasing'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'purchasing'\n",
    "    \n",
    "# business development\n",
    "business_development_lst = df_train.loc[df_train['customer_job'].str.contains('develop', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in business_development_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'business development'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'business development'\n",
    "    \n",
    "# consulting\n",
    "consulting_lst = df_train.loc[df_train['customer_job'].str.contains('consult', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in consulting_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'consulting'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'consulting'\n",
    "\n",
    "# art and design\n",
    "art_and_design_lst = list(df_train.loc[df_train['customer_job'].str.contains('design', case=False, na=False), 'customer_job'].unique())\n",
    "art_and_design_lst.extend(['graphic/color art', 'artist, lead on equipment selection', 'art installation', '3d/vfx art', 'arte y diseño'])\n",
    "\n",
    "for i in art_and_design_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'art and design'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'art and design'\n",
    "    \n",
    "# marketing\n",
    "marketing_lst = df_train.loc[df_train['customer_job'].str.contains('market', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in marketing_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'marketing'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'marketing'\n",
    "    \n",
    "# program and project management\n",
    "program_and_project_management_lst = df_train.loc[df_train['customer_job'].str.contains('program', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in program_and_project_management_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'program and project management'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'program and project management'\n",
    "    \n",
    "program_and_project_management_lst_1 = df_train.loc[df_train['customer_job'].str.contains('project', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in program_and_project_management_lst_1:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'program and project management'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'program and project management'\n",
    "    \n",
    "# media and communication\n",
    "media_and_communication_lst = df_train.loc[df_train['customer_job'].str.contains('communication', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in media_and_communication_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'media and communication'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'media and communication'\n",
    "    \n",
    "media_and_communication_lst_1 = df_train.loc[df_train['customer_job'].str.contains('media', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in media_and_communication_lst_1:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'media and communication'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'media and communication'\n",
    "    \n",
    "# product management\n",
    "product_management_lst = df_train.loc[df_train['customer_job'].str.contains('product_management', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in product_management_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'product management'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'product management'\n",
    "    \n",
    "# finance\n",
    "finance_lst = df_train.loc[df_train['customer_job'].str.contains('market', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in finance_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'finance'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'finance'\n",
    "    \n",
    "# other\n",
    "other_lst = df_train.loc[df_train['customer_job'].str.contains('other', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in other_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'other'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'other'\n",
    "    \n",
    "# accounting\n",
    "accounting_lst = df_train.loc[df_train['customer_job'].str.contains('account', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in accounting_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'accounting'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'accounting'\n",
    "    \n",
    "# support\n",
    "support_lst = df_train.loc[df_train['customer_job'].str.contains('account', case=False, na=False), 'customer_job'].unique()\n",
    "\n",
    "for i in support_lst:\n",
    "    df_train.loc[df_train['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'support'\n",
    "    df_test.loc[df_test['customer_job'].str.contains(i, case=False, na=False), 'customer_job'] = 'support'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36745e39",
   "metadata": {},
   "source": [
    "561 -> 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "75e71500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_job'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313d7924",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a595d",
   "metadata": {},
   "source": [
    "## ***13. lead_desc_length***\n",
    "고객이 작성한 Lead Descriptoin 텍스트 총 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "0bddd6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lead_desc_length'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "c5a07d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    57039.000000\n",
       "mean        80.058574\n",
       "std        133.108047\n",
       "min          1.000000\n",
       "25%          8.000000\n",
       "50%         30.000000\n",
       "75%         93.000000\n",
       "max       1264.000000\n",
       "Name: lead_desc_length, dtype: float64"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lead_desc_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4787ad",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926accb0",
   "metadata": {},
   "source": [
    "## ***14. inquiry_type***\n",
    "고객의 문의 유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "143e86ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['inquiry_type'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "8be68c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inquiry_type\n",
       "Quotation or purchase consultation    23192\n",
       "Quotation or Purchase Consultation    17541\n",
       "Sales Inquiry                          9374\n",
       "Product Information                    1143\n",
       "Other                                   914\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['inquiry_type'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "6b9551a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['inquiry_type'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d4dfc",
   "metadata": {},
   "source": [
    "일부 오탈자 및 비슷한 직업 묶기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "77ea7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quotation or Purchase Consultation\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"quotation\", case=False, na=False), 'inquiry_type'] = 'Quotation or Purchase Consultation'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"quotation\", case=False, na=False), 'inquiry_type'] = 'Quotation or Purchase Consultation'\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"purchase\", case=False, na=False), 'inquiry_type'] = 'Quotation or Purchase Consultation'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"purchase\", case=False, na=False), 'inquiry_type'] = 'Quotation or Purchase Consultation'\n",
    "\n",
    "# Sales Inquiry\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"sale\", case=False, na=False), 'inquiry_type'] = 'Sales Inquiry'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"sale\", case=False, na=False), 'inquiry_type'] = 'Sales Inquiry'\n",
    "\n",
    "# Usage or Technical Consultation\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"Technical Consultation\", case=False, na=False), 'inquiry_type'] = 'Usage or Technical Consultation'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"Technical Consultation\", case=False, na=False), 'inquiry_type'] = 'Usage or Technical Consultation'\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"usage\", case=False, na=False), 'inquiry_type'] = 'Usage or Technical Consultation'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"usage\", case=False, na=False), 'inquiry_type'] = 'Usage or Technical Consultation'\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"Technical\", case=False, na=False), 'inquiry_type'] = 'Usage or Technical Consultation'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"Technical\", case=False, na=False), 'inquiry_type'] = 'Usage or Technical Consultation'\n",
    "\n",
    "# Other\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"other\", case=False, na=False), 'inquiry_type'] = 'Other'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"other\", case=False, na=False), 'inquiry_type'] = 'Other'\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"etc\", case=False, na=False), 'inquiry_type'] = 'Other'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"etc\", case=False, na=False), 'inquiry_type'] = 'Other'\n",
    "#Product Information\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"product\", case=False, na=False), 'inquiry_type'] = 'Product Information'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"product\", case=False, na=False), 'inquiry_type'] = 'Product Information'\n",
    "\n",
    "\n",
    "# Request for Partnership\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"partnership\", case=False, na=False), 'inquiry_type'] = 'Request for Partnership'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"partnership\", case=False, na=False), 'inquiry_type'] = 'Request for Partnership'\n",
    "\n",
    "\n",
    "# Services\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"service\", case=False, na=False), 'inquiry_type'] = 'Services'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"service\", case=False, na=False), 'inquiry_type'] = 'Services'\n",
    "\n",
    "\n",
    "# Trainings\n",
    "df_train.loc[df_train['inquiry_type'].str.contains(\"train\", case=False, na=False), 'inquiry_type'] = 'Trainings'\n",
    "df_test.loc[df_test['inquiry_type'].str.contains(\"train\", case=False, na=False), 'inquiry_type'] = 'Trainings'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1858d",
   "metadata": {},
   "source": [
    "71 -> 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "ecb77fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['inquiry_type'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b9f34",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea617e58",
   "metadata": {},
   "source": [
    "## ***15. product_category***\n",
    "요청 제품 카테고리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "d21d0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['raw_product_category'] = df_train['product_category'].copy()\n",
    "df_test['raw_product_category'] = df_test['product_category'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "6c7b14f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17998"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_category'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "7eeb58d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "39a87843",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict ={\n",
    "'interactive digital board' : 'Commercial Display / Interactive Signage', 'vrf' : 'HVAC, ESS / VRF', 'multi-split' : 'HVAC, ESS / Multi-Split', 'video wall signage' : 'Commercial Display / Video Wall Signage', 'etc.' : 'etc.', 'led signage' : 'Commercial Display / LED Signage', 'interactive signage' : 'Commercial Display / Interactive Signage', 'single-split' : 'HVAC, ESS / Single-Split', 'rac' : 'HVAC, ESS / AC', 'oled signage' : 'Commercial Display / OLED Signage', 'hotel tv' : 'Commercial Display / Hotel TV', 'chiller' : 'HVAC, ESS / Chiller', 'standard signage' : 'Commercial Display / Standard Signage', 'medical display' : 'IT PRODUCTS / Medical Display', 'lg one:quick series' : 'Commercial Display / One:Quick Series', 'monitor': 'IT PRODUCTS / Monitor', 'one:quick series' : 'Commercial Display / One:Quick Series', 'heating' : 'HVAC, ESS / Heating', 'high brightness signage' : 'Commercial Display / High Brightness Signage', 'ventilation' : 'HVAC, ESS / Ventilation', 'teto ou cassete inverter' : 'HVAC, ESS / inverter', 'control' : 'HVAC, ESS / Control', 'multi inverter' : 'HVAC, ESS / inverter', 'ar condicionado residencial' : 'HVAC, ESS / AC', 'high brightness' : 'Commercial Display / High Brightness Signage', 'software solution' : 'Commercial Display / Software Solution', 'accessories' : 'Commercial Display / Accessories', 'special signage' : 'Commercial Display / Special Signage', 'hospital tv' : 'Commercial Display / Hospital TV', 'webos' : 'Commercial Display / WebOS', 'pc' : 'IT PRODUCTS', 'pro:centric' : 'Commercial Display / Pro:Centric', 'video wall' : 'Commercial Display / Video Wall Signage', 'projector' : 'IT PRODUCTS / Projector', 'all lg vrf systems' : 'HVAC, ESS / VRF', 'commercial display' : 'Commercial Display', 'residential air conditioner' :  'HVAC, ESS / AC', 'ur640' : 'Commercial Display', 'outros' : 'others', 'signage care solution' : 'Commercial Display / Signage Care Solution', 'multi v 5 air' : 'HVAC, ESS / ou', 'smart tv signage' : 'Commercial Display', 'technical support' : 'technical support', 'ur640s' : 'Commercial Display', 'cloud device' : 'IT PRODUCTS / Cloud Device', 'medical displays' : 'IT PRODUCTS / Medical Display', 'laptop' : 'IT PRODUCTS / Laptop', 'a thermodynamic water heater' : 'HVAC, ESS / Heating', 'uhd signage' : 'Commercial Display', 'monitor signage,monior/monitor tv' : 'Commercial Display', 'idb' : 'Commercial Display / Interactive Signage', 'virtual production' : 'virtual production', 'ogrzewanie (pompy ciepła)' : 'HVAC, ESS / Chiller', 'commercial tv' : 'Commercial Display / commercial tv', 'videowall_rmk' : 'Commercial Display / Video Wall Signage', 'digital signage' : 'Commercial Display / Digital Signage', '43us660h0sd.awz' : 'Commercial Display / Hotel TV', 'ledallinone' : 'Commercial Display / LED Signage', 'solar,ess' : 'solar & ess', 'services' : 'services', 'commercial tv,tv' : 'Commercial Display / commercial tv', 'monitor & pc' : 'IT PRODUCTS', 'aire acondicionado residencial' : 'HVAC, ESS / AC', 'onequick series' : 'Commercial Display / One:Quick Series', 'others' : 'others', 'led 顯示屏' : 'Commercial Display / LED Signage', 'education createboard' : 'Commercial Display / Interactive Signage', '28mq780' : 'IT PRODUCTS / Monitor', '32lq621cbsb.awz' : 'Commercial Display', 'other' : 'others', 'monior/monitor tv,tv' : 'Commercial Display', 'multi v water 5' : 'HVAC, ESS / ou', 'isıtma' : 'HVAC, ESS / Heating', 'tv' : 'Commercial Display', 'standalone' : 'Commercial Display', 'lainnya' : 'others', 'id' : 'id', 'calefacción' : 'HVAC, ESS / Heating', 'otros' : 'others', 'solar,system ac' : 'solar & HVAC, ESS / AC', 'sales inquiry' : '판매문의', 'fhd series' : 'Commercial Display', 'lg one:quick' : 'Commercial Display / One:Quick Series', 'washing machine,dryer' : 'Home Appliances / Washing Machine & Dryer', 'solar,aircare' : 'solar & Home Appliances / Aircare', '互動式顯示屏' : 'Commercial Display / Interactive signage', 'تكييف وتبريد' : 'HVAC, ESS / AC', 'tv signage' : 'Commercial Display', 'chiller,aircare' : 'HVAC, ESS / Chiller & Home Appliances / Aircare', 'system ac,aircare' : 'HVAC, ESS / AC & Home Appliances / Aircare', 'allinone_rmk' : 'all in one', 'led' : 'Commercial Display / LED Signage', 'multi v5 vrf' : 'HVAC, ESS / VRF', 'signage' : 'Commercial Display', 'điều hòa trung tâm multi' : 'HVAC, ESS', 'solar,chiller' : 'solar & HVAC, ESS / Chiller', 'vrf,multi-split,single-split' : 'HVAC, ESS / VRF & Multi-Split & Single-Split', 'monitor signage,commercial tv' : 'Commercial Display / commercial tv', 'leadallin' : 'Commercial Display / LED Signage', 'oled 顯示屏' : 'Commercial Display / OLED Signage', 'soğutucu' : 'HVAC, ESS / AC', 'robots' : 'Robot', 'htv' : 'Commercial Display', 'vrf,multi-split,single-split,chiller' : 'HVAC, ESS / VRF & Multi-Split & Single-Split & Chiller', 'vrf,multi-split' : 'HVAC, ESS / VRF & Multi-Split', 'computer monitors' : 'IT PRODUCTS / Monitor', 'vrf,single-split' : 'HVAC, ESS / VRF & Single-Split', 'system ac,chiller' : 'HVAC, ESS / AC & Chiller', 'single split' : 'HVAC, ESS / Single-Split', 'מזגנים למקום מגורים' : 'HVAC, ESS / AC', '標準顯示屏' : 'Commercial Display', 'monitor signage,commercial tv,monior/monitor tv' : 'Commercial Display / commercial tv & Commercial Display', 'monitor signage,commercial tv,solar,ess,monior/monitor tv,pc,projector,robot,system ac,ems,rac,chill' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / Projector & HVAC, ESS / AC & HVAC, ESS / Chiller & ems & HVAC, ESS / AC & Robot', 'commercial tv,projector' : 'Commercial Display / commercial tv & IT PRODUCTS / Projector', 'corpouh5f' : 'Commercial Display', 'commercial tv,monior/monitor tv' : 'Commercial Display / commercial tv & Commercial Display', 'error' : 'error', 'تكييفات' : 'HVAC, ESS / AC', 'standard' : 'Commercial Display / Standard Signage', 'مبرد (تشيلر)' : 'HVAC, ESS / AC', 'نظام التدفق المتغيرvrf' : 'HVAC, ESS / VRF', 'vb.' : 'Home Appliances / Vacuum Cleaner', 'multi-split (plusieurs pièces)' : 'HVAC, ESS / Multi-Split', 'lg customer care program' : 'lg customer care program', 'aquecimento' : 'HVAC, ESS / Heating', 'laec015' : 'Commercial Display / LED Signage', 'commercial tv,audio/video' : 'Commercial Display / commercial tv & Commercial Display / AV', 'monitor signage,tv' : 'Commercial Display', 'medical monitors' : 'IT PRODUCTS / Medical Display', 'vrf,multi-split,single-split,chiller,heating' : 'HVAC, ESS / VRF & Multi-Split & Single-Split & Chiller & Heating', 'ultra stretch signage' : 'Commercial Display', 'autre' : 'others', 'solar' : 'solar', 'corpuh5f-' : 'Commercial Display', 'monitor signage,pc' : 'Commercial Display & IT PRODUCTS', 'digital signage or commercial tvs' : 'Commercial Display / Digital Signage & Commercial Display / commercial tv', 'monior/monitor tv,pc' : 'Commercial Display & IT PRODUCTS / pc', '特別顯示屏' : 'IT PRODUCTS / Monitor', 'חימום' : 'HVAC, ESS / Heating', 'vrf,chiller' : 'HVAC, ESS / VRF & Chiller', 'ฯลฯ' : 'none', 'system air conditioner' : 'HVAC, ESS / AC', 'hoteleria_us670h' : 'Commercial Display', '55uq801c0sb.bwz' : 'Commercial Display', 'chiller,water care' : 'HVAC, ESS / Chiller & Home Appliances / Water Care', 'klimatyzacja multi-split' : 'HVAC, ESS / Multi-Split', '43uq751c0sf.bwz' : 'Commercial Display', 'scroll compressor' : 'Compressor, Motor / Scroll Compressor', '50uq801c0sb.bwz' : 'Commercial Display', 'vrf,multi-split,single-split,heating' : 'HVAC, ESS / VRF & Multi-Split & Single-Split & Heating', 'on or several reversible ac' : 'HVAC, ESS / AC', '55us660h0sd.bwz' : 'Commercial Display / Hotel TV', 'transparent oled' : 'Commercial Display / OLED Signage', 'monitor signage,commercial tv,monior/monitor tv,projector,tv' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / Projector', 'commercial tv,water care' : 'Commercial Display / commercial tv & Home Appliances / Water Care', 'one quick:flex' : 'Commercial Display / One:Quick Series', 'vrf,multi-split,single-split,chiller,etc.' : 'HVAC, ESS / VRF & Multi-Split & Single-Split & Chiller', 'tv,commercial tv' : 'Commercial Display / commercial tv',\n",
    " 'signage care solutions' : 'Commercial Display / Signage Care Solution', 'system ac,chiller,aircare' : 'HVAC, ESS & HVAC, ESS / Chiller & Home Appliances / Aircare', 'tv,refrigerator,washing machine' : 'Commercial Display & Home Appliances / Refrigerator & Washing Machine', 'climatiseur résidentiel' : 'HVAC, ESS', 'kimatyzacja vrf' : 'HVAC, ESS / VRF', 'เครื่องปรับอากาศเผื่อที่อยู่อาศัย' : 'HVAC, ESS & AC', 'monitor signage,audio/video' : 'Commercial Display & Commercial Display / AV', 'window facing display' : 'Commercial Display', 'lg home bliss air solution' : 'HVAC, ESS', 'ahu' : 'HVAC, ESS / VRF', 'split tunggal' : 'HVAC, ESS / Single-Split', 'ultra stretch series' : 'Commercial Display', 'system ac,rac' : 'HVAC, ESS / AC ', 'monitor signage,commercial tv,solar,ess,monior/monitor tv,pc' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS & solar & HVAC, ESS', 'bu50nst' : 'IT PRODUCTS / Projector', 'energy storage system' : 'HVAC, ESS', 'ac rumah' : 'HVAC, ESS / AC', 'commercial tv,robot' : 'Commercial Display / commercial tv & Robot', 'multi v' : 'HVAC, ESS / ou', 'tv,audio/video' : 'Commercial Display & Commercial Display / AV', 'solar,projector' : 'solar & IT PRODUCTS / Projector', 'multi split' : 'HVAC, ESS / Multi-Split', '酒店電視' : 'Commercial Display / Hotel TV', 'solar,monior/monitor tv' : 'solar & Commercial Display', 'system ac,refrigerator' : 'HVAC, ESS / AC & Home Appliances / Refrigerator', 'solar,refrigerator' : 'solar & Home Appliances / Refrigerator', 'monitor signage,system ac' : 'Commercial Display & HVAC, ESS / AC', 'system air conditioner,solar' : 'HVAC, ESS / AC & solar', 'solar,tv' : 'solar & Commercial Display', 'aio' : 'all in one', 'điều hòa cục bộ' : 'HVAC, ESS / AC', 'điều hòa gia dụng' : 'HVAC, ESS / AC', '55vm5e-a' : 'Commercial Display', 'laec15' : 'Commercial Display / LED Signage', '醫院電視' : 'Commercial Display / Hospital TV', 'ctv' : 'Commercial Display', '軟體' : 'IT PRODUCTS / software_', '55vm5j-h' : 'Commercial Display / Video Wall Signage', 'hospitality' : 'IT PRODUCTS / Medical Display', '49vl5f' : 'Commercial Display', 'monitorindustrial_rmk' : 'IT PRODUCTS / Monitor', 'lg magnit' : 'Commercial Display / LED Signage', 'retaildigital' : 'Commercial Display', 'one:quick' : 'Commercial Display / One:Quick Series', 'led cinema' : 'Commercial Display / LED Signage', '86uh5f' : 'Commercial Display', '55tc3d' : 'Commercial Display / Interactive signage', '43us660h (na)' : 'Commercial Display / Hotel TV', 'pro centric hotel' : 'Commercial Display / Hotel TV', 'comercial tv' : 'Commercial Display', 'video wall + aio' : 'Commercial Display / Video Wall Signage', '高亮度顯示屏' : 'Commercial Display / High Brightness Signage', 'led 70m2' : 'Commercial Display / LED Signage', 'single cac' : 'HVAC, ESS / AC', 'vrf - multi v s' : 'HVAC, ESS / VRF', 'procentric' : 'Commercial Display / Pro:Centric', 'monitor signage,monior/monitor tv,vacuum cleaner,tv,home beauty,commercial tv,pc,refrigerator,styler' : 'Commercial Display / commercial tv & Commercial Display & Home Appliances / Vacuum Cleaner & Home Appliances / Home Beauty & IT PRODUCTS / pc & Home Appliances / Refrigerator & Home Appliances / Styler', 'refrigerator,built-in/cooking' : 'Home Appliances / Refrigerator & Built-in, Cooking', 'ems,audio/video' : 'ems & Commercial Display / AV', 'projector,ems,mobile,audio/video' : 'IT PRODUCTS / Projector & ems & mobile & Commercial Display / AV', 'smart tv' : 'Commercial Display', 'tv 55\"' : 'Commercial Display', 'surgical monitor' : 'IT PRODUCTS / Medical Display', 'gsca046' : 'Commercial Display / LED Signage', 'gscd100' : 'Commercial Display / LED Signage', '32 pol' : 'Commercial Display', 'systèmes de débit à réfrigérant variable (drv)' : 'HVAC, ESS / AC', 'tv 43 pol' : 'Commercial Display', '43 pol' : 'Commercial Display', 'commercial tv,solar,ess,monior/monitor tv,pc,projector,robot,system ac,ems,rac,chiller,refrigerator,' : 'Commercial Display / commercial tv & HVAC, ESS / AC & solar & ess & IT PRODUCTS / Projector & Robot & Commercial Display & ems & HVAC, ESS / Chiller & Home Appliances / Refrigerator', 'tv,refrigerator' : 'Commercial Display & Home Appliances / Refrigerator', 'a definir' : 'none', 'điều hòa trung tâm chiller' : 'HVAC, ESS / Chiller', 'lsca039' : 'Commercial Display / LED Signage', 'essential series' : 'Commercial Display / LED Signage', 'parts' : 'Commercial Display / Accessories', 'vrf,heating' : 'HVAC, ESS / VRF & HVAC, ESS / Heating', 'điều hòa trung tâm vrf' : 'HVAC, ESS / VRF', 'inne' : 'others', '98uh5e' : 'Commercial Display', 'khác' : 'others', 'lg salang air solution for dream homes' : 'HVAC, ESS / AC', 'rac single cac' : 'HVAC, ESS / AC', 'آخر' : 'none', 'multi-split,single-split' : 'HVAC, ESS / Multi-Split & HVAC, ESS / Single-Split', 'vrf,multi-split,etc.' : 'HVAC, ESS / VRF & HVAC, ESS / Multi-Split', 'vrf,multi-split,heating' : 'HVAC, ESS / VRF & HVAC, ESS / Multi-Split & HVAC, ESS / Heating', 'vrf,single-split,chiller' : 'HVAC, ESS / VRF & HVAC, ESS / Single-Split & HVAC, ESS / Chiller', 'commercial tv,solar,ess,projector,system ac,tv,washing machine,home beauty,audio/video' : 'Commercial Display / commercial tv & Commercial Display & solar & ess & IT PRODUCTS / Projector & HVAC, ESS / AC & Home Appliances / Washing Machine & Home Appliances / Home Beauty & Commercial Display / AV', 'solar,robot' : 'solar & Robot', 'pantalla led outdoor' : 'Commercial Display / LED Signage', 'monitor signage,commercial tv,monior/monitor tv,pc,projector,tv,audio/video' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / pc & IT PRODUCTS / Projector & Commercial Display / AV', 'not specified' : 'none', 'lg led bloc' : 'Commercial Display / LED Signage', 'solar,energy storage system' : 'solar & ess', 'system ac,solar' : '냉HVAC, ESS / AC & solar', 'solar,system ac,water care' : 'solar & HVAC, ESS / AC & Home Appliances / Water Care', '55svh7f-a' : 'Commercial Display', 'tr3' : 'Commercial Display', 'uh' : 'Commercial Display', 'laec015-gn.awz' : 'Commercial Display / LED Signage', '49vl5g-m' : 'Commercial Display / Video Wall Signage', 'chiller,dryer' : 'HVAC, ESS / Chiller & Home Appliances / Dryer', 'monitor signage,monior/monitor tv,system ac,vacuum cleaner,tv,home beauty,commercial tv,mobile,audio' : 'Commercial Display / commercial tv & Commercial Display & HVAC, ESS / AC & Home Appliances / Vacuum Cleaner & Home Appliances / Home Beauty & mobile & Commercial Display / AV', 'videwall' : 'Commercial Display / Video Wall Signage', 'solar,vacuum cleaner' : 'solar & Home Appliances / Vacuum Cleaner', 'solar,monior/monitor tv,pc,tv,refrigerator,washing machine,dryer,home beauty' : 'solar & Commercial Display & IT PRODUCTS / pc & Home Appliances / Refrigerator & Home Appliances & Home Appliances / Washing Machine & Home Appliances / Dryer & Home Appliances / Home Beauty', 'monitor signage,solar,robot,water care' : 'Commercial Display & solar & Robot & Home Appliances / Water Care', 'mobile,audio/video' : 'mobile & Commercial Display / AV',\n",
    " 'system ac,refrigerator,washing machine,dryer' : 'HVAC, ESS / AC & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Dryer', 'solar,system ac,aircare' : 'solar & HVAC, ESS / AC & Home Appliances / Aircare', 'projector,system ac,water care' : 'IT PRODUCTS / Projector & HVAC, ESS / AC & Home Appliances / Water Care', 'monior/monitor tv,tv,commercial tv,pc,refrigerator,solar,rac,washing machine,mobile,ess,audio/video' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / pc & Home Appliances / Refrigerator & solar & HVAC, ESS / AC & Home Appliances / Washing Machine & mobile & ess & Commercial Display / AV', 'ess,chiller' : 'ess & HVAC, ESS / Chiller', 'monitor signage,monior/monitor tv,pc,tv' : 'Commercial Display & IT PRODUCTS / pc', 'solar,water care' : 'solar & Home Appliances / Water Care', 'monitor signage,commercial tv,monior/monitor tv,tv' : 'Commercial Display / commercial tv & Commercial Display', 'monitor signage,commercial tv,audio/video' : 'Commercial Display / commercial tv & Commercial Display & Commercial Display / AV', 'solar,built-in/cooking' : 'solar & Home Appliances / Built-in, Cooking', 'monitor signage,monior/monitor tv,commercial tv' : 'Commercial Display / commercial tv & Commercial Display', 'robot,system ac' : 'Robot & HVAC, ESS / AC', 'medical- surgical' : 'IT PRODUCTS / Medical Display', 'radiology displays' : 'IT PRODUCTS / Medical Display', 'high inch 86 / 98 or 110' : 'Commercial Display', 'dryer,chiller' : 'Home Appliances / Dryer & HVAC, ESS / Chiller', 'solar,dryer' : 'solar & Home Appliances / Dryer', 'chiller/enfriadoras' : 'HVAC, ESS / Chiller & HVAC, ESS / AC', 'refrigerator' : 'Home Appliances / Refrigerator', 'led aio 136' : 'Commercial Display / LED Signage', '110 + video wall' : 'Commercial Display / Video Wall Signage', 'videowall signage' : 'Commercial Display / Video Wall Signage', 'one:quick flex' : 'Commercial Display / One:Quick Series', 'collaboration displays' : 'Commercial Display', 'meeting & screen sharedirect view leddirect view led' : 'Commercial Display / LED Signage', 'one quick works' : 'Commercial Display / One:Quick Series', 'pendingin' : 'HVAC, ESS / AC', 'lg paradise air solution' : 'HVAC, ESS', 'פיצול מרובה' : 'HVAC, ESS / Multi-Split', 'אחר' : 'others', 'vrf,multi-split,chiller' : 'HVAC, ESS / VRF & HVAC, ESS / Multi-Split & HVAC, ESS / Chiller', 'system ac,solar,washing machine' : 'HVAC, ESS / AC & solar & Home Appliances / Washing Machine', 'solar,ess,ems' : 'solar & ess & ems', 'tv,mobile' : 'Commercial Display & mobile', 'aircare,water care' : 'Home Appliances / Aircare & Home Appliances / Water Care', 'monior/monitor tv,chiller' : 'Commercial Display & HVAC, ESS / Chiller', 'system ac,tv' : 'HVAC, ESS / AC & Commercial Display', 'monitor signage,commercial tv,solar,ess' : 'Commercial Display / commercial tv & Commercial Display & solar & ess', 'monior/monitor tv,system ac,tv,refrigerator,washing machine,dryer,built-in/cooking' : 'Commercial Display & HVAC, ESS / AC & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Dryer & Home Appliances / Built-in, Cooking', 'monitor signage,solar' : 'Commercial Display & solar', 'pc,washing machine' : 'IT PRODUCTS / pc & Home Appliances / Washing Machine', 'monitor signage,solar,monior/monitor tv,pc,projector,robot,system ac,tv,refrigerator,washing machine' : 'Commercial Display & solar & IT PRODUCTS / pc & IT PRODUCTS / Projector & Robot & HVAC, ESS / AC & Home Appliances / Refrigerator & Home Appliances / Washing Machine', 'system ac,tv,refrigerator,washing machine,built-in/cooking,audio/video' : 'HVAC, ESS / AC & Commercial Display & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Built-in, Cooking & Commercial Display / AV', 'system air conditioner,energy storage system' : 'HVAC, ESS / AC & ess', '50us660h0sd.bwz' : 'Commercial Display / LED Signage', 'tv 60\"' : 'Commercial Display', 'medical monitor' : 'IT PRODUCTS / Medical Display', 'aircare,mobile' : 'Home Appliances / Aircare & mobile', 'solar,ess,system ac' : 'solar & ess & HVAC, ESS / AC', 'tv,pc' : 'Commercial Display & IT PRODUCTS / pc', 'monitor signage,commercial tv,solar,pc,projector,system ac,ems,rac,chiller,refrigerator,washing mach' : 'Commercial Display / commercial tv & Commercial Display & solar & IT PRODUCTS / pc & IT PRODUCTS / Projector & HVAC, ESS / AC & ems & HVAC, ESS / Chiller & Home Appliances / Refrigerator & Home Appliances / Washing Machine', 'chiller,refrigerator' : 'HVAC, ESS / Chiller & Home Appliances / Refrigerator', 'monitor signage,commercial tv,solar,projector,robot,chiller,refrigerator,built-in/cooking,water care' : 'Commercial Display / commercial tv & Commercial Display & solar & IT PRODUCTS / pc & IT PRODUCTS / Projector & Robot & HVAC, ESS / Chiller & Home Appliances / Refrigerator & Home Appliances / Built-in, Cooking & Home Appliances / Water Care', 'commercial tv,solar' : 'Commercial Display / commercial tv & solar', 'monior/monitor tv,projector,audio/video' : 'Commercial Display & IT PRODUCTS / Projector & Commercial Display / AV', 'unitario' : 'none', 'refrigerator,chiller' : 'Home Appliances / Refrigerator & HVAC, ESS / Chiller', 'chiller,tv' : 'HVAC, ESS / Chiller & Commercial Display', 'projector,ems' : 'IT PRODUCTS / Projector & ems', 'cac' : 'HVAC, ESS', 'single package' : 'HVAC, ESS / Single-Split', 'monitor signage,mobile' : 'Commercial Display & mobile', 'robot,vacuum cleaner' : 'Robot & Home Appliances / Vacuum Cleaner', 'monitor signage,commercial tv,monior/monitor tv,audio/video' : 'Commercial Display / commercial tv & Commercial Display & Commercial Display / AV', 'aircare,built-in/cooking' : 'Home Appliances / Aircare & Home Appliances / Built-in, Cooking', '49uh / 49xf' : 'Commercial Display', '43uq751c0sb.bwz' : 'Commercial Display / Hotel TV', '32 / 43 pol' : 'Commercial Display', 'monior/monitor tv,audio/video' : 'Commercial Display & Commercial Display / AV', 'system ac,home beauty' : 'HVAC, ESS / AC & Home Appliances / Home Beauty', 'information display,monitor' : 'Commercial Display', 'taa lcd lfd displays' : 'Commercial Display', 'rac/cac' : 'HVAC, ESS / AC', 'حلول التدفئة' : 'HVAC, ESS / Heating', 'aio | one quick' : 'Commercial Display / One:Quick Series', 'monior/monitor tv,refrigerator' : 'Commercial Display & Home Appliances / Refrigerator', 'monior/monitor tv,system ac,tv,pc,refrigerator,water care,solar,washing machine,mobile,chiller,built' : 'Commercial Display & HVAC, ESS / AC & IT PRODUCTS / pc & Home Appliances / Refrigerator & Home Appliances / Water Care & solar & Home Appliances / Washing Machine & mobile & HVAC, ESS / Chiller & Home Appliances / Built-in, Cooking', 'projector,audio/video' : 'IT PRODUCTS / Projector & Commercial Display / AV', 'monitor signage,commercial tv,monior/monitor tv,pc,tv,home beauty,audio/video' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / pc & Home Appliances / Home Beauty & Commercial Display / AV', '49vl5g-m.awzm' : 'Commercial Display / Video Wall Signage', 'pc,robot,system ac,chiller,tv,refrigerator,washing machine,vacuum cleaner,styler,dryer,mobile,audio/' : 'IT PRODUCTS / pc & Robot & HVAC, ESS / AC & HVAC, ESS / Chiller & Commercial Display & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Vacuum Cleaner & Home Appliances / Dryer & Home Appliances / Styler & mobile & HVAC, ESS / AC', 'refrigerator,washing machine,built-in/cooking' : 'Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Built-in, Cooking', 'monitor signage,monior/monitor tv,tv,audio/video' : 'Commercial Display & Commercial Display / AV', 'tv,refrigerator,washing machine,vacuum cleaner,audio/video' : 'Commercial Display & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Vacuum Cleaner & HVAC, ESS / AC', 'pc,tv' : 'IT PRODUCTS / pc & Commercial Display', 'system ac' : 'HVAC, ESS / AC', 'sac' : 'HVAC, ESS / AC', 'gscd046' : 'Commercial Display / LED Signage', '43uh5f-h.awzm' : 'Commercial Display', 'monior/monitor tv,refrigerator,audio/video' : 'Commercial Display & Home Appliances / Refrigerator & Commercial Display / AV'\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "b386a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict ={\n",
    "'interactive digital board' : 'Commercial Display / Interactive Signage', 'vrf' : 'HVAC, ESS / VRF', 'multi-split' : 'HVAC, ESS / Multi-Split', 'video wall signage' : 'Commercial Display / Video Wall Signage', 'etc.' : 'etc.', 'led signage' : 'Commercial Display / LED Signage', 'interactive signage' : 'Commercial Display / Interactive Signage', 'single-split' : 'HVAC, ESS / Single-Split', 'rac' : 'HVAC, ESS / AC', 'oled signage' : 'Commercial Display / OLED Signage', 'hotel tv' : 'Commercial Display / Hotel TV', 'chiller' : 'HVAC, ESS / Chiller', 'standard signage' : 'Commercial Display / Standard Signage', 'medical display' : 'IT PRODUCTS / Medical Display', 'lg one:quick series' : 'Commercial Display / One:Quick Series', 'monitor': 'IT PRODUCTS / Monitor', 'one:quick series' : 'Commercial Display / One:Quick Series', 'heating' : 'HVAC, ESS / Heating', 'high brightness signage' : 'Commercial Display / High Brightness Signage', 'ventilation' : 'HVAC, ESS / Ventilation', 'teto ou cassete inverter' : 'HVAC, ESS / inverter', 'control' : 'HVAC, ESS / Control', 'multi inverter' : 'HVAC, ESS / inverter', 'ar condicionado residencial' : 'HVAC, ESS / AC', 'high brightness' : 'Commercial Display / High Brightness Signage', 'software solution' : 'Commercial Display / Software Solution', 'accessories' : 'Commercial Display / Accessories', 'special signage' : 'Commercial Display / Special Signage', 'hospital tv' : 'Commercial Display / Hospital TV', 'webos' : 'Commercial Display / WebOS', 'pc' : 'IT PRODUCTS', 'pro:centric' : 'Commercial Display / Pro:Centric', 'video wall' : 'Commercial Display / Video Wall Signage', 'projector' : 'IT PRODUCTS / Projector', 'all lg vrf systems' : 'HVAC, ESS / VRF', 'commercial display' : 'Commercial Display', 'residential air conditioner' :  'HVAC, ESS / AC', 'ur640' : 'Commercial Display', 'outros' : 'others', 'signage care solution' : 'Commercial Display / Signage Care Solution', 'multi v 5 air' : 'HVAC, ESS / ou', 'smart tv signage' : 'Commercial Display', 'technical support' : 'technical support', 'ur640s' : 'Commercial Display', 'cloud device' : 'IT PRODUCTS / Cloud Device', 'medical displays' : 'IT PRODUCTS / Medical Display', 'laptop' : 'IT PRODUCTS / Laptop', 'a thermodynamic water heater' : 'HVAC, ESS / Heating', 'uhd signage' : 'Commercial Display', 'monitor signage,monior / monitor tv' : 'Commercial Display', 'idb' : 'Commercial Display / Interactive Signage', 'virtual production' : 'virtual production', 'ogrzewanie (pompy ciepła)' : 'HVAC, ESS / Chiller', 'commercial tv' : 'Commercial Display / commercial tv', 'videowall_rmk' : 'Commercial Display / Video Wall Signage', 'digital signage' : 'Commercial Display / Digital Signage', '43us660h0sd.awz' : 'Commercial Display / Hotel TV', 'ledallinone' : 'Commercial Display / LED Signage', 'solar,ess' : 'solar & ess', 'services' : 'services', 'commercial tv,tv' : 'Commercial Display / commercial tv', 'monitor & pc' : 'IT PRODUCTS', 'aire acondicionado residencial' : 'HVAC, ESS / AC', 'onequick series' : 'Commercial Display / One:Quick Series', 'others' : 'others', 'led 顯示屏' : 'Commercial Display / LED Signage', 'education createboard' : 'Commercial Display / Interactive Signage', '28mq780' : 'IT PRODUCTS / Monitor', '32lq621cbsb.awz' : 'Commercial Display', 'other' : 'others', 'monior / monitor tv,tv' : 'Commercial Display', 'multi v water 5' : 'HVAC, ESS / ou', 'isıtma' : 'HVAC, ESS / Heating', 'tv' : 'Commercial Display', 'standalone' : 'Commercial Display', 'lainnya' : 'others', 'id' : 'id', 'calefacción' : 'HVAC, ESS / Heating', 'otros' : 'others', 'solar,system ac' : 'solar & HVAC, ESS / AC', 'sales inquiry' : '판매문의', 'fhd series' : 'Commercial Display', 'lg one:quick' : 'Commercial Display / One:Quick Series', 'washing machine,dryer' : 'Home Appliances / Washing Machine & Dryer', 'solar,aircare' : 'solar & Home Appliances / Aircare', '互動式顯示屏' : 'Commercial Display / Interactive signage', 'تكييف وتبريد' : 'HVAC, ESS / AC', 'tv signage' : 'Commercial Display', 'chiller,aircare' : 'HVAC, ESS / Chiller & Home Appliances / Aircare', 'system ac,aircare' : 'HVAC, ESS / AC & Home Appliances / Aircare', 'allinone_rmk' : 'all in one', 'led' : 'Commercial Display / LED Signage', 'multi v5 vrf' : 'HVAC, ESS / VRF', 'signage' : 'Commercial Display', 'điều hòa trung tâm multi' : 'HVAC, ESS', 'solar,chiller' : 'solar & HVAC, ESS / Chiller', 'vrf,multi-split,single-split' : 'HVAC, ESS / VRF & Multi-Split & Single-Split', 'monitor signage,commercial tv' : 'Commercial Display / commercial tv', 'leadallin' : 'Commercial Display / LED Signage', 'oled 顯示屏' : 'Commercial Display / OLED Signage', 'soğutucu' : 'HVAC, ESS / AC', 'robots' : 'Robot', 'htv' : 'Commercial Display', 'vrf,multi-split,single-split,chiller' : 'HVAC, ESS / VRF & Multi-Split & Single-Split & Chiller', 'vrf,multi-split' : 'HVAC, ESS / VRF & Multi-Split', 'computer monitors' : 'IT PRODUCTS / Monitor', 'vrf,single-split' : 'HVAC, ESS / VRF & Single-Split', 'system ac,chiller' : 'HVAC, ESS / AC & Chiller', 'single split' : 'HVAC, ESS / Single-Split', 'מזגנים למקום מגורים' : 'HVAC, ESS / AC', '標準顯示屏' : 'Commercial Display', 'monitor signage,commercial tv,monior / monitor tv' : 'Commercial Display / commercial tv & Commercial Display', 'monitor signage,commercial tv,solar,ess,monior / monitor tv,pc,projector,robot,system ac,ems,rac,chill' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / Projector & HVAC, ESS / AC & HVAC, ESS / Chiller & ems & HVAC, ESS / AC & Robot', 'commercial tv,projector' : 'Commercial Display / commercial tv & IT PRODUCTS / Projector', 'corpouh5f' : 'Commercial Display', 'commercial tv,monior / monitor tv' : 'Commercial Display / commercial tv & Commercial Display', 'error' : 'error', 'تكييفات' : 'HVAC, ESS / AC', 'standard' : 'Commercial Display / Standard Signage', 'مبرد (تشيلر)' : 'HVAC, ESS / AC', 'نظام التدفق المتغيرvrf' : 'HVAC, ESS / VRF', 'vb.' : 'Home Appliances / Vacuum Cleaner', 'multi-split (plusieurs pièces)' : 'HVAC, ESS / Multi-Split', 'lg customer care program' : 'lg customer care program', 'aquecimento' : 'HVAC, ESS / Heating', 'laec015' : 'Commercial Display / LED Signage', 'commercial tv,audio / video' : 'Commercial Display / commercial tv & Commercial Display / AV', 'monitor signage,tv' : 'Commercial Display', 'medical monitors' : 'IT PRODUCTS / Medical Display', 'vrf,multi-split,single-split,chiller,heating' : 'HVAC, ESS / VRF & Multi-Split & Single-Split & Chiller & Heating', 'ultra stretch signage' : 'Commercial Display', 'autre' : 'others', 'solar' : 'solar', 'corpuh5f-' : 'Commercial Display', 'monitor signage,pc' : 'Commercial Display & IT PRODUCTS', 'digital signage or commercial tvs' : 'Commercial Display / Digital Signage & Commercial Display / commercial tv', 'monior / monitor tv,pc' : 'Commercial Display & IT PRODUCTS / pc', '特別顯示屏' : 'IT PRODUCTS / Monitor', 'חימום' : 'HVAC, ESS / Heating', 'vrf,chiller' : 'HVAC, ESS / VRF & Chiller', 'ฯลฯ' : 'none', 'system air conditioner' : 'HVAC, ESS / AC', 'hoteleria_us670h' : 'Commercial Display', '55uq801c0sb.bwz' : 'Commercial Display', 'chiller,water care' : 'HVAC, ESS / Chiller & Home Appliances / Water Care', 'klimatyzacja multi-split' : 'HVAC, ESS / Multi-Split', '43uq751c0sf.bwz' : 'Commercial Display', 'scroll compressor' : 'Compressor, Motor / Scroll Compressor', '50uq801c0sb.bwz' : 'Commercial Display', 'vrf,multi-split,single-split,heating' : 'HVAC, ESS / VRF & Multi-Split & Single-Split & Heating', 'on or several reversible ac' : 'HVAC, ESS / AC', '55us660h0sd.bwz' : 'Commercial Display / Hotel TV', 'transparent oled' : 'Commercial Display / OLED Signage', 'monitor signage,commercial tv,monior / monitor tv,projector,tv' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / Projector', 'commercial tv,water care' : 'Commercial Display / commercial tv & Home Appliances / Water Care', 'one quick:flex' : 'Commercial Display / One:Quick Series', 'vrf,multi-split,single-split,chiller,etc.' : 'HVAC, ESS / VRF & Multi-Split & Single-Split & Chiller', 'tv,commercial tv' : 'Commercial Display / commercial tv',\n",
    " 'signage care solutions' : 'Commercial Display / Signage Care Solution', 'system ac,chiller,aircare' : 'HVAC, ESS & HVAC, ESS / Chiller & Home Appliances / Aircare', 'tv,refrigerator,washing machine' : 'Commercial Display & Home Appliances / Refrigerator & Washing Machine', 'climatiseur résidentiel' : 'HVAC, ESS', 'kimatyzacja vrf' : 'HVAC, ESS / VRF', 'เครื่องปรับอากาศเผื่อที่อยู่อาศัย' : 'HVAC, ESS & AC', 'monitor signage,audio / video' : 'Commercial Display & Commercial Display / AV', 'window facing display' : 'Commercial Display', 'lg home bliss air solution' : 'HVAC, ESS', 'ahu' : 'HVAC, ESS / VRF', 'split tunggal' : 'HVAC, ESS / Single-Split', 'ultra stretch series' : 'Commercial Display', 'system ac,rac' : 'HVAC, ESS / AC ', 'monitor signage,commercial tv,solar,ess,monior / monitor tv,pc' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS & solar & HVAC, ESS', 'bu50nst' : 'IT PRODUCTS / Projector', 'energy storage system' : 'HVAC, ESS', 'ac rumah' : 'HVAC, ESS / AC', 'commercial tv,robot' : 'Commercial Display / commercial tv & Robot', 'multi v' : 'HVAC, ESS / ou', 'tv,audio / video' : 'Commercial Display & Commercial Display / AV', 'solar,projector' : 'solar & IT PRODUCTS / Projector', 'multi split' : 'HVAC, ESS / Multi-Split', '酒店電視' : 'Commercial Display / Hotel TV', 'solar,monior / monitor tv' : 'solar & Commercial Display', 'system ac,refrigerator' : 'HVAC, ESS / AC & Home Appliances / Refrigerator', 'solar,refrigerator' : 'solar & Home Appliances / Refrigerator', 'monitor signage,system ac' : 'Commercial Display & HVAC, ESS / AC', 'system air conditioner,solar' : 'HVAC, ESS / AC & solar', 'solar,tv' : 'solar & Commercial Display', 'aio' : 'all in one', 'điều hòa cục bộ' : 'HVAC, ESS / AC', 'điều hòa gia dụng' : 'HVAC, ESS / AC', '55vm5e-a' : 'Commercial Display', 'laec15' : 'Commercial Display / LED Signage', '醫院電視' : 'Commercial Display / Hospital TV', 'ctv' : 'Commercial Display', '軟體' : 'IT PRODUCTS / software_', '55vm5j-h' : 'Commercial Display / Video Wall Signage', 'hospitality' : 'IT PRODUCTS / Medical Display', '49vl5f' : 'Commercial Display', 'monitorindustrial_rmk' : 'IT PRODUCTS / Monitor', 'lg magnit' : 'Commercial Display / LED Signage', 'retaildigital' : 'Commercial Display', 'one:quick' : 'Commercial Display / One:Quick Series', 'led cinema' : 'Commercial Display / LED Signage', '86uh5f' : 'Commercial Display', '55tc3d' : 'Commercial Display / Interactive signage', '43us660h (na)' : 'Commercial Display / Hotel TV', 'pro centric hotel' : 'Commercial Display / Hotel TV', 'comercial tv' : 'Commercial Display', 'video wall + aio' : 'Commercial Display / Video Wall Signage', '高亮度顯示屏' : 'Commercial Display / High Brightness Signage', 'led 70m2' : 'Commercial Display / LED Signage', 'single cac' : 'HVAC, ESS / AC', 'vrf - multi v s' : 'HVAC, ESS / VRF', 'procentric' : 'Commercial Display / Pro:Centric', 'monitor signage,monior / monitor tv,vacuum cleaner,tv,home beauty,commercial tv,pc,refrigerator,styler' : 'Commercial Display / commercial tv & Commercial Display & Home Appliances / Vacuum Cleaner & Home Appliances / Home Beauty & IT PRODUCTS / pc & Home Appliances / Refrigerator & Home Appliances / Styler', 'refrigerator,built-in / cooking' : 'Home Appliances / Refrigerator & Built-in, Cooking', 'ems,audio / video' : 'ems & Commercial Display / AV', 'projector,ems,mobile,audio / video' : 'IT PRODUCTS / Projector & ems & mobile & Commercial Display / AV', 'smart tv' : 'Commercial Display', 'tv 55\"' : 'Commercial Display', 'surgical monitor' : 'IT PRODUCTS / Medical Display', 'gsca046' : 'Commercial Display / LED Signage', 'gscd100' : 'Commercial Display / LED Signage', '32 pol' : 'Commercial Display', 'systèmes de débit à réfrigérant variable (drv)' : 'HVAC, ESS / AC', 'tv 43 pol' : 'Commercial Display', '43 pol' : 'Commercial Display', 'commercial tv,solar,ess,monior / monitor tv,pc,projector,robot,system ac,ems,rac,chiller,refrigerator,' : 'Commercial Display / commercial tv & HVAC, ESS / AC & solar & ess & IT PRODUCTS / Projector & Robot & Commercial Display & ems & HVAC, ESS / Chiller & Home Appliances / Refrigerator', 'tv,refrigerator' : 'Commercial Display & Home Appliances / Refrigerator', 'a definir' : 'none', 'điều hòa trung tâm chiller' : 'HVAC, ESS / Chiller', 'lsca039' : 'Commercial Display / LED Signage', 'essential series' : 'Commercial Display / LED Signage', 'parts' : 'Commercial Display / Accessories', 'vrf,heating' : 'HVAC, ESS / VRF & HVAC, ESS / Heating', 'điều hòa trung tâm vrf' : 'HVAC, ESS / VRF', 'inne' : 'others', '98uh5e' : 'Commercial Display', 'khác' : 'others', 'lg salang air solution for dream homes' : 'HVAC, ESS / AC', 'rac single cac' : 'HVAC, ESS / AC', 'آخر' : 'none', 'multi-split,single-split' : 'HVAC, ESS / Multi-Split & HVAC, ESS / Single-Split', 'vrf,multi-split,etc.' : 'HVAC, ESS / VRF & HVAC, ESS / Multi-Split', 'vrf,multi-split,heating' : 'HVAC, ESS / VRF & HVAC, ESS / Multi-Split & HVAC, ESS / Heating', 'vrf,single-split,chiller' : 'HVAC, ESS / VRF & HVAC, ESS / Single-Split & HVAC, ESS / Chiller', 'commercial tv,solar,ess,projector,system ac,tv,washing machine,home beauty,audio / video' : 'Commercial Display / commercial tv & Commercial Display & solar & ess & IT PRODUCTS / Projector & HVAC, ESS / AC & Home Appliances / Washing Machine & Home Appliances / Home Beauty & Commercial Display / AV', 'solar,robot' : 'solar & Robot', 'pantalla led outdoor' : 'Commercial Display / LED Signage', 'monitor signage,commercial tv,monior / monitor tv,pc,projector,tv,audio / video' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / pc & IT PRODUCTS / Projector & Commercial Display / AV', 'not specified' : 'none', 'lg led bloc' : 'Commercial Display / LED Signage', 'solar,energy storage system' : 'solar & ess', 'system ac,solar' : '냉HVAC, ESS / AC & solar', 'solar,system ac,water care' : 'solar & HVAC, ESS / AC & Home Appliances / Water Care', '55svh7f-a' : 'Commercial Display', 'tr3' : 'Commercial Display', 'uh' : 'Commercial Display', 'laec015-gn.awz' : 'Commercial Display / LED Signage', '49vl5g-m' : 'Commercial Display / Video Wall Signage', 'chiller,dryer' : 'HVAC, ESS / Chiller & Home Appliances / Dryer', 'monitor signage,monior / monitor tv,system ac,vacuum cleaner,tv,home beauty,commercial tv,mobile,audio' : 'Commercial Display / commercial tv & Commercial Display & HVAC, ESS / AC & Home Appliances / Vacuum Cleaner & Home Appliances / Home Beauty & mobile & Commercial Display / AV', 'videwall' : 'Commercial Display / Video Wall Signage', 'solar,vacuum cleaner' : 'solar & Home Appliances / Vacuum Cleaner', 'solar,monior / monitor tv,pc,tv,refrigerator,washing machine,dryer,home beauty' : 'solar & Commercial Display & IT PRODUCTS / pc & Home Appliances / Refrigerator & Home Appliances & Home Appliances / Washing Machine & Home Appliances / Dryer & Home Appliances / Home Beauty', 'monitor signage,solar,robot,water care' : 'Commercial Display & solar & Robot & Home Appliances / Water Care', 'mobile,audio / video' : 'mobile & Commercial Display / AV',\n",
    " 'system ac,refrigerator,washing machine,dryer' : 'HVAC, ESS / AC & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Dryer', 'solar,system ac,aircare' : 'solar & HVAC, ESS / AC & Home Appliances / Aircare', 'projector,system ac,water care' : 'IT PRODUCTS / Projector & HVAC, ESS / AC & Home Appliances / Water Care', 'monior / monitor tv,tv,commercial tv,pc,refrigerator,solar,rac,washing machine,mobile,ess,audio / video' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / pc & Home Appliances / Refrigerator & solar & HVAC, ESS / AC & Home Appliances / Washing Machine & mobile & ess & Commercial Display / AV', 'ess,chiller' : 'ess & HVAC, ESS / Chiller', 'monitor signage,monior / monitor tv,pc,tv' : 'Commercial Display & IT PRODUCTS / pc', 'solar,water care' : 'solar & Home Appliances / Water Care', 'monitor signage,commercial tv,monior / monitor tv,tv' : 'Commercial Display / commercial tv & Commercial Display', 'monitor signage,commercial tv,audio / video' : 'Commercial Display / commercial tv & Commercial Display & Commercial Display / AV', 'solar,built-in / cooking' : 'solar & Home Appliances / Built-in, Cooking', 'monitor signage,monior / monitor tv,commercial tv' : 'Commercial Display / commercial tv & Commercial Display', 'robot,system ac' : 'Robot & HVAC, ESS / AC', 'medical- surgical' : 'IT PRODUCTS / Medical Display', 'radiology displays' : 'IT PRODUCTS / Medical Display', 'high inch 86  /  98 or 110' : 'Commercial Display', 'dryer,chiller' : 'Home Appliances / Dryer & HVAC, ESS / Chiller', 'solar,dryer' : 'solar & Home Appliances / Dryer', 'chiller / enfriadoras' : 'HVAC, ESS / Chiller & HVAC, ESS / AC', 'refrigerator' : 'Home Appliances / Refrigerator', 'led aio 136' : 'Commercial Display / LED Signage', '110 + video wall' : 'Commercial Display / Video Wall Signage', 'videowall signage' : 'Commercial Display / Video Wall Signage', 'one:quick flex' : 'Commercial Display / One:Quick Series', 'collaboration displays' : 'Commercial Display', 'meeting & screen sharedirect view leddirect view led' : 'Commercial Display / LED Signage', 'one quick works' : 'Commercial Display / One:Quick Series', 'pendingin' : 'HVAC, ESS / AC', 'lg paradise air solution' : 'HVAC, ESS', 'פיצול מרובה' : 'HVAC, ESS / Multi-Split', 'אחר' : 'others', 'vrf,multi-split,chiller' : 'HVAC, ESS / VRF & HVAC, ESS / Multi-Split & HVAC, ESS / Chiller', 'system ac,solar,washing machine' : 'HVAC, ESS / AC & solar & Home Appliances / Washing Machine', 'solar,ess,ems' : 'solar & ess & ems', 'tv,mobile' : 'Commercial Display & mobile', 'aircare,water care' : 'Home Appliances / Aircare & Home Appliances / Water Care', 'monior / monitor tv,chiller' : 'Commercial Display & HVAC, ESS / Chiller', 'system ac,tv' : 'HVAC, ESS / AC & Commercial Display', 'monitor signage,commercial tv,solar,ess' : 'Commercial Display / commercial tv & Commercial Display & solar & ess', 'monior / monitor tv,system ac,tv,refrigerator,washing machine,dryer,built-in / cooking' : 'Commercial Display & HVAC, ESS / AC & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Dryer & Home Appliances / Built-in, Cooking', 'monitor signage,solar' : 'Commercial Display & solar', 'pc,washing machine' : 'IT PRODUCTS / pc & Home Appliances / Washing Machine', 'monitor signage,solar,monior / monitor tv,pc,projector,robot,system ac,tv,refrigerator,washing machine' : 'Commercial Display & solar & IT PRODUCTS / pc & IT PRODUCTS / Projector & Robot & HVAC, ESS / AC & Home Appliances / Refrigerator & Home Appliances / Washing Machine', 'system ac,tv,refrigerator,washing machine,built-in / cooking,audio / video' : 'HVAC, ESS / AC & Commercial Display & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Built-in, Cooking & Commercial Display / AV', 'system air conditioner,energy storage system' : 'HVAC, ESS / AC & ess', '50us660h0sd.bwz' : 'Commercial Display / LED Signage', 'tv 60\"' : 'Commercial Display', 'medical monitor' : 'IT PRODUCTS / Medical Display', 'aircare,mobile' : 'Home Appliances / Aircare & mobile', 'solar,ess,system ac' : 'solar & ess & HVAC, ESS / AC', 'tv,pc' : 'Commercial Display & IT PRODUCTS / pc', 'monitor signage,commercial tv,solar,pc,projector,system ac,ems,rac,chiller,refrigerator,washing mach' : 'Commercial Display / commercial tv & Commercial Display & solar & IT PRODUCTS / pc & IT PRODUCTS / Projector & HVAC, ESS / AC & ems & HVAC, ESS / Chiller & Home Appliances / Refrigerator & Home Appliances / Washing Machine', 'chiller,refrigerator' : 'HVAC, ESS / Chiller & Home Appliances / Refrigerator', 'monitor signage,commercial tv,solar,projector,robot,chiller,refrigerator,built-in / cooking,water care' : 'Commercial Display / commercial tv & Commercial Display & solar & IT PRODUCTS / pc & IT PRODUCTS / Projector & Robot & HVAC, ESS / Chiller & Home Appliances / Refrigerator & Home Appliances / Built-in, Cooking & Home Appliances / Water Care', 'commercial tv,solar' : 'Commercial Display / commercial tv & solar', 'monior / monitor tv,projector,audio / video' : 'Commercial Display & IT PRODUCTS / Projector & Commercial Display / AV', 'unitario' : 'none', 'refrigerator,chiller' : 'Home Appliances / Refrigerator & HVAC, ESS / Chiller', 'chiller,tv' : 'HVAC, ESS / Chiller & Commercial Display', 'projector,ems' : 'IT PRODUCTS / Projector & ems', 'cac' : 'HVAC, ESS', 'single package' : 'HVAC, ESS / Single-Split', 'monitor signage,mobile' : 'Commercial Display & mobile', 'robot,vacuum cleaner' : 'Robot & Home Appliances / Vacuum Cleaner', 'monitor signage,commercial tv,monior / monitor tv,audio / video' : 'Commercial Display / commercial tv & Commercial Display & Commercial Display / AV', 'aircare,built-in / cooking' : 'Home Appliances / Aircare & Home Appliances / Built-in, Cooking', '49uh  /  49xf' : 'Commercial Display', '43uq751c0sb.bwz' : 'Commercial Display / Hotel TV', '32  /  43 pol' : 'Commercial Display', 'monior / monitor tv,audio / video' : 'Commercial Display & Commercial Display / AV', 'system ac,home beauty' : 'HVAC, ESS / AC & Home Appliances / Home Beauty', 'information display,monitor' : 'Commercial Display', 'taa lcd lfd displays' : 'Commercial Display', 'rac / cac' : 'HVAC, ESS / AC', 'حلول التدفئة' : 'HVAC, ESS / Heating', 'aio | one quick' : 'Commercial Display / One:Quick Series', 'monior / monitor tv,refrigerator' : 'Commercial Display & Home Appliances / Refrigerator', 'monior / monitor tv,system ac,tv,pc,refrigerator,water care,solar,washing machine,mobile,chiller,built' : 'Commercial Display & HVAC, ESS / AC & IT PRODUCTS / pc & Home Appliances / Refrigerator & Home Appliances / Water Care & solar & Home Appliances / Washing Machine & mobile & HVAC, ESS / Chiller & Home Appliances / Built-in, Cooking', 'projector,audio / video' : 'IT PRODUCTS / Projector & Commercial Display / AV', 'monitor signage,commercial tv,monior / monitor tv,pc,tv,home beauty,audio / video' : 'Commercial Display / commercial tv & Commercial Display & IT PRODUCTS / pc & Home Appliances / Home Beauty & Commercial Display / AV', '49vl5g-m.awzm' : 'Commercial Display / Video Wall Signage', 'pc,robot,system ac,chiller,tv,refrigerator,washing machine,vacuum cleaner,styler,dryer,mobile,audio / ' : 'IT PRODUCTS / pc & Robot & HVAC, ESS / AC & HVAC, ESS / Chiller & Commercial Display & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Vacuum Cleaner & Home Appliances / Dryer & Home Appliances / Styler & mobile & HVAC, ESS / AC', 'refrigerator,washing machine,built-in / cooking' : 'Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Built-in, Cooking', 'monitor signage,monior / monitor tv,tv,audio / video' : 'Commercial Display & Commercial Display / AV', 'tv,refrigerator,washing machine,vacuum cleaner,audio / video' : 'Commercial Display & Home Appliances / Refrigerator & Home Appliances / Washing Machine & Home Appliances / Vacuum Cleaner & HVAC, ESS / AC', 'pc,tv' : 'IT PRODUCTS / pc & Commercial Display', 'system ac' : 'HVAC, ESS / AC', 'sac' : 'HVAC, ESS / AC', 'gscd046' : 'Commercial Display / LED Signage', '43uh5f-h.awzm' : 'Commercial Display', 'monior / monitor tv,refrigerator,audio / video' : 'Commercial Display & Home Appliances / Refrigerator & Commercial Display / AV'\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "1154128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['product_category'] = df_train['product_category'].map(product_dict)\n",
    "df_test['product_category'] = df_test['product_category'].map(product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "137f5943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18112"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_category'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128d5936",
   "metadata": {},
   "source": [
    "### ***modelname 존재 -> category null 값 / 결측치 대체***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "01a8b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict ={\n",
    "    'LG SuperSign CMS' : 'Commercial Display / Software Solution',    '55CT5WJ,43HT3WJ' : 'Commercial Display / Interactive signage',    '55CT5WJ,43HT3WJ,SC-00DA' : 'Commercial Display / Interactive signage & Commercial Display / One:Quick Series',    'SC-00DA' : 'Commercial Display / One:Quick Series',    '43HT3WJ' : 'Commercial Display / Interactive signage',    '27BN85U' : 'IT PRODUCTS / Monitor',    'CL600' : 'IT PRODUCTS / Cloud Device',    '55CT5WJ' : 'Commercial Display / Interactive signage',    '32BP95E' : 'IT PRODUCTS / Monitor',    '31HN713D' : 'IT PRODUCTS / Medical Display',    '21HQ513D' : 'IT PRODUCTS / Medical Display',    'UltraFine Ergo(32UN880)' : 'IT PRODUCTS / Monitor',    'Ergo Dual(27QP88D)' : 'IT PRODUCTS / Monitor',    '34WN780, 28MQ780' : 'IT PRODUCTS / Monitor',    '32UN880' : 'IT PRODUCTS / Monitor',    '38CL950' : 'IT PRODUCTS / Cloud Device',    '65EP5G OLED Pro' : 'Commercial Display / OLED Signage',    '32HL512D' : 'IT PRODUCTS / Medical Display',    '19HK312C' : 'IT PRODUCTS / Medical Display',    '38CL950P' : 'IT PRODUCTS / Cloud Device',    'BU60' : 'IT PRODUCTS / Projector',    'AI/Machine Learning | Antennas, Transmitters and Towers | Audience Measurement | Cameras and Lenses' : '',    'UltraWide Ergo(34WN780)' : 'IT PRODUCTS / Monitor',    '28MQ780' : 'IT PRODUCTS / Monitor',    'DualUp(28MQ780)' : 'IT PRODUCTS / Monitor',    '34WN780' : 'IT PRODUCTS / Monitor',    '27HJ713C' : 'IT PRODUCTS / Medical Display',    'BU50N' : 'IT PRODUCTS / Projector',    '17Z90P' : 'IT PRODUCTS / Laptop',    '24CN670N-6N' : 'IT PRODUCTS / Cloud Device'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "49240525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:00, 412.39it/s]\n"
     ]
    }
   ],
   "source": [
    "product_dict_key = product_dict.keys()\n",
    "product_dict_value = product_dict.values()\n",
    "\n",
    "for i, val in tqdm(enumerate(product_dict_key)):\n",
    "    df_train.loc[df_train['product_modelname'] == val, 'product_category'] = product_dict[val]\n",
    "    df_test.loc[df_test['product_modelname'] == val, 'product_category'] = product_dict[val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ae91c",
   "metadata": {},
   "source": [
    "### ***subcategory 존재 -> category null 값 / 결측치 대체***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "a69f5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict ={\n",
    "    'All Monitors' : 'IT PRODUCTS / Monitor',    'Diagnostic Monitors' : 'IT PRODUCTS / Medical Display',    'Thin Clients' : 'IT PRODUCTS',    'Digital X-ray Detectors' : 'IT PRODUCTS / Medical Display',    'Zero Clients' : 'IT PRODUCTS / Cloud Device',    'All Medical Display' : 'IT PRODUCTS / Medical Display',    'UHD 4K Monitors' : 'IT PRODUCTS / Monitor',    'Clinical Review Monitors' : 'IT PRODUCTS / Medical Display',    'Surgical Monitors' : 'IT PRODUCTS / Medical Display',    '其他' : 'others',    'All Monitors & PCs' : 'IT PRODUCTS / Monitor',    'Laptops' : 'IT PRODUCTS / Laptop',    'IPS Monitors' : 'IT PRODUCTS / Monitor',    'จอภาพสำหรับการตรวจสอบทางคลินิก' : 'IT PRODUCTS / Medical Display',    'All Medical Displays' : 'IT PRODUCTS / Medical Display',    'ProBeam' : 'IT PRODUCTS / Projector',    'Other' : 'others',    'All Cloud Devices' : 'IT PRODUCTS / Cloud Device',    'Digital Signage or Commercial TVs' : 'Commercial Display / Digital Signage',    'Category' : 'Category',    'All Projectors' : 'IT PRODUCTS / Projector',    'Monitors with USB-C connection' : 'IT PRODUCTS / Monitor',    'Monitors for graphics applications & video editing' : 'IT PRODUCTS / Monitor',    'Channel Partner done FTS Details in System' : 'Channel Partner done FTS Details in System',    'Others' : 'others',    'Ergonomic monitors' : 'IT PRODUCTS / Monitor',    'UltraWide™ Monitors' : 'IT PRODUCTS / Monitor',    'Todo Medical Display' : 'IT PRODUCTS / Medical Display',    'TV Monitors' : 'IT PRODUCTS / Monitor',    'จอภาพเพื่อการวินิจฉัย' : 'Medical Display'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "a6c0ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:00, 403.79it/s]\n"
     ]
    }
   ],
   "source": [
    "product_dict_key = product_dict.keys()\n",
    "product_dict_value = product_dict.values()\n",
    "\n",
    "for i, val in tqdm(enumerate(product_dict_key)):\n",
    "    df_train.loc[df_train['product_subcategory'] == val, 'product_category'] = product_dict[val]\n",
    "    df_test.loc[df_test['product_subcategory'] == val, 'product_category'] = product_dict[val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1022f65",
   "metadata": {},
   "source": [
    "결측치에 business_unit 정보 포함시켜주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "b2f68023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['product_category'] = df_train['product_category'].fillna('Unknown')\n",
    "df_test['product_category'] = df_test['product_category'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "d127722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['product_category']=='Unknown')& (df_train['business_unit']=='ID'),'product_category']='ID_unknown'\n",
    "df_train.loc[(df_train['product_category']=='Unknown')& (df_train['business_unit']=='IT'),'product_category']='IT_unknown'\n",
    "df_train.loc[(df_train['product_category']=='Unknown')& (df_train['business_unit']=='AS'),'product_category']='AS_unknown'\n",
    "\n",
    "df_test.loc[(df_test['product_category']=='Unknown')& (df_test['business_unit']=='ID'),'product_category']='ID_unknown'\n",
    "df_test.loc[(df_test['product_category']=='Unknown')& (df_test['business_unit']=='IT'),'product_category']='IT_unknown'\n",
    "df_test.loc[(df_test['product_category']=='Unknown')& (df_test['business_unit']=='AS'),'product_category']='AS_unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12b70c",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14113407",
   "metadata": {},
   "source": [
    "## ***16. product_subcategory***\n",
    "요청 제품 하위 카테고리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "78258412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47982"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_subcategory'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "a6e3ab26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_subcategory'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "13c828b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['product_subcategory'].fillna(df_train['product_category'], inplace=True)\n",
    "df_test['product_subcategory'].fillna(df_test['product_category'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c3106",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133140cb",
   "metadata": {},
   "source": [
    "## ***17. product_modelname***\n",
    "요청 제품 모델명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "3df9e41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47966"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_modelname'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "b8a23694",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_modelname'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "3e2c2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['product_modelname'].fillna(df_train['product_subcategory'], inplace=True)\n",
    "df_test['product_modelname'].fillna(df_test['product_subcategory'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e836bb",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41130aa",
   "metadata": {},
   "source": [
    "## ***18. customer_country.1***\n",
    "담당 자사 법인명 기반의 지역 정보(대륙)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "f4c21333",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df_raw[~df_raw['customer_country'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "fe506ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tmp_df['customer_country'] == tmp_df['customer_country.1']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f80cb1",
   "metadata": {},
   "source": [
    "아예 같은 컬럼이기 때문에 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "3e2d6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns='customer_country.1')\n",
    "df_test = df_test.drop(columns='customer_country.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388e41d",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde36954",
   "metadata": {},
   "source": [
    "## ***19. customer_position***\n",
    "고객의 회사 직책"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "bb7a736a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_position'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "2b611bfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_position'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5aab6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manager\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"manage\", case=False, na=False), 'customer_position'] = 'manager'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"manage\", case=False, na=False), 'customer_position'] = 'manager'\n",
    "\n",
    "# ceo/founder\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"ceo\", case=False, na=False), 'customer_position'] = 'ceo/founder'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"ceo\", case=False, na=False), 'customer_position'] = 'ceo/founder'\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"founder\", case=False, na=False), 'customer_position'] = 'ceo/founder'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"founder\", case=False, na=False), 'customer_position'] = 'ceo/founder'\n",
    "\n",
    "# other\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"other\", case=False, na=False), 'customer_position'] = 'other'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"other\", case=False, na=False), 'customer_position'] = 'other'\n",
    "\n",
    "# director\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"director\", case=False, na=False), 'customer_position'] = 'director'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"director\", case=False, na=False), 'customer_position'] = 'director'\n",
    "\n",
    "# associate/analyst\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"associate\", case=False, na=False), 'customer_position'] = 'associate/analyst'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"associate\", case=False, na=False), 'customer_position'] = 'associate/analyst'\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"analyst\", case=False, na=False), 'customer_position'] = 'associate/analyst'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"analyst\", case=False, na=False), 'customer_position'] = 'associate/analyst'\n",
    "\n",
    "# partner\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"partner\", case=False, na=False), 'customer_position'] = 'partner'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"partner\", case=False, na=False), 'customer_position'] = 'partner'\n",
    "\n",
    "# entrylevel\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"entrylevel\", case=False, na=False), 'customer_position'] = 'entry level'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"entrylevel\", case=False, na=False), 'customer_position'] = 'entry level'\n",
    "\n",
    "# trainee\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"train\", case=False, na=False), 'customer_position'] = 'trainee'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"train\", case=False, na=False), 'customer_position'] = 'trainee'\n",
    "\n",
    "# c-level executive\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"executive\", case=False, na=False), 'customer_position'] = 'c-level executive'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"executive\", case=False, na=False), 'customer_position'] = 'c-level executive'\n",
    "\n",
    "# vice president\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"vicepresident\", case=False, na=False), 'customer_position'] = 'vice president'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"vicepresident\", case=False, na=False), 'customer_position'] = 'vice president'\n",
    "\n",
    "# intern\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"intern\", case=False, na=False), 'customer_position'] = 'intern'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"intern\", case=False, na=False), 'customer_position'] = 'intern'\n",
    "\n",
    "# end-user\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"end-user\", case=False, na=False), 'customer_position'] = 'end-user'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"end-user\", case=False, na=False), 'customer_position'] = 'end-user'\n",
    "\n",
    "# consultant\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"consult\", case=False, na=False), 'customer_position'] = 'consultant'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"consult\", case=False, na=False), 'customer_position'] = 'consultant'\n",
    "\n",
    "# manufacturer\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"manufacturer\", case=False, na=False), 'customer_position'] = 'manufacturer'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"manufacturer\", case=False, na=False), 'customer_position'] = 'manufacturer'\n",
    "\n",
    "# assistant professor\n",
    "df_train.loc[df_train['customer_position'].str.contains(\"assistant\", case=False, na=False), 'customer_position'] = 'assistant professor'\n",
    "df_test.loc[df_test['customer_position'].str.contains(\"assistant\", case=False, na=False), 'customer_position'] = 'assistant professor'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513ece7",
   "metadata": {},
   "source": [
    "117->90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "e10615ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_position'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f44706",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6db15",
   "metadata": {},
   "source": [
    "## ***20. response_corporate***\n",
    "담당 자사 법인명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "336ad0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['response_corporate'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "edea9a80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LGEIN', 'LGEUS', 'LGEDG', 'LGESL', 'LGEIL', 'LGEES', 'LGEIS',\n",
       "       'LGESJ', 'LGEMS', 'LGEVH', 'LGESP', 'LGEPL', 'LGEHK', 'LGECL',\n",
       "       'LGEAS', 'LGEPH', 'LGEPS', 'LGEGF', 'LGEFS', 'LGEEG', 'LGEMK',\n",
       "       'LGEKR', 'LGECB', 'LGEUK', 'LGESA', 'LGEAF', 'LGEAP', 'LGECI',\n",
       "       'LGEML', 'LGEPT', 'LGEBN', 'LGECZ', 'LGEPR', 'LGEHS', 'LGETK',\n",
       "       'LGELF', 'LGETH', 'LGEAR', 'LGEYK', 'LGETT', 'LGEEF', 'LGESW',\n",
       "       'LGEMC', 'LGECH', 'LGERO', 'LGEEB', 'LGEJP', 'LGEAG', 'LGERA',\n",
       "       'LGELA', 'LGEBT', 'LGEUR', 'LGEIR'], dtype=object)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['response_corporate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1956de",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a897d",
   "metadata": {},
   "source": [
    "## ***21. expected_timeline***\n",
    "고객의 요청한 처리 일정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "431a4a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29270"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['expected_timeline'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "7fd43652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['expected_timeline'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "585bf6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#less than 3 months\n",
    "df_train.loc[df_train['expected_timeline'] == \"less_than_3_months\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"less than 3 months. customer not answered . to call back\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"duplicate lead - il220100042906. less than 3 months\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"less than 3 months- outdoor led requiment\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"3 months\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"less than 3 months ,meeting with the customer for the more details and tentative boq will ne 32 and 43\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"4/8 months\", 'expected_timeline'] = \"less than 3 months\"\n",
    "\n",
    "#3 months ~ 6 months\n",
    "df_train.loc[df_train['expected_timeline'] == \"less than 6 months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"3_months_~_6_months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"more then 3 months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"less then 6 months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"less than 5 months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "\n",
    "#6 months ~ 9 months\n",
    "df_train.loc[df_train['expected_timeline'] == \"6_months_~_9_months\", 'expected_timeline'] = \"6 months ~ 9 months\"\n",
    "\n",
    "#9 months ~ 1 year\n",
    "df_train.loc[df_train['expected_timeline'] == \"9_months_~_1_year\", 'expected_timeline'] = \"9 months ~ 1 year\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"9 months - 1 year\", 'expected_timeline'] = \"9 months ~ 1 year\"\n",
    "\n",
    "#more than a year\n",
    "df_train.loc[df_train['expected_timeline'] == \"more_than_a_year\", 'expected_timeline'] = \"more than a year\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"more_than_a_year\", 'expected_timeline'] = \"more than a year\"\n",
    "\n",
    "#df_test\n",
    "df_test.loc[df_test['expected_timeline'] == \"less_than_3_months\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"less than 3 months. customer not answered . to call back\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"duplicate lead - il220100042906. less than 3 months\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"less than 3 months- outdoor led requiment\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"3 months\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"less than 3 months ,meeting with the customer for the more details and tentative boq will ne 32 and 43\", 'expected_timeline'] = \"less than 3 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"4/8 months\", 'expected_timeline'] = \"less than 3 months\"\n",
    "\n",
    "df_test.loc[df_test['expected_timeline'] == \"less than 6 months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"3_months_~_6_months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"more then 3 months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"less then 6 months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"less than 5 months\", 'expected_timeline'] = \"3 months ~ 6 months\"\n",
    "\n",
    "df_test.loc[df_test['expected_timeline'] == \"6_months_~_9_months\", 'expected_timeline'] = \"6 months ~ 9 months\"\n",
    "\n",
    "df_test.loc[df_test['expected_timeline'] == \"9_months_~_1_year\", 'expected_timeline'] = \"9 months ~ 1 year\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"9 months - 1 year\", 'expected_timeline'] = \"9 months ~ 1 year\"\n",
    "\n",
    "df_test.loc[df_test['expected_timeline'] == \"more_than_a_year\", 'expected_timeline'] = \"more than a year\"\n",
    "df_test.loc[df_test['expected_timeline'] == \"more_than_a_year\", 'expected_timeline'] = \"more than a year\"\n",
    "\n",
    "df_train.loc[df_train['expected_timeline'] == \"being followed up\", 'expected_timeline'] = \"being followed up\"\n",
    "df_train.loc[df_train['expected_timeline'] == \"being followed up.\", 'expected_timeline'] = \"being followed up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "fc9fe98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#처리완료가 아닌 것 및 결측치 처리\n",
    "timeline = ['less than 3 months', '3 months ~ 6 months', '6 months ~ 9 months', '9 months ~ 1 year', 'more than a year']\n",
    "df_train['expected_timeline'] = df_train['expected_timeline'].fillna(\"incomplete\")\n",
    "timeline.append(\"incomplete\")\n",
    "df_train.loc[~df_train['expected_timeline'].isin(timeline), \"expected_timeline\"] = \"etc\"\n",
    "\n",
    "df_test['expected_timeline'] = df_test['expected_timeline'].fillna(\"incomplete\")\n",
    "df_test.loc[~df_test['expected_timeline'].isin(timeline), \"expected_timeline\"] = \"etc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37237891",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe84966",
   "metadata": {},
   "source": [
    "## ***22. ver_cus***\n",
    "특정 Vertical Level 1(사업영역) 이면서 Customer_type(고객 유형)이 소비자(End-user)인 경우에 대한 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "a4bd7251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_cus'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "6c37115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ver_cus\n",
       "0    54652\n",
       "1     2387\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_cus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "d9cbcb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['corporate / office', 'education', 'retail',\n",
       "       'hotel & accommodation'], dtype=object)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['ver_cus']==1]['business_area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "b914129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['End-Customer'], dtype=object)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['ver_cus']==1]['customer_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7d06a",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d804120",
   "metadata": {},
   "source": [
    "## ***23. ver_pro***\n",
    "특정 Vertical Level 1(사업영역) 이면서 특정 Product Category(제품 유형)인 경우에 대한 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "ce529654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_pro'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "bfa39cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ver_pro\n",
       "0    54102\n",
       "1     2937\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_pro'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b1b4e01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['retail', 'corporate / office', 'hotel & accommodation'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['ver_pro']==1]['business_area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "0cd3579a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Commercial Display / OLED Signage',\n",
       "       'Commercial Display / LED Signage',\n",
       "       'Commercial Display / Interactive Signage',\n",
       "       'Commercial Display / Hotel TV',\n",
       "       'Commercial Display / Video Wall Signage',\n",
       "       'Commercial Display / Standard Signage',\n",
       "       'Commercial Display / High Brightness Signage',\n",
       "       'Commercial Display / Special Signage', 'Unknown',\n",
       "       'Commercial Display / Signage Care Solution',\n",
       "       'Commercial Display / Digital Signage', 'Commercial Display'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['ver_pro']==1]['product_category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8c578",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c401fc",
   "metadata": {},
   "source": [
    "## ***24. ver_win_rate_x***\n",
    "전체 Lead 중에서 Vertical을 기준으로 Vertical 수 비율과 Vertical 별 Lead 수 대비 영업 전환 성공 비율 값을 곱한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "d4a47e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39152"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_win_rate_x'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "6ebc066f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ver_win_rate_x\n",
       "0.003079    4013\n",
       "0.001183    2941\n",
       "0.000717    1966\n",
       "0.000543    1886\n",
       "0.000298    1800\n",
       "0.000572    1693\n",
       "0.000060    1024\n",
       "0.000215    1018\n",
       "0.000097     635\n",
       "0.000026     508\n",
       "0.000013     293\n",
       "0.000002     110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_win_rate_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "6b4d51a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ver_win_rate_x  business_unit  business_area                 \n",
       "0.000002        AS             power plant / renewable energy      59\n",
       "                ID             power plant / renewable energy      43\n",
       "                IT             power plant / renewable energy       8\n",
       "0.000013        ID             transportation                     209\n",
       "                AS             transportation                      52\n",
       "                IT             transportation                      28\n",
       "                Solution       transportation                       4\n",
       "0.000026        ID             public facility                    265\n",
       "                AS             public facility                    195\n",
       "                IT             public facility                     40\n",
       "                Solution       public facility                      8\n",
       "0.000060        IT             hospital & health care             741\n",
       "                AS             hospital & health care             152\n",
       "                ID             hospital & health care             131\n",
       "0.000097        ID             government department              411\n",
       "                AS             government department              170\n",
       "                IT             government department               47\n",
       "                Solution       government department                7\n",
       "0.000215        ID             factory                            533\n",
       "                AS             factory                            398\n",
       "                IT             factory                             78\n",
       "                Solution       factory                              9\n",
       "0.000298        AS             residential (home)                1355\n",
       "                ID             residential (home)                 379\n",
       "                IT             residential (home)                  40\n",
       "                Solution       residential (home)                  26\n",
       "0.000543        ID             special purpose                   1043\n",
       "                AS             special purpose                    704\n",
       "                IT             special purpose                    106\n",
       "                Solution       special purpose                     33\n",
       "0.000572        ID             education                         1334\n",
       "                AS             education                          207\n",
       "                IT             education                          141\n",
       "                Solution       education                           11\n",
       "0.000717        ID             hotel & accommodation              939\n",
       "                IT             hotel & accommodation              789\n",
       "                AS             hotel & accommodation              207\n",
       "                Solution       hotel & accommodation               31\n",
       "0.001183        ID             retail                            1972\n",
       "                AS             retail                             781\n",
       "                IT             retail                             156\n",
       "                Solution       retail                              32\n",
       "0.003079        ID             corporate / office                2408\n",
       "                AS             corporate / office                1251\n",
       "                IT             corporate / office                 325\n",
       "                Solution       corporate / office                  29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('ver_win_rate_x')[['business_unit','business_area']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c161eb66",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a164a",
   "metadata": {},
   "source": [
    "## ***25. ver_win_ratio_per_bu***\n",
    "특정 Vertical Level1의 Business Unit 별 샘플 수 대비 영업 전환된 샘플 수의 비율을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "b713c6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42071"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_win_ratio_per_bu'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "c8a4e91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ver_win_ratio_per_bu\n",
       "0.064566    2408\n",
       "0.049840    1972\n",
       "0.020121    1355\n",
       "0.048630    1334\n",
       "0.026846    1251\n",
       "0.064070    1043\n",
       "0.071345     939\n",
       "0.011583     781\n",
       "0.022634     704\n",
       "0.060924     533\n",
       "0.079412     411\n",
       "0.036913     398\n",
       "0.035484     379\n",
       "0.031579     265\n",
       "0.053571     209\n",
       "0.051471     207\n",
       "0.028777     195\n",
       "0.022727     170\n",
       "0.128571     152\n",
       "0.131148     131\n",
       "0.227273      59\n",
       "0.285714      43\n",
       "0.034483      29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_win_ratio_per_bu'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "57c86a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ver_win_ratio_per_bu  business_unit  business_area                 \n",
       "0.011583              AS             retail                             781\n",
       "0.020121              AS             residential (home)                1355\n",
       "0.022634              AS             special purpose                    704\n",
       "0.022727              AS             government department              170\n",
       "0.026846              AS             corporate / office                1251\n",
       "0.028777              AS             public facility                    195\n",
       "0.031579              ID             public facility                    265\n",
       "0.034483              Solution       corporate / office                  29\n",
       "0.035484              ID             residential (home)                 379\n",
       "0.036913              AS             factory                            398\n",
       "0.048630              ID             education                         1334\n",
       "0.049840              ID             retail                            1972\n",
       "0.051471              AS             education                          207\n",
       "0.053571              ID             transportation                     209\n",
       "0.060924              ID             factory                            533\n",
       "0.064070              ID             special purpose                   1043\n",
       "0.064566              ID             corporate / office                2408\n",
       "0.071345              ID             hotel & accommodation              939\n",
       "0.079412              ID             government department              411\n",
       "0.128571              AS             hospital & health care             152\n",
       "0.131148              ID             hospital & health care             131\n",
       "0.227273              AS             power plant / renewable energy      59\n",
       "0.285714              ID             power plant / renewable energy      43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('ver_win_ratio_per_bu')[['business_unit','business_area']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e533f8a",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed18ac",
   "metadata": {},
   "source": [
    "## ***26. business_area***\n",
    "고객의 사업 영역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "3383116e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39152"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['business_area'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "27336f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_area\n",
       "corporate / office                4013\n",
       "retail                            2941\n",
       "hotel & accommodation             1966\n",
       "special purpose                   1886\n",
       "residential (home)                1800\n",
       "education                         1693\n",
       "hospital & health care            1024\n",
       "factory                           1018\n",
       "government department              635\n",
       "public facility                    508\n",
       "transportation                     293\n",
       "power plant / renewable energy     110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['business_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "c17ed518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Business_Area 결측치 처리\n",
    "df_train['business_area'] = df_train['business_area'].fillna(\"Not entered\")\n",
    "df_test['business_area'] = df_test['business_area'].fillna(\"Not entered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f8078",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d1ddc",
   "metadata": {},
   "source": [
    "## ***27. business_subarea***\n",
    "고객의 세부 사업 영역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "11d86d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51838"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['business_subarea'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "04503a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_subarea\n",
       "Others                           1587\n",
       "Other Stores                      271\n",
       "Hospital                          246\n",
       "Manufacturing Factory / Plant     192\n",
       "Construction                      182\n",
       "                                 ... \n",
       "Duty Free Shop                      2\n",
       "Casino Resort                       1\n",
       "Travel Agency                       1\n",
       "Holdings                            1\n",
       "Dormitory                           1\n",
       "Name: count, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['business_subarea'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "4e83b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Business_Subarea 결측치 처리\n",
    "df_train['business_subarea'] = df_train['business_subarea'].fillna(\"Not entered\")\n",
    "df_test['business_subarea'] = df_test['business_subarea'].fillna(\"Not entered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "f64f2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Business_Subarea 건강관련 값 통일\n",
    "health = ['Hospital','General Hospital','Clinic','Healthcare']\n",
    "df_train.loc[df_train['business_subarea'].isin(health), 'business_subarea'] = \"Health\"\n",
    "df_test.loc[df_test['business_subarea'].isin(health), 'business_subarea'] = \"Health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "898b759b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업전환_확률</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_subarea</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Casino Resort</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F&amp;B(Food and Beverage)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVS (Convenience Store)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hotel</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cruise</th>\n",
       "      <td>0.645833</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duty Free Shop</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gas Station</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holdings</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistics</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welfare Facilities</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          영업전환_확률  Count\n",
       "business_subarea                        \n",
       "Casino Resort            1.000000      1\n",
       "F&B(Food and Beverage)   1.000000      2\n",
       "CVS (Convenience Store)  1.000000      2\n",
       "Hotel                    0.657143     35\n",
       "Cruise                   0.645833     48\n",
       "...                           ...    ...\n",
       "Duty Free Shop           0.000000      2\n",
       "Gas Station              0.000000      4\n",
       "Holdings                 0.000000      1\n",
       "Logistics                0.000000     14\n",
       "Welfare Facilities       0.000000      5\n",
       "\n",
       "[84 rows x 2 columns]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = pd.concat([pd.DataFrame(df_train.groupby('business_subarea')['is_converted'].mean()), pd.DataFrame(df_train.groupby('business_subarea')['is_converted'].count())], axis=1)\n",
    "tmp_df.columns = ['영업전환_확률', 'Count']\n",
    "tmp_df.sort_values('영업전환_확률', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b70df",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd2d17b",
   "metadata": {},
   "source": [
    "## ***28. lead_owner***\n",
    "영업 담당자 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "7a6189d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lead_owner'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "d93b2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lead_owner가 2개 이하일 경우 과적합 우려 있어 특정 값 대체.\n",
    "\n",
    "# tmp_lst = df_train.groupby('lead_owner')['is_converted'].count().loc[lambda x: x <= 3].index\n",
    "# df_train.loc[df_train['lead_owner'].isin(tmp_lst), 'lead_owner'] = 'Unknown'\n",
    "# df_test.loc[df_test['lead_owner'].isin(tmp_lst), 'lead_owner'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5339ed6",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f562fdf",
   "metadata": {},
   "source": [
    "## ***29. is_converted***\n",
    "영업 성공 여부. True일 시 성공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "b1281073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_converted'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "7923d06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_converted\n",
       "False    52410\n",
       "True      4629\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_converted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744f5a4",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120aa2a4",
   "metadata": {},
   "source": [
    "## ***30. expected_budget***\n",
    "고객이 희망하는 예산 범위 (텍스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "fc0f8ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33495"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['expected_budget'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2b6972c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expected_budget\n",
       "Less than $10,000                            5575\n",
       "Less than $100,000                           4272\n",
       "$10,000 ~ $50,000                            3052\n",
       "less_than_$100,000                           2453\n",
       "$100,000 ~ $500,000                          1742\n",
       "                                             ... \n",
       "More than $1,000,000;More than $1,000,000       1\n",
       "$50,000_~_$100,000                              1\n",
       "£7,000 ~ £35,000                                1\n",
       "COP 2.000.000                                   1\n",
       "cop 15.000.000 - 30.000.000                     1\n",
       "Name: count, Length: 95, dtype: int64"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['expected_budget'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "50b17f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dollar = {'COP 2.000.000' : 530,'1000' : 741,'cop 3.000.000' : 795,'700' : 884,'cop 5.000.000' : 1325,'5000' : 1332,'cop 5.000.000 - 9.000.000' : 1855,'8.000.000 cop' : 2121,'9.000.000 COP' : 2386,'10.000.000 - 20.000.000' : 3977,'less_than_£7,000' : 4400,'Less than £7,000' : 4400,'Less than $10,000' : 5000,'weniger_als_€10,000' : 5000,'menos_de_10.000€' : 5000,'less_than_$10,000' : 5000,'Menos de $10,000' : 5000,\n",
    "'Menos de 10.000€' : 5000,'Weniger als €10,000' : 5000,'Less than $10,000;Less than $10,000' : 5000,'cop 15.000.000 - 30.000.000' : 5965,'Less than IDR 155,000,000' : 9755,'$50.337.000 COP' : 13347,'Less than $50,000' : 25000,'25000 USD' : 25000,'£7,000_~_£35,000' : 26400,'£7,000 ~ £35,000' : 26400,'$10,000 ~ $50,000' : 30000,'$10,000_~_$50,000' : 30000,'€10,000_~_€50,000' : 30000,'entre_10.000€_y_50.000€' : 30000,'10.000 $ ~ 50.000 $' : 30000,'10.000€__~__50.000€' : 30000,'Entre 10.000€ y 50.000€' : 30000,'$10,000 ~ $50,000;$10,000 ~ $50,000' : 30000,\n",
    "'$50.000 - $10.000' : 30000,'30.000 $ ~ 50.000 $' : 40000,'Less than $100,000' : 50000,'less_than_$100,000' : 50000,'More than $50,000' : 50000,'Less than $123,000' : 61500,'£35,000_~_£70,000' : 66000,'$50,000 ~ $100,000' : 75000,'€50,000_~_€100,000' : 75000,'$50,000 ~ $100,000;$50,000 ~ $100,000' : 75000,'entre_50.000€_y_100.000€' : 75000,'Entre 50.000€ y 100.000€' : 75000,'$50,000_~_$100,000' : 75000,'100000 $' : 100000,'More than $100,000' : 100000,'More than $123,000' : 123000,'$100,000 ~ $200,000' : 150000,'$100,000_~_$200,000' : 150000,'£70,000_~_£350,000' : 265000,'$100,000 ~ $500,000' : 300000,'$100,000_-_$500,000' : 300000,\n",
    "'$200,000 ~ $400,000' : 300000,'$200,000_~_$400,000' : 300000,'€100,000_~_€500,000' : 300000,'R$100.000 ~ R$500.000' : 300000,'$100,000 ~ $500,000;$100,000 ~ $500,000' : 300000,'€100,000 ~ €500,000' : 300000,'$400,000 ~ $600,000' : 500000,'$400,000_~_$600,000' : 500000,'€ 5000,00' : 500000,'$600,000 ~ $800,000' : 700000,'more_than_£700,000' : 700000,'$600,000_~_$800,000' : 700000,'$500,000 ~ $1,000,000' : 750000,'$500,000_-_$1,000,000' : 750000,'€500,000_~_€1,000,000' : 750000,'entre_500.000€_y_1.000.000€' : 750000,'$500,000 to less than $1M' : 750000,'500.000€__~__1.000.000€' : 750000,'$500.000 ~ $1.000.000' : 750000,'$500,000 ~ $1,000,000;$500,000 ~ $1,000,000' : 750000,'$800,000 ~ $1,000,000' : 900000,'$800,000_~_$1,000,000' : 900000,'More than $1,000,000' : 1000000,'more_than_$1,000,000' : 1000000,'über_€1,000,000' : 1000000,'More than $1.000.000' : 1000000,'More than $1,000,000;More than $1,000,000' : 1000000,'$1M to less than $10M' : 5500000,'$10M to less than $25M' : 17500000,\n",
    "'OnGoing' : 'ongoing',\n",
    "'Ongoing' : 'ongoing',\n",
    "'On-going' : 'ongoing'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "a84d4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['to_dollar'] = df_train['expected_budget'].map(to_dollar)\n",
    "df_test['to_dollar'] = df_test['expected_budget'].map(to_dollar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "bd582890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유로 > 달러로 변환(환율 1.08이므로 거의 같다) / 파운드 > 달러로 변환(환율 1.26이므로 거의 같다)\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"€\",\"$\"))\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"£\",\"$\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"€\",\"$\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"£\",\"$\"))\n",
    "\n",
    "#문자열 통일화\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"less\",\"Less\"))\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"less\",\"Less\"))\n",
    "\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"Ongoing\",\"OnGoing\"))\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"On-going\",\"OnGoing\"))\n",
    "\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"more\",\"More\"))\n",
    "\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"_\",\" \"))\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"-\",\"~\"))\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"weniger als\",\"Less than\"))\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"menos de\",\"Less than\"))\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\".\",\",\"))\n",
    "df_train['expected_budget'] = df_train['expected_budget'].apply(lambda x : str(x).replace(\"$\",\"\"))\n",
    "\n",
    "#test\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"€\",\"$\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"€\",\"$\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"£\",\"$\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"£\",\"$\"))\n",
    "\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"less\",\"Less\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"less\",\"Less\"))\n",
    "\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"Ongoing\",\"OnGoing\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"On-going\",\"OnGoing\"))\n",
    "\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"more\",\"More\"))\n",
    "\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"_\",\" \"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"-\",\"~\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"weniger als\",\"Less than\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"menos de\",\"Less than\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\".\",\",\"))\n",
    "df_test['expected_budget'] = df_test['expected_budget'].apply(lambda x : str(x).replace(\"$\",\"\"))\n",
    "\n",
    "#동일한 unique값 처리\n",
    "df_train.loc[df_train['expected_budget']==\"500,000 ~ 1,000,000;500,000 ~ 1,000,000\",\"expected_budget\"] = \"500,000 ~ 1,000,000\"\n",
    "df_test.loc[df_test['expected_budget']==\"500,000 ~ 1,000,000;500,000 ~ 1,000,000\",\"expected_budget\"] = \"500,000 ~ 1,000,000\"\n",
    "\n",
    "df_train.loc[df_train['expected_budget']==\"More than 1,000,000;More than 1,000,000\",\"expected_budget\"] = \"More than 1,000,000\"\n",
    "df_test.loc[df_test['expected_budget']==\"More than 1,000,000;More than 1,000,000\",\"expected_budget\"] = \"More than 1,000,000\"\n",
    "\n",
    "#결측치로 판단되는 문자열 처리\n",
    "df_train.loc[df_train['expected_budget']==\"N/A;N/A\",\"expected_budget\"] = np.nan\n",
    "df_train.loc[df_train['expected_budget']==\"Don't know/Not sure\",\"expected_budget\"] = np.nan\n",
    "df_train.loc[df_train['expected_budget']==\"(Select ID_Budget)\",\"expected_budget\"] = np.nan\n",
    "df_train.loc[df_train['expected_budget']==\"no know\",\"expected_budget\"] = np.nan\n",
    "df_train.loc[df_train['expected_budget']==\"Residential (Home)\",\"expected_budget\"] = np.nan\n",
    "df_train.loc[df_train['expected_budget']==\"10,000,000 ~ 20,000,000\",\"expected_budget\"] = np.nan\n",
    "df_train.loc[df_train['expected_budget']==\"0\",\"expected_budget\"] = np.nan\n",
    "df_train.loc[df_train['expected_budget']==\"nan\",\"expected_budget\"] = np.nan\n",
    "\n",
    "df_test.loc[df_test['expected_budget']==\"N/A;N/A\",\"expected_budget\"] = np.nan\n",
    "df_test.loc[df_test['expected_budget']==\"Don't know/Not sure\",\"expected_budget\"] = np.nan\n",
    "df_test.loc[df_test['expected_budget']==\"(Select ID_Budget)\",\"expected_budget\"] = np.nan\n",
    "df_test.loc[df_test['expected_budget']==\"no know\",\"expected_budget\"] = np.nan\n",
    "df_test.loc[df_test['expected_budget']==\"Residential (Home)\",\"expected_budget\"] = np.nan\n",
    "df_test.loc[df_test['expected_budget']==\"10,000,000 ~ 20,000,000\",\"expected_budget\"] = np.nan\n",
    "df_test.loc[df_test['expected_budget']==\"0\",\"expected_budget\"] = np.nan\n",
    "df_test.loc[df_test['expected_budget']==\"nan\",\"expected_budget\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abb13c",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b0d5c",
   "metadata": {},
   "source": [
    "## ***31. lead_date***\n",
    "Lead 정보 생성일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "0390ff48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_history'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "eb4c3542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_history\n",
       "New         43953\n",
       "Existing    13086\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_history'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "fdca5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA전 datetime 컬럼 처리\n",
    "df_train['lead_date'] = pd.to_datetime(df_train['lead_date'])\n",
    "df_test['lead_date'] = pd.to_datetime(df_test['lead_date'])\n",
    "\n",
    "# datetime을 여러 파생 변수로 변환\n",
    "for df in [df_train, df_test]:\n",
    "    df['date'] = df['lead_date'].dt.date\n",
    "    #df['date_1'] = df['lead_date'].dt.date\n",
    "    df['year'] = df['lead_date'].dt.year\n",
    "    df['month'] = df['lead_date'].dt.month\n",
    "    df['day'] = df['lead_date'].dt.day\n",
    "    df['weekday'] = df['lead_date'].dt.weekday\n",
    "    \n",
    "df_train = df_train.drop(columns='date')\n",
    "df_test = df_test.drop(columns='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db96b13",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499eca6",
   "metadata": {},
   "source": [
    "## ***32. customer_history***\n",
    "이전에 Converted(영업 전환) 되었던 이력이 있는지에 대한 여부. (New / Existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "eb2bf888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_history'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "eec3d81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_history\n",
       "New         43953\n",
       "Existing    13086\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['customer_history'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b215bc24",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60dac6f",
   "metadata": {},
   "source": [
    "## ***33. lead_from_channel***\n",
    "Lead 정보가 수집된 채널 이름 (lg.com, 페이스북, 웨비나 등 다양한 채널을 통해서 수집)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "7fa29ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2840"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lead_from_channel'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "c7f32749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_from_channel\n",
       "lg.com(local)     15962\n",
       "facebook          13816\n",
       "lg.com             5711\n",
       "webinar            4877\n",
       "lg.com(global)     2958\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lead_from_channel'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "4da2bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lead_from_channel'] = df_train['lead_from_channel'].fillna('UnKnown')\n",
    "df_test['lead_from_channel'] = df_test['lead_from_channel'].fillna('UnKnown')\n",
    "\n",
    "df_train['lead_from_lg_site'] = 0\n",
    "df_test['lead_from_lg_site'] = 0\n",
    "\n",
    "df_train.loc[df_train['lead_from_channel'].str.contains('lg.com'), 'lead_from_lg_site'] = 1\n",
    "df_test.loc[df_test['lead_from_channel'].str.contains('lg.com'), 'lead_from_lg_site'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "57ee3174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_from_lg_site\n",
       "0    32408\n",
       "1    24631\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lead_from_lg_site'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8460558",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2ad1c",
   "metadata": {},
   "source": [
    "## ***34. lead_description***\n",
    "고객이 작성한 Lead Description 텍스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "8687e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28569"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lead_description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "009c6c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_description\n",
       "XXX                                                                                                                                                                                                                                                                                                                                                                               601\n",
       "XXXXX                                                                                                                                                                                                                                                                                                                                                                             306\n",
       "Price                                                                                                                                                                                                                                                                                                                                                                             191\n",
       "yes                                                                                                                                                                                                                                                                                                                                                                               191\n",
       ".                                                                                                                                                                                                                                                                                                                                                                                 166\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 ... \n",
       "Need to order parts                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "Looking to purchase an OLED for our conference room and lobby. Specifically we want a LG G2 97\" or (g3 if its available) or LG SIGNATURE 88 inch Z2 PUA 8k.  We have a $37,000 line of credit with Dell but have no LOC with LG. How can I get a LOC for business purchases - or net terms?  We are looking to purchase with debt financing for tax and depreciation purposes.      1\n",
       "Working and purchasing                                                                                                                                                                                                                                                                                                                                                              1\n",
       "1 screen                                                                                                                                                                                                                                                                                                                                                                            1\n",
       "how much is 5 zones ac \\n1.5 hp x 4\\n5 hp x 1                                                                                                                                                                                                                                                                                                                                       1\n",
       "Name: count, Length: 20084, dtype: int64"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lead_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "7c0283a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #소문자 통일화\n",
    "# df_train.loc[df_train['lead_description'].notna(),\"lead_description\"] = df_train.loc[df_train['lead_description'].notna(),\"lead_description\"].apply(lambda x : str(x).lower() if str(x).isascii() else str(x))\n",
    "# df_test.loc[df_test['lead_description'].notna(),\"lead_description\"] = df_test.loc[df_test['lead_description'].notna(),\"lead_description\"].apply(lambda x : str(x).lower() if str(x).isascii() else str(x))\n",
    "\n",
    "# #문자열 결측치 치환\n",
    "# def find_nan(x):\n",
    "#     if 'n' in x and 'a' in x:\n",
    "#         index_n = x.find('n')\n",
    "#         index_a = x.find('a')\n",
    "#         if index_n < index_a:\n",
    "#             if len(x) <= 3:\n",
    "#                 return np.nan\n",
    "#             else:\n",
    "#                 return x\n",
    "#         else:\n",
    "#             return x\n",
    "#     else:\n",
    "#         return x\n",
    "\n",
    "# df_train.loc[df_train['lead_description'].notna(),\"lead_description\"] = df_train.loc[df_train['lead_description'].notna(),\"lead_description\"].apply(find_nan)\n",
    "# df_test.loc[df_test['lead_description'].notna(),\"lead_description\"] = df_test.loc[df_test['lead_description'].notna(),\"lead_description\"].apply(find_nan)\n",
    "\n",
    "# #추가 문자열 결측치 치환\n",
    "# df_train.loc[df_train['lead_description'] == \".\",\"lead_description\"] = np.nan\n",
    "# df_train.loc[df_train['lead_description'] == \"-\",\"lead_description\"] = np.nan\n",
    "# df_train.loc[df_train['lead_description'] == \"no\",\"lead_description\"] = np.nan\n",
    "# df_train.loc[df_train['lead_description'] == \"none\",\"lead_description\"] = np.nan\n",
    "\n",
    "# df_test.loc[df_test['lead_description'] == \".\",\"lead_description\"] = np.nan\n",
    "# df_test.loc[df_test['lead_description'] == \"-\",\"lead_description\"] = np.nan\n",
    "# df_test.loc[df_test['lead_description'] == \"no\",\"lead_description\"] = np.nan\n",
    "# df_test.loc[df_test['lead_description'] == \"none\",\"lead_description\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "72766991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lead_nan'] = 0\n",
    "df_test['lead_nan'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "32377559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['lead_description'].isnull(), 'lead_nan'] = 1\n",
    "df_test.loc[df_test['lead_description'].isnull(), 'lead_nan'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "856336ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lead_real_nan'] = 0\n",
    "df_train.loc[(df_train['lead_description'].isna()==True) & (df_train['lead_desc_length']==3),'lead_real_nan'] = 1\n",
    "\n",
    "df_test['lead_real_nan'] = 0\n",
    "df_test.loc[(df_test['lead_description'].isna()==True) & (df_test['lead_desc_length']==3),'lead_real_nan'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "4deee7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dots(text):\n",
    "    if pd.notna(text):  \n",
    "        return text.count('.')\n",
    "    else:\n",
    "        return 0  \n",
    "\n",
    "# 새로운 특성 생성\n",
    "df_train['dot_count'] = df_train['lead_description'].apply(count_dots)\n",
    "df_test['dot_count'] = df_test['lead_description'].apply(count_dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "ae04d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dots(text):\n",
    "    if pd.notna(text):  \n",
    "        return text.count('?')\n",
    "    else:\n",
    "        return 0  \n",
    "\n",
    "# 새로운 특성 생성\n",
    "df_train['question_count'] = df_train['lead_description'].apply(count_dots)\n",
    "df_test['question_count'] = df_test['lead_description'].apply(count_dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "783fd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lead_small'] = 0\n",
    "df_test['lead_small'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "fcf8a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['lead_desc_length']<=10, 'lead_small'] = 1\n",
    "df_test.loc[df_test['lead_desc_length']<=10, 'lead_small'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1facdf88",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b4cfb",
   "metadata": {},
   "source": [
    "## ***35. event_name***\n",
    "영업 활동이 있었던 마케팅 이벤트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "794c0102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1111"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['event_name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "bde058a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_name\n",
       "ID_IL_Social BANT Camp_220308                                          4470\n",
       "AS_SP_LG.com_I2B_2022                                                  2370\n",
       "ID_HQ_LG.com_I2B                                                       2361\n",
       "AS_SP_Webinar_Integrated_SeminarDate(220322)_CasaConteúdo              2310\n",
       "ID_HQ_Cdisplay_I2B                                                     2194\n",
       "                                                                       ... \n",
       "ID_CL_NewsletterOLED_211216                                               1\n",
       "ID_MS_Campaign_Digital_FB_211226                                          1\n",
       "AS_IL_BusinessConnect_Integrated_14May(220506)_Mumbai_Attendee_form       1\n",
       "IT_HQ_Medical_Lead Ads_FB_UAE_22.06                                       1\n",
       "IT_Showroom_Medical(Demo Req)                                             1\n",
       "Name: count, Length: 1132, dtype: int64"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['event_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "3b33c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #이벤트별 영업전환 확률 피쳐\n",
    "# event_dict = {}\n",
    "# for i in df_train[df_train['is_converted'] == True]['event_name'].value_counts().index:\n",
    "#     분모 = len(df_train[df_train['event_name'] == i])\n",
    "#     분자 = len(df_train[(df_train['event_name'] == i) & (df_train['is_converted']== True)])\n",
    "#     print(i, '비율 :', round(분자/분모, 4))\n",
    "    \n",
    "#     event_dict[i] = round(분자/분모, 4)\n",
    "    \n",
    "# 조절 = 0\n",
    "# for k,v in event_dict.items():\n",
    "#     if len(df_train[df_train['event_name']==k]) <= 조절:\n",
    "#         event_dict[k] = 0\n",
    "        \n",
    "# df_train['event_true_ratio'] = df_train['event_name'].map(event_dict)\n",
    "# df_train['event_true_ratio'] = df_train['event_true_ratio'].fillna(0)\n",
    "\n",
    "# df_test['event_true_ratio'] = df_test['event_name'].map(event_dict)\n",
    "# df_test['event_true_ratio'] = df_test['event_true_ratio'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "e1c58ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['event_name_first_part'] = df_train['event_name'].apply(lambda x: x.split('_', 1)[0] if pd.notnull(x) else x)\n",
    "def extract_second_part(event_name):\n",
    "    if pd.isnull(event_name):\n",
    "        return event_name\n",
    "    parts = event_name.split('_', 1)\n",
    "    if len(parts) > 1:\n",
    "        second_part = re.split('_| ', parts[1], 1)[0]\n",
    "        return second_part\n",
    "    return None\n",
    "\n",
    "# df_train['event_name_second_part'] = df_train['event_name'].apply(extract_second_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "2737845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['event_name_first_part'] = df_test['event_name'].apply(lambda x: x.split('_', 1)[0] if pd.notnull(x) else x)\n",
    "# df_test['event_name_second_part'] = df_test['event_name'].apply(extract_second_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ce1cf",
   "metadata": {},
   "source": [
    "첫 분리와 business_unit이 다르면 drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "db2e352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_train[df_train['event_name_first_part'].isin(['AS', 'ID', 'IT'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "745c3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(tmp[tmp['event_name_first_part'] != tmp['business_unit']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "33c2b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d70812",
   "metadata": {},
   "source": [
    "이벤트가 lead_date 가 1인것 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "1a5f60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(df_train.groupby('event_name')['lead_date'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "96e224e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_1_lst = list(tmp[tmp['lead_date']==1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "f8018bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lead_1'] = 0\n",
    "df_test['lead_1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "3360611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['event_name'].isin(lead_1_lst), 'lead_1'] = 1\n",
    "df_test.loc[df_test['event_name'].isin(lead_1_lst), 'lead_1'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cdc95",
   "metadata": {},
   "source": [
    "event와 channel 일치여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "38584468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ev_ch_lg'] = 0\n",
    "df_test['ev_ch_lg'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "d707274e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['event_name'].str.contains(\"lg.com\", case=False, na=False)) & (~df_train['lead_from_channel'].str.contains(\"lg.com\", case=False, na=False)), 'ev_ch_lg'] = 1\n",
    "df_test.loc[(df_test['event_name'].str.contains(\"lg.com\", case=False, na=False)) & (~df_test['lead_from_channel'].str.contains(\"lg.com\", case=False, na=False)), 'ev_ch_lg'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "3f17fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ev_ch_fb'] = 0\n",
    "df_test['ev_ch_fb'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "10150136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['event_name'].str.contains(\"facebook\", case=False, na=False)) & (~df_train['lead_from_channel'].str.contains(\"facebook\", case=False, na=False)), 'ev_ch_fb'] = 1\n",
    "df_test.loc[(df_test['event_name'].str.contains(\"facebook\", case=False, na=False)) & (~df_test['lead_from_channel'].str.contains(\"facebook\", case=False, na=False)), 'ev_ch_fb'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "352c347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ev_ch_web'] = 0\n",
    "df_test['ev_ch_web'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "ede7ece6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['event_name'].str.contains(\"webinar\", case=False, na=False)) & (~df_train['lead_from_channel'].str.contains(\"webinar\", case=False, na=False)), 'ev_ch_web'] = 1\n",
    "df_test.loc[(df_test['event_name'].str.contains(\"webinar\", case=False, na=False)) & (~df_test['lead_from_channel'].str.contains(\"webinar\", case=False, na=False)), 'ev_ch_web'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "db44b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ev_ch_same'] = 0\n",
    "df_test['ev_ch_same'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "c10c8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_condition = ((df_train.loc[:, 'ev_ch_lg'] == 1) | (df_train.loc[:, 'ev_ch_fb'] == 1) | (df_train.loc[:, 'ev_ch_web'] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "8580a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[filter_condition, 'ev_ch_same'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "2ab1b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=[\"event_name_first_part\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17db151c",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae4078",
   "metadata": {},
   "source": [
    "## ***36. prefer_ver_count***\n",
    "특정 Business Unit 기준으로 영업 전환 성공 샘플에 대해서 Vertical Level 1 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "08d899c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38759"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['prefer_ver_count'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "60103f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prefer_ver_count\n",
       "0.211618    2395\n",
       "0.145228    1948\n",
       "0.038462    1371\n",
       "0.269231    1353\n",
       "0.095436    1332\n",
       "0.288462    1248\n",
       "0.116183    1034\n",
       "0.215768     926\n",
       "0.000000     826\n",
       "0.043478     824\n",
       "0.016598     770\n",
       "0.434783     738\n",
       "0.115385     703\n",
       "0.070539     533\n",
       "0.058091     411\n",
       "0.057692     375\n",
       "0.173913     357\n",
       "0.024896     209\n",
       "0.076923     152\n",
       "0.130435     134\n",
       "0.019231      59\n",
       "0.012448      43\n",
       "1.000000      28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['prefer_ver_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "8b467656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['prefer_ver_mean_unique'] = 0\n",
    "df_test['prefer_ver_mean_unique'] = 0\n",
    "df_train['prefer_ver_mean_unique'][(df_train['prefer_ver_mean'] > 0.208274) & (df_train['prefer_ver_mean'] < 0.208276)] = -1\n",
    "df_test['prefer_ver_mean_unique'][(df_test['prefer_ver_mean'] > 0.208274) & (df_test['prefer_ver_mean'] < 0.208276)] = -1\n",
    "df_train['prefer_ver_mean_unique'][(df_train['prefer_ver_mean'] > 0.445655) & (df_train['prefer_ver_mean'] < 0.445657)] = -1\n",
    "df_test['prefer_ver_mean_unique'][(df_test['prefer_ver_mean'] > 0.445655) & (df_test['prefer_ver_mean'] < 0.445657)] = -1\n",
    "\n",
    "df_train['prefer_ver_count_unique'] = 0\n",
    "df_test['prefer_ver_count_unique'] = 0\n",
    "df_train['prefer_ver_count_unique'][(df_train['prefer_ver_count'] > 0.434782) & (df_train['prefer_ver_count'] < 0.434784)] = -1\n",
    "df_test['prefer_ver_count_unique'][(df_test['prefer_ver_count'] > 0.434782) & (df_test['prefer_ver_count'] < 0.434784)] = -1\n",
    "df_train['prefer_ver_count_unique'][(df_train['prefer_ver_count'] > 0.043477) & (df_train['prefer_ver_count'] < 0.043479)] = -1\n",
    "df_test['prefer_ver_count_unique'][(df_test['prefer_ver_count'] > 0.043477) & (df_test['prefer_ver_count'] < 0.043479)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "ae944b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['prefer_ver_count'] = df_train['prefer_ver_count'].astype('object')\n",
    "df_test['prefer_ver_count'] = df_test['prefer_ver_count'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5e959",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de1956",
   "metadata": {},
   "source": [
    "## ***37. prefer_ver_mean***\n",
    "‘prefer_ver_count’ 와 동일한 기준으로 계산되며 샘플 개수가 아닌 이익 값의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "426402ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38759"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['prefer_ver_mean'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "44a372ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prefer_ver_mean\n",
       "0.027756    2395\n",
       "0.103511    1948\n",
       "0.003494    1353\n",
       "0.067718    1332\n",
       "0.016624    1248\n",
       "0.038886    1034\n",
       "0.046220     926\n",
       "0.000000     826\n",
       "0.208275     788\n",
       "0.008944     781\n",
       "0.445656     738\n",
       "0.391321     703\n",
       "0.049939     533\n",
       "0.068288     411\n",
       "0.449872     395\n",
       "0.044163     378\n",
       "0.072195     317\n",
       "0.025764     264\n",
       "0.106115     209\n",
       "0.005677     207\n",
       "0.067927     195\n",
       "0.110869     170\n",
       "0.032717     168\n",
       "0.019648     152\n",
       "0.130980     128\n",
       "0.003777      59\n",
       "0.290661      43\n",
       "0.052136      40\n",
       "1.000000      28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['prefer_ver_mean'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "10d84a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['prefer_ver_mean'] = df_train['prefer_ver_mean'].astype('object')\n",
    "df_test['prefer_ver_mean'] = df_test['prefer_ver_mean'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711cc3e",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedae7e",
   "metadata": {},
   "source": [
    "## ***38. transfer_agreement***\n",
    "‘prefer_ver_count’ 와 동일한 기준으로 계산되며 샘플 개수가 아닌 이익 값의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "fd823df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['transfer_agreement'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "8b945a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transfer_agreement\n",
       "Y    47092\n",
       "N     8906\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['transfer_agreement'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add94363",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6161bdca",
   "metadata": {},
   "source": [
    "## ***39. ver_win_rate_mean_upper***\n",
    "Ratio_oppty – Ratio 값을 구해서 Vertical 별 평균 값보다 클 경우 1, 아니면 0 값으로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "76c4ad58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38759"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_win_rate_mean_upper'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "8acc24d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ver_win_rate_mean_upper\n",
       "0.0    14199\n",
       "1.0     3570\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ver_win_rate_mean_upper'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c1e12",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09772c",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda9ccfc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad291d",
   "metadata": {},
   "source": [
    "## ***product_category_2***\n",
    "동일 조건 여러개 category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "a9eec883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['product_category_2'] = df_train['product_category'].copy()\n",
    "df_test['product_category_2'] = df_test['product_category'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "0521121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict = {\n",
    "    '110UM5J' : 'Commercial Display / Digital Signage',    '15LS766F (NA)' : 'Commercial Display / commercial tv',    '28MQ780' : 'IT PRODUCTS / Monitor',    '32LT340C' : 'Commercial Display / Digital Signage',    '43HT3WJ' : 'Commercial Display / Interactive signage',    '43UH5F-H' : 'Commercial Display / Digital Signage',    '43US660H' : 'Commercial Display / Hotel TV',    '49UH7F-H' : 'Commercial Display / Digital Signage',    '49VL5PF' : 'Commercial Display / Video Wall Signage',    '55CT5WJ' : 'Commercial Display / One:Quick Series',    '55EF5F-L' : 'Commercial Display / OLED Signage',    '55EF5F-P' : 'Commercial Display / OLED Signage',    '55EF5G-P' : 'Commercial Display / OLED Signage',    '55TR3BG-B' : 'Commercial Display / Interactive signage',    '55UH5F-H': 'Commercial Display / Digital Signage',    '55UH7F-B' : 'Commercial Display / Digital Signage',    '55UR640S' : 'Commercial Display / commercial tv',    '55VM5J-H' : 'Commercial Display / Video Wall Signage',    '55VSM5J' : 'Commercial Display / Video Wall Signage',    '55XE4F-M' : 'Commercial Display / High Brightness Signage',    '55XS2E' : 'Commercial Display / Digital Signage',\n",
    "    '65EV5E' : 'Commercial Display / OLED Signage',    '65UH5F-H' : 'Commercial Display / Standard Signage',    '75TC3D' : 'Commercial Display / Interactive signage',    '75UR640S (EU/CIS)' : 'Commercial Display / Digital Signage',    '85TR3BF' : 'Commercial Display / Interactive signage',    '86BH5F' : 'Commercial Display / Digital Signage',    '86BH5F-B' : 'Commercial Display / Digital Signage',    '86TR3E' : 'Commercial Display / Interactive signage',    '86UT640S' : 'Commercial Display / commercial tv',    '98UH5F-H' : 'Commercial Display / commercial tv',    'Ergo Dual(27QP88D)' : 'IT PRODUCTS / Monitor',    'GSCC066' : 'Commercial Display / LED Signage',    'KT-T32E' : 'Commercial Display / Digital Signage',    'LAD033F' : 'Commercial Display / LED Signage',    'LAEB015' : 'Commercial Display / LED Signage',    'LAS039DB9-V' : 'Commercial Display / LED Signage',    'LAT140' : 'Commercial Display / LED Signage',    'LSAA012' : 'Commercial Display / LED Signage',    'LSAB009' : 'Commercial Display / LED Signage',    'LSAB012' : 'Commercial Display / LED Signage',    'SC-00DA' : 'Commercial Display / One:Quick Series',    'UltraFine Ergo(32UN880)' : 'IT PRODUCTS / Monitor',    'UltraWide Ergo(34WN780)' : 'IT PRODUCTS / Monitor'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "0424dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict_key = product_dict.keys()\n",
    "product_dict_value = product_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "b4820c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:00, 193.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, val in tqdm(enumerate(product_dict_key)):\n",
    "    df_train.loc[df_train['product_modelname'] == val, 'product_category_2'] = product_dict[val]\n",
    "    df_test.loc[df_test['product_modelname'] == val, 'product_category_2'] = product_dict[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "de1fc5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict = {\n",
    "    '49\" 500 nits FHD Slim Bezel Video Wall' : 'Commercial Display / Video Wall Signage',    'All Medical Display' : 'IT PRODUCTS / Medical Display',    'All Medical Displays' : 'IT PRODUCTS / Medical Display',    'All Monitors & PCs' : 'IT PRODUCTS / Monitor & IT PRODUCTS / pc',    'All Projectors' : 'IT PRODUCTS / Projector',    'Built-in Touch Display' : 'Commercial Display / Interactive signage',    'Clinical Review Monitors' : 'IT PRODUCTS / Medical Display',    'Diagnostic Monitors' : 'IT PRODUCTS / Medical Display',    'Diagnostic Monitors\\u200b' : 'IT PRODUCTS / Medical Display',    'Digital X-ray Detectors' : 'IT PRODUCTS / Medical Display',    'Essential Series' : 'Commercial Display / LED Signage',    'Flat OLED Signage' : 'Commercial Display / OLED Signage',    'Interactive Digital Board' : 'Commercial Display / Interactive signage',    'LED Cinema' : 'Commercial Display / LED Signage',    'LT340C Series' : 'Commercial Display / commercial tv',    'LU640H Series' : 'Commercial Display / Hotel TV',    'Laptops' : 'IT PRODUCTS / Laptop',    'OLED Pro Monitor' : 'IT PRODUCTS / Monitor',    'One:Quick Flex' : 'Commercial Display / One:Quick Series',    'One:Quick Works' : 'Commercial Display / One:Quick Series',    'One:Quick works' : 'Commercial Display / One:Quick Series',    'Other' : 'others',    'Others' : 'others',    'SE3KE Series' : 'Commercial Display / Digital Signage',    'SH7DD 系列' : 'Commercial Display / Digital Signage',    'SM3G Series' : 'Commercial Display / Digital Signage',    'SM5KE Series' : 'Commercial Display / Digital Signage',    'Series' : 'others',    'Smart Touch Screen TV' : 'Commercial Display / commercial tv',    'Surgical Monitors' : 'IT PRODUCTS / Medical Display',    'TC3D Series' : 'Commercial Display / Interactive signage',\n",
    "    'TR3BF Series' : 'Commercial Display / Interactive signage',    'TR3BG Series' : 'Commercial Display / Interactive signage',    'Thin Clients' : 'IT PRODUCTS / Cloud Device',    'Touch Overlay Kit' : 'Commercial Display / Digital Signage',    'UH5F Series' : 'UH5F Series',    'UH5F-H Series' : 'Commercial Display / Digital Signage',    'UH7F Series' : 'Commercial Display / Digital Signage',    'UH7F-H Series' : 'Commercial Display / Digital Signage',    'UHD 4K Monitors' : 'IT PRODUCTS / Monitor',    'UHD Large Screen Signage Display' : 'Commercial Display / Digital Signage',    'UHD TV Signage' : 'Commercial Display / Digital Signage',    'UL3G Series' : 'Commercial Display / Digital Signage',    'UM3DG Series' : 'Commercial Display / Digital Signage',    'UM5J Series' : 'Commercial Display / Digital Signage',    'UR640S Series' : 'Commercial Display / Digital Signage',    'UT640S' : 'Commercial Display / Digital Signage',    'UT640S Series' : 'Commercial Display / Digital Signage',    'Ultra Narrow Bezel Video Wall' : 'Commercial Display / Video Wall Signage',    'Ultra Slim Series' : 'Commercial Display / LED Signage',    'Ultra Stretch Series' : 'Commercial Display / Digital Signage',    'Ultra Stretch Signage' : 'Commercial Display / Digital Signage',    'VH7E Series' : 'Commercial Display / Digital Signage',    'Video Wall' : 'Commercial Display / Video Wall Signage',    'Wallpaper OLED Signage' : 'Commercial Display / OLED Signage',    'Window Facing Display' : 'Commercial Display / Digital Signage'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "1476b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict_key = product_dict.keys()\n",
    "product_dict_value = product_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "97a42f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:00, 194.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, val in tqdm(enumerate(product_dict_key)):\n",
    "    df_train.loc[df_train['product_subcategory'] == val, 'product_category_2'] = product_dict[val]\n",
    "    df_test.loc[df_test['product_subcategory'] == val, 'product_category_2'] = product_dict[val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8650f5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904554b9",
   "metadata": {},
   "source": [
    "## ***write_budget***\n",
    "MQL 구성 요소 중 Budget 작성여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "4de5d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MQL 구성 요소 중 Budget 작성여부\n",
    "df_train.loc[df_train['bant_submit'] == 1.0,'write_budget'] = 1\n",
    "\n",
    "df_train.loc[df_train['bant_submit'] == 0.0,'write_budget'] = 0\n",
    "\n",
    "df_train.loc[(df_train['bant_submit'] == 0.25) & (df_train['expected_timeline'].isna())  & (df_train['customer_position'] == \"none\") & (df_train['inquiry_type'].isna()),'write_budget'] = 1\n",
    "df_train.loc[(df_train['bant_submit'] == 0.25) & (df_train['expected_timeline'].notna())  & (df_train['customer_position'] == \"none\") & (df_train['inquiry_type'].isna()),'write_budget'] = 0\n",
    "df_train.loc[(df_train['bant_submit'] == 0.25) & (df_train['expected_timeline'].isna())  & (df_train['customer_position'] == \"none\") & (df_train['inquiry_type'].notna()),'write_budget'] = 0\n",
    "df_train.loc[(df_train['bant_submit'] == 0.25) & (df_train['expected_timeline'].isna())  & (df_train['customer_position'] != \"none\") & (df_train['inquiry_type'].isna()),'write_budget'] = 0\n",
    "\n",
    "df_train.loc[(df_train['bant_submit'] == 0.5) & (df_train['expected_timeline'].notna())  & (df_train['customer_position'] == \"none\") & (df_train['inquiry_type'].isna()),'write_budget'] = 1\n",
    "df_train.loc[(df_train['bant_submit'] == 0.5) & (df_train['expected_timeline'].notna())  & (df_train['customer_position'] != \"none\") & (df_train['inquiry_type'].isna()),'write_budget'] = 0\n",
    "df_train.loc[(df_train['bant_submit'] == 0.5) & (df_train['expected_timeline'].notna())  & (df_train['customer_position'] == \"none\") & (df_train['inquiry_type'].notna()),'write_budget'] = 0\n",
    "df_train.loc[(df_train['bant_submit'] == 0.5) & (df_train['expected_timeline'].isna())  & (df_train['customer_position'] != \"none\") & (df_train['inquiry_type'].notna()),'write_budget'] = 0\n",
    "df_train.loc[(df_train['bant_submit'] == 0.5) & (df_train['expected_timeline'].isna())  & (df_train['customer_position'] != \"none\") & (df_train['inquiry_type'].isna()),'write_budget'] = 1\n",
    "df_train.loc[(df_train['bant_submit'] == 0.5) & (df_train['expected_timeline'].isna())  & (df_train['customer_position'] == \"none\") & (df_train['inquiry_type'].notna()),'write_budget'] = 1\n",
    "\n",
    "df_train.loc[(df_train['bant_submit'] == 0.75) & (df_train['expected_timeline'].isna())  & (df_train['customer_position'] != \"none\") & (df_train['inquiry_type'].notna()),'write_budget'] = 1\n",
    "df_train.loc[(df_train['bant_submit'] == 0.75) & (df_train['expected_timeline'].notna())  & (df_train['customer_position'] == \"none\") & (df_train['inquiry_type'].notna()),'write_budget'] = 1\n",
    "df_train.loc[(df_train['bant_submit'] == 0.75) & (df_train['expected_timeline'].notna())  & (df_train['customer_position'] != \"none\") & (df_train['inquiry_type'].isna()),'write_budget'] = 1\n",
    "df_train.loc[(df_train['bant_submit'] == 0.75) & (df_train['expected_timeline'].notna())  & (df_train['customer_position'] != \"none\") & (df_train['inquiry_type'].notna()),'write_budget'] = 0\n",
    "\n",
    "#MQL 구성 요소 중 Budget 작성여부\n",
    "df_test.loc[df_test['bant_submit'] == 1.0,'write_budget'] = 1\n",
    "\n",
    "df_test.loc[df_test['bant_submit'] == 0.0,'write_budget'] = 0\n",
    "\n",
    "df_test.loc[(df_test['bant_submit'] == 0.25) & (df_test['expected_timeline'].isna())  & (df_test['customer_position'] == \"none\") & (df_test['inquiry_type'].isna()),'write_budget'] = 1\n",
    "df_test.loc[(df_test['bant_submit'] == 0.25) & (df_test['expected_timeline'].notna())  & (df_test['customer_position'] == \"none\") & (df_test['inquiry_type'].isna()),'write_budget'] = 0\n",
    "df_test.loc[(df_test['bant_submit'] == 0.25) & (df_test['expected_timeline'].isna())  & (df_test['customer_position'] == \"none\") & (df_test['inquiry_type'].notna()),'write_budget'] = 0\n",
    "df_test.loc[(df_test['bant_submit'] == 0.25) & (df_test['expected_timeline'].isna())  & (df_test['customer_position'] != \"none\") & (df_test['inquiry_type'].isna()),'write_budget'] = 0\n",
    "\n",
    "df_test.loc[(df_test['bant_submit'] == 0.5) & (df_test['expected_timeline'].notna())  & (df_test['customer_position'] == \"none\") & (df_test['inquiry_type'].isna()),'write_budget'] = 1\n",
    "df_test.loc[(df_test['bant_submit'] == 0.5) & (df_test['expected_timeline'].notna())  & (df_test['customer_position'] != \"none\") & (df_test['inquiry_type'].isna()),'write_budget'] = 0\n",
    "df_test.loc[(df_test['bant_submit'] == 0.5) & (df_test['expected_timeline'].notna())  & (df_test['customer_position'] == \"none\") & (df_test['inquiry_type'].notna()),'write_budget'] = 0\n",
    "df_test.loc[(df_test['bant_submit'] == 0.5) & (df_test['expected_timeline'].isna())  & (df_test['customer_position'] != \"none\") & (df_test['inquiry_type'].notna()),'write_budget'] = 0\n",
    "df_test.loc[(df_test['bant_submit'] == 0.5) & (df_test['expected_timeline'].isna())  & (df_test['customer_position'] != \"none\") & (df_test['inquiry_type'].isna()),'write_budget'] = 1\n",
    "df_test.loc[(df_test['bant_submit'] == 0.5) & (df_test['expected_timeline'].isna())  & (df_test['customer_position'] == \"none\") & (df_test['inquiry_type'].notna()),'write_budget'] = 1\n",
    "\n",
    "df_test.loc[(df_test['bant_submit'] == 0.75) & (df_test['expected_timeline'].isna())  & (df_test['customer_position'] != \"none\") & (df_test['inquiry_type'].notna()),'write_budget'] = 1\n",
    "df_test.loc[(df_test['bant_submit'] == 0.75) & (df_test['expected_timeline'].notna())  & (df_test['customer_position'] == \"none\") & (df_test['inquiry_type'].notna()),'write_budget'] = 1\n",
    "df_test.loc[(df_test['bant_submit'] == 0.75) & (df_test['expected_timeline'].notna())  & (df_test['customer_position'] != \"none\") & (df_test['inquiry_type'].isna()),'write_budget'] = 1\n",
    "df_test.loc[(df_test['bant_submit'] == 0.75) & (df_test['expected_timeline'].notna())  & (df_test['customer_position'] != \"none\") & (df_test['inquiry_type'].notna()),'write_budget'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "e65d3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['write_budget'] = df_train['write_budget'].fillna(0)\n",
    "df_test['write_budget'] = df_test['write_budget'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8a353",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913a9bb",
   "metadata": {},
   "source": [
    "## ***bant_submit_zegob***\n",
    "bant_submit 제곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "82553411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['bant_submit_zegob'] = df_train['bant_submit'] * df_train['bant_submit']\n",
    "df_test['bant_submit_zegob'] = df_test['bant_submit'] * df_test['bant_submit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05420613",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ec637",
   "metadata": {},
   "source": [
    "## ***raw_country***\n",
    "기존 나라 컬럼 그대로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "6bc29039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['raw_country'] = df_train['customer_country2'].copy()\n",
    "df_test['raw_country'] = df_test['customer_country2'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "bdb0a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['raw_country'] = df_train['raw_country'].apply(lambda x: re.sub(r'\\s*/\\s*', '/', x) if isinstance(x, str) else x)\n",
    "df_test['raw_country'] = df_test['raw_country'].apply(lambda x: re.sub(r'\\s*/\\s*', '/', x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "94aca342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['raw_country'] = df_train['raw_country'].astype(str).apply(lambda x : x.strip().lower())\n",
    "df_test['raw_country'] = df_test['raw_country'].astype(str).apply(lambda x : x.strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a104364c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc86f37",
   "metadata": {},
   "source": [
    "## ***City***\n",
    "도시정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "e85d2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = df_train['customer_country2'].str.split('/', expand=True)\n",
    "condition_1 = split[1].notna() & split[2].notna()\n",
    "df_train.loc[condition_1, 'Field'] = None\n",
    "df_train.loc[condition_1, 'City'] = split[1]\n",
    "df_train.loc[condition_1, 'Country'] = split[2]\n",
    "# 두 번째 섹션이 비어 있음\n",
    "condition_2 = split[0].notna() & split[2].notna()\n",
    "df_train.loc[condition_2, 'Field'] = split[0]\n",
    "df_train.loc[condition_2, 'City'] = None\n",
    "df_train.loc[condition_2, 'Country'] = split[2]\n",
    "# 세 번째 섹션이 비어 있음\n",
    "condition_3 = split[0].notna() & split[1].notna()\n",
    "df_train.loc[condition_3, 'Field'] = split[0]\n",
    "df_train.loc[condition_3, 'City'] = split[1]\n",
    "df_train.loc[condition_3, 'Country'] = None\n",
    "# 첫 번째와 두 번째 섹션이 비어 있음\n",
    "condition_4 = split[2].notna() & split[0].isna() & split[1].isna()\n",
    "df_train.loc[condition_4, 'Field'] = None\n",
    "df_train.loc[condition_4, 'City'] = None\n",
    "df_train.loc[condition_4, 'Country'] = split[2]\n",
    "# 첫 번째와 세 번째 섹션이 비어 있고 두 번째 섹션에만 값이 있음\n",
    "condition_5 = split[1].notna() & split[0].isna() & split[2].isna()\n",
    "df_train.loc[condition_5, 'Field'] = None\n",
    "df_train.loc[condition_5, 'City'] = split[1]\n",
    "df_train.loc[condition_5, 'Country'] = None\n",
    "# 두 번째와 세 번째 섹션이 비어 있고 첫 번째 섹션에만 값이 있음\n",
    "condition_6 = split[0].notna() & split[1].isna() & split[2].isna()\n",
    "df_train.loc[condition_6, 'Field'] = split[0]\n",
    "df_train.loc[condition_6, 'City'] = None\n",
    "df_train.loc[condition_6, 'Country'] = None\n",
    "# 모든 섹션이 비어 있음\n",
    "condition_7 = split[0].isna() & split[1].isna() & split[2].isna()\n",
    "df_train.loc[condition_7, ['Field', 'City', 'Country']] = None\n",
    "# 모든 섹션이 채워져 있는 경우 처리 추가\n",
    "condition_all_filled = split[0].notna() & split[1].notna() & split[2].notna()\n",
    "df_train.loc[condition_all_filled, 'Field'] = split[0]\n",
    "df_train.loc[condition_all_filled, 'City'] = split[1]\n",
    "df_train.loc[condition_all_filled, 'Country'] = split[2]\n",
    "# 이미 처리한 조건들에 대한 인덱스를 제외하고 나머지 데이터 확인을 위한 조건 재설정\n",
    "remaining_conditions = ~(condition_1 | condition_2 | condition_3 | condition_4 | condition_5 | condition_6 | condition_7 | condition_all_filled)\n",
    "# 처리되지 않은 나머지 데이터 확인 (있을 경우)\n",
    "remaining_df_train = df_train[remaining_conditions]\n",
    "remaining_sample = remaining_df_train[['customer_country2', 'Field', 'City', 'Country']] if not remaining_df_train.empty else \"All cases have been handled.\"\n",
    "split = df_test['customer_country2'].str.split('/', expand=True)\n",
    "condition_1 = split[1].notna() & split[2].notna()\n",
    "df_test.loc[condition_1, 'Field'] = None\n",
    "df_test.loc[condition_1, 'City'] = split[1]\n",
    "df_test.loc[condition_1, 'Country'] = split[2]\n",
    "condition_2 = split[0].notna() & split[2].notna()\n",
    "df_test.loc[condition_2, 'Field'] = split[0]\n",
    "df_test.loc[condition_2, 'City'] = None\n",
    "df_test.loc[condition_2, 'Country'] = split[2]\n",
    "condition_3 = split[0].notna() & split[1].notna()\n",
    "df_test.loc[condition_3, 'Field'] = split[0]\n",
    "df_test.loc[condition_3, 'City'] = split[1]\n",
    "df_test.loc[condition_3, 'Country'] = None\n",
    "condition_4 = split[2].notna() & split[0].isna() & split[1].isna()\n",
    "df_test.loc[condition_4, 'Field'] = None\n",
    "df_test.loc[condition_4, 'City'] = None\n",
    "df_test.loc[condition_4, 'Country'] = split[2]\n",
    "condition_5 = split[1].notna() & split[0].isna() & split[2].isna()\n",
    "df_test.loc[condition_5, 'Field'] = None\n",
    "df_test.loc[condition_5, 'City'] = split[1]\n",
    "df_test.loc[condition_5, 'Country'] = None\n",
    "condition_6 = split[0].notna() & split[1].isna() & split[2].isna()\n",
    "df_test.loc[condition_6, 'Field'] = split[0]\n",
    "df_test.loc[condition_6, 'City'] = None\n",
    "df_test.loc[condition_6, 'Country'] = None\n",
    "condition_7 = split[0].isna() & split[1].isna() & split[2].isna()\n",
    "df_test.loc[condition_7, ['Field', 'City', 'Country']] = None\n",
    "condition_all_filled = split[0].notna() & split[1].notna() & split[2].notna()\n",
    "df_test.loc[condition_all_filled, 'Field'] = split[0]\n",
    "df_test.loc[condition_all_filled, 'City'] = split[1]\n",
    "df_test.loc[condition_all_filled, 'Country'] = split[2]\n",
    "remaining_conditions = ~(condition_1 | condition_2 | condition_3 | condition_4 | condition_5 | condition_6 | condition_7 | condition_all_filled)\n",
    "remaining_df_test = df_test[remaining_conditions]\n",
    "remaining_sample = remaining_df_test[['customer_country2', 'Field', 'City', 'Country']] if not remaining_df_test.empty else \"All cases have been handled.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "1046e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['customer_country2'],axis=1,inplace=True)\n",
    "df_test.drop(['customer_country2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "af5dcb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['City'] = df_train['City'].astype(str).apply(lambda x : x.strip().lower())\n",
    "df_test['City'] = df_test['City'].astype(str).apply(lambda x : x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "1caa8af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영국 도시\n",
    "df_train.loc[df_train['City'].str.contains('paulo', case=True, na=False), 'City'] = 'sanpaulo'\n",
    "df_test.loc[df_test['City'].str.contains('paulo', case=True, na=False), 'City'] = 'sanpaulo'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('mumbai', case=True, na=False), 'City'] = 'mumbai'\n",
    "df_test.loc[df_test['City'].str.contains('mumbai', case=True, na=False), 'City'] = 'mumbai'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('hyderabad', case=True, na=False), 'City'] = 'hyderabad'\n",
    "df_test.loc[df_test['City'].str.contains('hyderabad', case=True, na=False), 'City'] = 'hyderabad'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('lima', case=True, na=False), 'City'] = 'lima'\n",
    "df_test.loc[df_test['City'].str.contains('lima', case=True, na=False), 'City'] = 'lima'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('bangalore', case=True, na=False), 'City'] = 'bangalore'\n",
    "df_test.loc[df_test['City'].str.contains('bangalore', case=True, na=False), 'City'] = 'bangalore'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('santiago', case=True, na=False), 'City'] = 'santiago'\n",
    "df_test.loc[df_test['City'].str.contains('santiago', case=True, na=False), 'City'] = 'santiago'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('mexico', case=True, na=False), 'City'] = 'mexico'\n",
    "df_test.loc[df_test['City'].str.contains('mexico', case=True, na=False), 'City'] = 'mexico'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('dubai', case=True, na=False), 'City'] = 'dubai'\n",
    "df_test.loc[df_test['City'].str.contains('dubai', case=True, na=False), 'City'] = 'dubai'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('pune', case=True, na=False), 'City'] = 'pune'\n",
    "df_test.loc[df_test['City'].str.contains('pune', case=True, na=False), 'City'] = 'pune'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('delhi', case=True, na=False), 'City'] = 'delhi'\n",
    "df_test.loc[df_test['City'].str.contains('delhi', case=True, na=False), 'City'] = 'delhi'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('chennai', case=True, na=False), 'City'] = 'chennai'\n",
    "df_test.loc[df_test['City'].str.contains('chennai', case=True, na=False), 'City'] = 'chennai'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('bogot', case=True, na=False), 'City'] = 'bogota'\n",
    "df_test.loc[df_test['City'].str.contains('bogot', case=True, na=False), 'City'] = 'bogota'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('janeiro', case=True, na=False), 'City'] = 'janeiro'\n",
    "df_test.loc[df_test['City'].str.contains('janeiro', case=True, na=False), 'City'] = 'janeiro'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('kolkata', case=True, na=False), 'City'] = 'kolkata'\n",
    "df_test.loc[df_test['City'].str.contains('kolkata', case=True, na=False), 'City'] = 'kolkata'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('ahmedabad', case=True, na=False), 'City'] = 'ahmedabad'\n",
    "df_test.loc[df_test['City'].str.contains('ahmedabad', case=True, na=False), 'City'] = 'ahmedabad'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('patna', case=True, na=False), 'City'] = 'patna'\n",
    "df_test.loc[df_test['City'].str.contains('patna', case=True, na=False), 'City'] = 'patna'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('cdmx', case=True, na=False), 'City'] = 'cdmx'\n",
    "df_test.loc[df_test['City'].str.contains('cdmx', case=True, na=False), 'City'] = 'cdmx'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('riyadh', case=True, na=False), 'City'] = 'riyadh'\n",
    "df_test.loc[df_test['City'].str.contains('riyadh', case=True, na=False), 'City'] = 'riyadh'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('surat', case=True, na=False), 'City'] = 'surat'\n",
    "df_test.loc[df_test['City'].str.contains('surat', case=True, na=False), 'City'] = 'surat'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('gujarat', case=True, na=False), 'City'] = 'gujarat'\n",
    "df_test.loc[df_test['City'].str.contains('gujarat', case=True, na=False), 'City'] = 'gujarat'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('quezon city', case=True, na=False), 'City'] = 'quezon city'\n",
    "df_test.loc[df_test['City'].str.contains('quezon city', case=True, na=False), 'City'] = 'quezon city'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('oran', case=True, na=False), 'oran'] = 'oran'\n",
    "df_test.loc[df_test['City'].str.contains('oran', case=True, na=False), 'oran'] = 'oran'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('ohio', case=True, na=False), 'ohio'] = 'ohio'\n",
    "df_test.loc[df_test['City'].str.contains('ohio', case=True, na=False), 'ohio'] = 'ohio'\n",
    "\n",
    "df_train.loc[df_train['City'].str.contains('valencia', case=True, na=False), 'valencia'] = 'valencia'\n",
    "df_test.loc[df_test['City'].str.contains('valencia', case=True, na=False), 'valencia'] = 'valencia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "489853fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['City']=='.','City'] =''\n",
    "df_test.loc[df_test['City']=='.','City'] =''\n",
    "\n",
    "df_train.loc[df_train['City']==',','City'] =''\n",
    "df_test.loc[df_test['City']==',','City'] =''\n",
    "\n",
    "data1 = df_train['City'].value_counts().reset_index()\n",
    "small_city_list1 = list(data1[data1['count']<=2]['City'].unique())\n",
    "small_city = small_city_list1\n",
    "\n",
    "df_train.loc[df_train['City'].isin(small_city),'City'] = df_train['customer_country']\n",
    "df_test.loc[df_test['City'].isin(small_city),'City'] = df_test['customer_country']\n",
    "\n",
    "df_train['City'] = df_train['City'].astype(str).apply(lambda x : x.strip().lower())\n",
    "df_test['City'] = df_test['City'].astype(str).apply(lambda x : x.strip().lower())\n",
    "\n",
    "df_train.loc[df_train['City']=='','City']=np.nan\n",
    "df_test.loc[df_test['City']=='','City']=np.nan\n",
    "\n",
    "df_train.loc[df_train['City']=='unknown','City']=np.nan\n",
    "df_test.loc[df_test['City']=='unknown','City']=np.nan\n",
    "\n",
    "df_train['City'] = df_train['City'].fillna(df_train['customer_country'])\n",
    "df_test['City'] = df_test['City'].fillna(df_test['customer_country'])\n",
    "\n",
    "df_train['City'] = df_train['City'].astype(str).apply(lambda x : x.strip().lower())\n",
    "df_test['City'] = df_test['City'].astype(str).apply(lambda x : x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "0771e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['Field'].str.contains('Cloud', case=True, na=False), 'Field'] ='IT/CLOUD'\n",
    "df_train.loc[df_train['Field'].str.contains('Commercial Display', case=True, na=False), 'Field'] = 'Commercial Display'\n",
    "df_train.loc[df_train['Field'].str.contains('Education', case=True, na=False), 'Field'] = 'Education'\n",
    "df_train.loc[df_train['Field'].str.contains('Cruise', case=True, na=False), 'Field'] = 'Cruise'\n",
    "df_train.loc[df_train['Field'].str.contains('Medical', case=True, na=False), 'Field'] = 'Medical'\n",
    "df_train.loc[df_train['Field'].str.contains('Healthcare', case=True, na=False), 'Field'] = 'Healthcare'\n",
    "df_train.loc[df_train['Field'].str.contains('Information Technology', case=True, na=False), 'Field'] = 'Information Technology'\n",
    "df_train.loc[df_train['Field'].str.contains('Hotel', case=True, na=False), 'Field'] = 'Hotel'\n",
    "df_train.loc[df_train['Field'].str.contains('Finance & Insurance', case=True, na=False), 'Field'] = 'Finance & Insurance'\n",
    "df_train.loc[df_train['Field'].str.contains('Retail', case=True, na=False), 'Field'] = 'Retail'\n",
    "df_train.loc[df_train['Field'].str.contains('Transport & Logistics', case=True, na=False), 'Field'] = 'Transport & Logistics'\n",
    "#it products / cloud device\n",
    "\n",
    "df_train.loc[df_train['Field']=='IT/CLOUD','product_category']='it products / cloud device'\n",
    "df_train.loc[(df_train['Field']=='Commercial Display') & (df_train['product_category']=='ID_unknown'),'product_category']='Commercial Display'\n",
    "df_train.loc[(df_train['Field']=='Commercial Display') & (df_train['product_category']=='IT_unknown'),'product_category']='Commercial Display'\n",
    "df_train.loc[(df_train['Field']=='Cruise') & (df_train['business_subarea']=='Not entered'),'business_subarea']='Cruise'\n",
    "df_train.loc[(df_train['Field']=='Cruise') & (df_train['business_area']=='hotel & accommodation'),'business_subarea']='hotel & accommodation'\n",
    "df_train.loc[(df_train['Field']=='Medical') ,'business_subarea']='Health'\n",
    "df_train.loc[(df_train['Field']=='Medical') ,'business_area']='hospital & health care'\n",
    "\n",
    "df_train.loc[(df_train['Field']=='Healthcare') ,'business_subarea']='Health'\n",
    "df_train.loc[(df_train['Field']=='Healthcare') ,'business_area']='hospital & health care'\n",
    "\n",
    "df_train.loc[(df_train['Field']=='Finance & Insurance') ,'business_subarea']='Finance'\n",
    "df_train.loc[(df_train['Field']=='Finance & Insurance') ,'business_area']='corporate / office'\n",
    "\n",
    "df_train.loc[(df_train['Field']=='Retail') ,'business_subarea']='Other Stores'\n",
    "df_train.loc[(df_train['Field']=='Retail') ,'business_area']='retail'\n",
    "\n",
    "#df_train.loc[(df_train['Field']=='Education') ,'product_category']='commercial display'\n",
    "df_train.loc[(df_train['Field']=='Education') ,'business_area']='education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "dff6267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['Field'].str.contains('Cloud', case=True, na=False), 'Field'] ='IT/CLOUD'\n",
    "df_test.loc[df_test['Field'].str.contains('Commercial Display', case=True, na=False), 'Field'] = 'Commercial Display'\n",
    "df_test.loc[df_test['Field'].str.contains('Education', case=True, na=False), 'Field'] = 'Education'\n",
    "df_test.loc[df_test['Field'].str.contains('Cruise', case=True, na=False), 'Field'] = 'Cruise'\n",
    "df_test.loc[df_test['Field'].str.contains('Medical', case=True, na=False), 'Field'] = 'Medical'\n",
    "df_test.loc[df_test['Field'].str.contains('Healthcare', case=True, na=False), 'Field'] = 'Healthcare'\n",
    "df_test.loc[df_test['Field'].str.contains('Information Technology', case=True, na=False), 'Field'] = 'Information Technology'\n",
    "df_test.loc[df_test['Field'].str.contains('Hotel', case=True, na=False), 'Field'] = 'Hotel'\n",
    "df_test.loc[df_test['Field'].str.contains('Finance & Insurance', case=True, na=False), 'Field'] = 'Finance & Insurance'\n",
    "df_test.loc[df_test['Field'].str.contains('Retail', case=True, na=False), 'Field'] = 'Retail'\n",
    "df_test.loc[df_test['Field'].str.contains('Transport & Logistics', case=True, na=False), 'Field'] = 'Transport & Logistics'\n",
    "#it products / cloud device\n",
    "\n",
    "df_test.loc[df_test['Field']=='IT/CLOUD','product_category']='it products / cloud device'\n",
    "df_test.loc[(df_test['Field']=='Commercial Display') & (df_test['product_category']=='ID_unknown'),'product_category']='Commercial Display'\n",
    "df_test.loc[(df_test['Field']=='Commercial Display') & (df_test['product_category']=='IT_unknown'),'product_category']='Commercial Display'\n",
    "df_test.loc[(df_test['Field']=='Cruise') & (df_test['business_subarea']=='Not entered'),'business_subarea']='Cruise'\n",
    "df_test.loc[(df_test['Field']=='Cruise') & (df_test['business_area']=='hotel & accommodation'),'business_subarea']='hotel & accommodation'\n",
    "df_test.loc[(df_test['Field']=='Medical') ,'business_subarea']='Health'\n",
    "df_test.loc[(df_test['Field']=='Medical') ,'business_area']='hospital & health care'\n",
    "\n",
    "df_test.loc[(df_test['Field']=='Healthcare') ,'business_subarea']='Health'\n",
    "df_test.loc[(df_test['Field']=='Healthcare') ,'business_area']='hospital & health care'\n",
    "\n",
    "df_test.loc[(df_test['Field']=='Finance & Insurance') ,'business_subarea']='Finance'\n",
    "df_test.loc[(df_test['Field']=='Finance & Insurance') ,'business_area']='corporate / office'\n",
    "\n",
    "df_test.loc[(df_test['Field']=='Retail') ,'business_subarea']='Other Stores'\n",
    "df_test.loc[(df_test['Field']=='Retail') ,'business_area']='retail'\n",
    "\n",
    "#df_test.loc[(df_test['Field']=='Education') ,'product_category']='commercial display'\n",
    "df_test.loc[(df_test['Field']=='Education') ,'business_area']='education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "4a548ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['Field','Country'])\n",
    "df_test = df_test.drop(columns = ['Field','Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ceea8e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336b31f",
   "metadata": {},
   "source": [
    "## ***customer_continent***\n",
    "나라 대륙 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "51987c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_east = ['India','Afghanistan', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kuwait', 'Lebanon', 'Oman', 'Qatar', 'Saudi Arabia', 'Syria', 'Turkey', 'United Arab Emirates', 'Yemen','Saudi Arabia', 'United Arab Emirates', 'Oman', 'Qatar', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kuwait', 'Lebanon', 'Syria', 'Yemen', 'Bahrain', 'Palestine']\n",
    "balkans = ['Albania', 'Bosnia and Herzegovina', 'Bulgaria', 'Croatia', 'Greece', 'Kosovo', 'Montenegro', 'North Macedonia', 'Romania', 'Serbia', 'Slovenia','Greece', 'Turkey', 'Bulgaria', 'Serbia', 'Croatia', 'Bosnia and Herzegovina', 'Montenegro', 'North Macedonia', 'Albania', 'Kosovo', 'Romania']\n",
    "south_america = ['Barranquilla', 'Belo Horizonte', 'Jojia','Argentina', 'Bolivia', 'Brazil', 'Chile', 'Colombia', 'Ecuador', 'Guyana', 'Paraguay', 'Peru', 'Suriname', 'Uruguay', 'Venezuela','Brazil', 'Colombia', 'Argentina', 'Chile', 'Peru', 'Ecuador', 'Venezuela', 'Bolivia', 'Paraguay', 'Uruguay', 'Suriname', 'Guyana']\n",
    "north_america = ['Anguilla', 'Antigua', 'Aruba', 'Bahamas', 'Barbados', 'Belize', 'Bermuda', 'Cayman Islands', 'Costa Rica', 'Cuba', 'CuraÃ§ao', 'Dominica', 'El Salvador', 'Grenada', 'Guadeloupe', 'Guatemala', 'Haiti', 'Honduras', 'Jamaica', 'Martinique', 'Mexico', 'Montserrat', 'Nicaragua', 'Panama', 'Puerto Rico', 'Saint Kitts', 'Saint Lucia', 'Saint Martin', 'Sint Maarten', 'Trinidad and Tobago', 'Turks and Caicos Islands', 'Virgin Islands','United States', 'Mexico', 'Canada', 'Guatemala', 'Panama']\n",
    "eastern_europe = ['Czech', 'Macedonia','Russia', 'Ukraine', 'Belarus', 'Moldova', 'Romania', 'Hungary', 'Poland', 'Czech Republic', 'Slovakia', 'Bulgaria', 'Serbia', 'Croatia', 'Bosnia and Herzegovina', 'Montenegro', 'Albania', 'North Macedonia', 'Kosovo', 'Slovenia', 'Latvia', 'Lithuania', 'Estonia']\n",
    "western_europe = ['Denmark', 'Finland', 'Iceland', 'Isle of Man', 'Jersey', 'Malta', 'Monaco', 'Norway', 'Sweden','United Kingdom', 'France', 'Germany', 'Italy', 'Spain', 'Netherlands', 'Belgium', 'Luxembourg', 'Switzerland', 'Austria', 'Portugal', 'Ireland']\n",
    "east_asia = ['Bangladesh', 'Brunei', 'Cambodia', 'Indonesia', 'Laos', 'Malaysia', 'Maldives', 'Myanmar', 'Nepal', 'Philippines', 'Singapore', 'Sri Lanka', 'Thailand', 'VietNam','Korea','China', 'Japan', 'South Korea', 'North Korea', 'Taiwan', 'Mongolia', 'Hong Kong', 'Macau']\n",
    "west_asia = ['Kazakhstan', 'Pakistan', 'Turkmenistan', 'Uzbekistan','Bahrain','Turkey', 'Cyprus', 'Georgia', 'Armenia', 'Azerbaijan', 'Iran', 'Iraq', 'Syria', 'Lebanon', 'Israel', 'Jordan', 'Saudi Arabia', 'Yemen', 'United Arab Emirates', 'Qatar', 'Bahrain', 'Kuwait', 'Oman']\n",
    "west_africa = ['Nigeria', 'Benin', 'Ghana', 'Guinea', 'Liberia', 'Mali', 'Niger', 'Senegal', 'Sierra Leone', 'Togo', 'Burkina Faso', 'Cape Verde', 'Gambia', 'Guinea-Bissau', 'Ivory Coast']\n",
    "east_africa = ['Ethiopia', 'Kenya', 'Tanzania', 'Uganda', 'Burundi', 'Rwanda', 'Somalia', 'South Sudan', 'Sudan', 'Djibouti', 'Eritrea', 'Madagascar', 'Mauritius', 'Seychelles', 'Comoros']\n",
    "southern_africa = ['Swaziland','South Africa', 'Angola', 'Botswana', 'Lesotho', 'Malawi', 'Mozambique', 'Namibia', 'Eswatini', 'Zambia', 'Zimbabwe']\n",
    "central_africa = ['Congo','Democratic Republic of the Congo', 'Republic of the Congo', 'Gabon', 'Equatorial Guinea', 'Sao Tome and Principe', 'Cameroon', 'Central African Republic', 'Chad']\n",
    "north_africa = ['Mauritania','Gujarat','Egypt', 'Algeria', 'Libya', 'Morocco', 'Tunisia', 'Western Sahara']\n",
    "oceania = ['Australia', 'Fiji', 'Guam', 'New Zealand']\n",
    "origin_america = south_america+north_america\n",
    "origin_europe = eastern_europe+western_europe\n",
    "origin_asia = east_asia+west_asia\n",
    "origin_africa = west_africa+east_africa+southern_africa+central_africa+north_africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "1b0ac80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in middle_east:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'middle_east'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'middle_east'] = 1\n",
    "for i in balkans:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'balkans'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'balkans'] = 1\n",
    "for i in south_america:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'south_america'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'south_america'] = 1\n",
    "for i in north_america:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'north_america'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'north_america'] = 1\n",
    "for i in eastern_europe:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'eastern_europe'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'eastern_europe'] = 1\n",
    "for i in western_europe:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'western_europe'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'western_europe'] = 1\n",
    "for i in east_asia:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'east_asia'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'east_asia'] = 1\n",
    "for i in west_asia:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'west_asia'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'west_asia'] = 1\n",
    "for i in west_africa:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'west_africa'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'west_africa'] = 1\n",
    "for i in east_africa:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'east_africa'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'east_africa'] = 1\n",
    "for i in southern_africa:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'southern_africa'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'southern_africa'] = 1\n",
    "for i in central_africa:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'central_africa'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'central_africa'] = 1\n",
    "for i in north_africa:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'north_africa'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'north_africa'] = 1\n",
    "for i in oceania:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'oceania'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'oceania'] = 1\n",
    "for i in origin_america:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'origin_america'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'origin_america'] = 1\n",
    "for i in origin_europe:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'origin_europe'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'origin_europe'] = 1\n",
    "for i in origin_asia:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'origin_asia'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'origin_asia'] = 1\n",
    "for i in origin_africa:\n",
    "    df_train.loc[df_train['customer_country'].str.contains(i, case=True, na=False), 'origin_africa'] = 1\n",
    "    df_test.loc[df_test['customer_country'].str.contains(i, case=True, na=False), 'origin_africa'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "fe618ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['middle_east', 'balkans', 'south_america', 'north_america', 'eastern_europe', 'western_europe', 'east_asia', 'west_asia', 'west_africa', 'east_africa', 'southern_africa', 'central_africa', 'north_africa', 'oceania', 'origin_america', 'origin_europe', 'origin_asia', 'origin_africa']] = df_train[['middle_east', 'balkans', 'south_america', 'north_america', 'eastern_europe', 'western_europe', 'east_asia', 'west_asia', 'west_africa', 'east_africa', 'southern_africa', 'central_africa', 'north_africa', 'oceania', 'origin_america', 'origin_europe', 'origin_asia', 'origin_africa']].fillna(0)\n",
    "df_test[['middle_east', 'balkans', 'south_america', 'north_america', 'eastern_europe', 'western_europe', 'east_asia', 'west_asia', 'west_africa', 'east_africa', 'southern_africa', 'central_africa', 'north_africa', 'oceania', 'origin_america', 'origin_europe', 'origin_asia', 'origin_africa']] = df_test[['middle_east', 'balkans', 'south_america', 'north_america', 'eastern_europe', 'western_europe', 'east_asia', 'west_asia', 'west_africa', 'east_africa', 'southern_africa', 'central_africa', 'north_africa', 'oceania', 'origin_america', 'origin_europe', 'origin_asia', 'origin_africa']].fillna(0)\n",
    "\n",
    "df_train[['middle_east', 'balkans', 'south_america', 'north_america', 'eastern_europe', 'western_europe', 'east_asia', 'west_asia', 'west_africa', 'east_africa', 'southern_africa', 'central_africa', 'north_africa', 'oceania', 'origin_america', 'origin_europe', 'origin_asia', 'origin_africa']] = df_train[['middle_east', 'balkans', 'south_america', 'north_america', 'eastern_europe', 'western_europe', 'east_asia', 'west_asia', 'west_africa', 'east_africa', 'southern_africa', 'central_africa', 'north_africa', 'oceania', 'origin_america', 'origin_europe', 'origin_asia', 'origin_africa']].astype(object)\n",
    "df_test[['middle_east', 'balkans', 'south_america', 'north_america', 'eastern_europe', 'western_europe', 'east_asia', 'west_asia', 'west_africa', 'east_africa', 'southern_africa', 'central_africa', 'north_africa', 'oceania', 'origin_america', 'origin_europe', 'origin_asia', 'origin_africa']] = df_test[['middle_east', 'balkans', 'south_america', 'north_america', 'eastern_europe', 'western_europe', 'east_asia', 'west_asia', 'west_africa', 'east_africa', 'southern_africa', 'central_africa', 'north_africa', 'oceania', 'origin_america', 'origin_europe', 'origin_asia', 'origin_africa']].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059fef87",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1d7ff0",
   "metadata": {},
   "source": [
    "## ***com_reg_ver_win_rate_zegob***\n",
    "com_reg_ver_win_rate 제곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "6cafd1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['com_reg_ver_win_rate_zegob'] = df_train['com_reg_ver_win_rate'] * df_train['com_reg_ver_win_rate']\n",
    "df_test['com_reg_ver_win_rate_zegob'] = df_test['com_reg_ver_win_rate'] * df_test['com_reg_ver_win_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975456a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5df590",
   "metadata": {},
   "source": [
    "## ***as_strategic_ver***\n",
    "(도메인 지식) 특정 사업부(Business Unit이 AS일 때), 특정 사업 영역(Vertical Level1)에 대해 가중치를 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "e8e55c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VL_1_lst = df_train[df_train['it_strategic_ver']!=0]['business_area'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "c3b0f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['as_strategic_ver'] = 0\n",
    "df_test['as_strategic_ver'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "2f242f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['business_area'].isin(VL_1_lst)) & (df_train['business_unit'] == 'AS'), 'as_strategic_ver'] = 1\n",
    "df_test.loc[(df_test['business_area'].isin(VL_1_lst)) & (df_test['business_unit'] == 'AS'), 'as_strategic_ver'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a159eb",
   "metadata": {},
   "source": [
    "## ***asit_strategic_ver***\n",
    "as_strategic_ver이나 it_strategic_ver 값 중 하나라도 1의 값을 가지면 1 값으로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "6ad288f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['asit_strategic_ver'] = 0\n",
    "df_test['asit_strategic_ver'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "1ab8ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['as_strategic_ver'] == 1) | (df_train['it_strategic_ver'] == 1), 'asit_strategic_ver'] = 1\n",
    "df_test.loc[(df_test['as_strategic_ver'] == 1) | (df_test['it_strategic_ver'] == 1), 'asit_strategic_ver'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541dceb8",
   "metadata": {},
   "source": [
    "## ***asid_strategic_ver***\n",
    "as_strategic_ver이나 id_strategic_ver 값 중 하나라도 1의 값을 가지면 1 값으로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "44ec589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['asid_strategic_ver'] = 0\n",
    "df_test['asid_strategic_ver'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "943cd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['as_strategic_ver'] == 1) | (df_train['id_strategic_ver'] == 1), 'asid_strategic_ver'] = 1\n",
    "df_test.loc[(df_test['as_strategic_ver'] == 1) | (df_test['id_strategic_ver'] == 1), 'asid_strategic_ver'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba6eaa",
   "metadata": {},
   "source": [
    "## ***iditas_strategic_ver***\n",
    "Id_strategic_ver이나 it_strategic_ver이나 as_strategic_ver 값 중 하나라도 1의 값을 가지면 1 값으로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "969c5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['iditas_strategic_ver'] = 0\n",
    "df_test['iditas_strategic_ver'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "d187b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['as_strategic_ver'] == 1) | (df_train['id_strategic_ver'] == 1) | (df_train['it_strategic_ver'] == 1), 'iditas_strategic_ver'] = 1\n",
    "df_test.loc[(df_test['as_strategic_ver'] == 1) | (df_test['id_strategic_ver'] == 1) | (df_train['it_strategic_ver'] == 1), 'iditas_strategic_ver'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ab36e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e664af",
   "metadata": {},
   "source": [
    "## ***New_Customer***\n",
    "신규고객 (historical_existing_cnt 이 0인지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "d38a01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Historical_Existing_Cnt 신규고객 여부\n",
    "df_train['New_Customer'] = 0\n",
    "df_test['New_Customer'] = 0\n",
    "\n",
    "df_train.loc[df_train['historical_existing_cnt'] == 0, 'New_Customer'] = 1\n",
    "df_train.loc[df_train['historical_existing_cnt'] > 0, 'New_Customer'] = 0\n",
    "df_train.loc[df_train['historical_existing_cnt'].isna(), 'New_Customer'] = -1\n",
    "\n",
    "df_test.loc[df_test['historical_existing_cnt'] == 0, 'New_Customer'] = 1\n",
    "df_test.loc[df_test['historical_existing_cnt'] > 0, 'New_Customer'] = 0\n",
    "df_test.loc[df_test['historical_existing_cnt'].isna(), 'New_Customer'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "43bc5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['New_Customer'] = df_train['New_Customer'].astype(object)\n",
    "df_test['New_Customer'] = df_test['New_Customer'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263f3ace",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed4f03",
   "metadata": {},
   "source": [
    "## ***is_endcustomer***\n",
    "최종 고객"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "2c2fba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_endcustomer'] =0\n",
    "df_test['is_endcustomer'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "837f3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['customer_type'] == 'End-Customer','is_endcustomer'] =1\n",
    "df_test.loc[df_test['customer_type'] == 'End-Customer','is_endcustomer'] =1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb68167",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3feafb",
   "metadata": {},
   "source": [
    "## ***is_Partner***\n",
    "유통인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "1ebf281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_Partner'] =0\n",
    "df_test['is_Partner'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "bfa988a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['customer_type'].str.contains('Partner'), 'is_Partner'] = 1\n",
    "df_test.loc[df_test['customer_type'].str.contains('Partner'), 'is_Partner'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfb470",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9c4a5",
   "metadata": {},
   "source": [
    "## ***HEC_Group***\n",
    "Historical_Existing_Cnt 그룹핑 (historical_existing_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "3d7febbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Historical_Existing_Cnt 횟수별 그룹핑\n",
    "df_train['HEC_Group'] = \"-\"\n",
    "df_test['HEC_Group'] = \"-\"\n",
    "\n",
    "df_train.loc[df_train['historical_existing_cnt'] >= 0, 'HEC_Group'] = \"newbie\"\n",
    "df_train.loc[df_train['historical_existing_cnt'] >= 10, 'HEC_Group'] = \"Familiar\"\n",
    "df_train.loc[df_train['historical_existing_cnt'] >= 100, 'HEC_Group'] = \"mania\"\n",
    "\n",
    "df_test.loc[df_test['historical_existing_cnt'] >= 0, 'HEC_Group'] = \"Newbie\"\n",
    "df_test.loc[df_test['historical_existing_cnt'] >= 10, 'HEC_Group'] = \"Familiar\"\n",
    "df_test.loc[df_test['historical_existing_cnt'] >= 100, 'HEC_Group'] = \"Mania\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db9037",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab53a1",
   "metadata": {},
   "source": [
    "## ***lead_desc_length***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31604eef",
   "metadata": {},
   "source": [
    "log, sqrt 취하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "0e4ece34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_lead_desc_length'] = np.log1p(df_train['lead_desc_length'])\n",
    "df_test['log_lead_desc_length'] = np.log1p(df_test['lead_desc_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "a42fb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sqrt_lead_desc_length'] = np.sqrt(df_train['lead_desc_length'])\n",
    "df_test['sqrt_lead_desc_length'] = np.sqrt(df_test['lead_desc_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b6404",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d5bf3",
   "metadata": {},
   "source": [
    "## ***product_category***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "96c93010",
   "metadata": {},
   "outputs": [],
   "source": [
    "Commercial_Display = ['oled signage', 'led signage','video wall signage','interactive signage','high brightness signage',\n",
    "                      'special signage', 'standard signage', 'hotel tv', 'hospital tv', 'accessories', 'software solution',\n",
    "                      'signage care solution', 'webos', 'pro:centric', 'one:quick series', 'interactive digital board']\n",
    "\n",
    "IT_PRODUCTS = ['monitor', 'laptop', 'projector', 'cloud device', 'medical display']\n",
    "\n",
    "HVAC_ESS = ['control', 'ventilation', 'vrf', 'multi-split', 'single-split', 'chiller', 'heating','ess']\n",
    "\n",
    "Other = ['other' , 'others', 'etc.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "a4531862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commercial_Display\n",
    "\n",
    "for i in Commercial_Display:\n",
    "    df_train.loc[df_train['product_category'].str.contains(i, case=False, na=False), 'Commercial_Display'] = 1\n",
    "    df_test.loc[df_test['product_category'].str.contains(i, case=False, na=False), 'Commercial_Display'] = 1\n",
    "    \n",
    "df_train['Commercial_Display'] = df_train['Commercial_Display'].fillna(0)\n",
    "df_test['Commercial_Display'] = df_test['Commercial_Display'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "a20e1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT_PRODUCTS\n",
    "\n",
    "for i in IT_PRODUCTS:\n",
    "    df_train.loc[df_train['product_category'].str.contains(i, case=False, na=False), 'IT_PRODUCTS'] = 1\n",
    "    df_test.loc[df_test['product_category'].str.contains(i, case=False, na=False), 'IT_PRODUCTS'] = 1\n",
    "    \n",
    "df_train['IT_PRODUCTS'] = df_train['IT_PRODUCTS'].fillna(0)\n",
    "df_test['IT_PRODUCTS'] = df_test['IT_PRODUCTS'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "902b66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVAC_ESS\n",
    "\n",
    "for i in HVAC_ESS:\n",
    "    df_train.loc[df_train['product_category'].str.contains(i, case=False, na=False), 'HVAC_ESS'] = 1\n",
    "    df_test.loc[df_test['product_category'].str.contains(i, case=False, na=False), 'HVAC_ESS'] = 1\n",
    "    \n",
    "df_train['HVAC_ESS'] = df_train['HVAC_ESS'].fillna(0)\n",
    "df_test['HVAC_ESS'] = df_test['HVAC_ESS'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "f7d8ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other\n",
    "\n",
    "for i in Other:\n",
    "    df_train.loc[df_train['product_category'].str.contains(i, case=False, na=False), 'Other'] = 1\n",
    "    df_test.loc[df_test['product_category'].str.contains(i, case=False, na=False), 'Other'] = 1\n",
    "    \n",
    "df_train['Other'] = df_train['Other'].fillna(0)\n",
    "df_test['Other'] = df_test['Other'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5db71c0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179a018",
   "metadata": {},
   "source": [
    "## ***Respone_Corporate_Continent***\n",
    "Respone_Corporate 대륙별 그룹핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "a2ad2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Respone_Corporate 대륙별 그룹핑\n",
    "df_train['Respone_Corporate_Continent'] = \"-\"\n",
    "df_test['Respone_Corporate_Continent'] = \"-\"\n",
    "\n",
    "Asia = ['LGEIL','LGEPH','LGEVH','LGETK','LGEAP','LGESL','LGEIN','LGETH','LGEML','LGETT','LGEJP']\n",
    "Middle_East = ['LGEGF','LGESJ','LGEEG','LGELF','LGEAS','LGEMC','LGEIR']\n",
    "China = ['LGEHK','LGECH']\n",
    "North_America = ['LGEUS','LGEMS','LGECI']\n",
    "South_America = ['LGESP','LGECB','LGECL','LGEPS','LGEPR','LGEAR','LGEAG']\n",
    "Europe = ['LGEUK','LGEIS','LGEDG','LGEPL','LGEES','LGEMK','LGEFS','LGEPT','LGEBN','LGEHS','LGESW','LGERO','LGEEB','LGERA','LGECZ','LGELA','LGEUR','LGEBT']\n",
    "Africa = ['LGEAF','LGESA','LGEEF','LGEYK']\n",
    "Combination = ['LGEKR']\n",
    "\n",
    "df_train.loc[df_train['response_corporate'].isin(Asia), 'Respone_Corporate_Continent'] = \"Asia\"\n",
    "df_train.loc[df_train['response_corporate'].isin(Middle_East), 'Respone_Corporate_Continent'] = \"Middle_East\"\n",
    "df_train.loc[df_train['response_corporate'].isin(China), 'Respone_Corporate_Continent'] = \"China\"\n",
    "df_train.loc[df_train['response_corporate'].isin(North_America), 'Respone_Corporate_Continent'] = \"North_America\"\n",
    "df_train.loc[df_train['response_corporate'].isin(South_America), 'Respone_Corporate_Continent'] = \"South_America\"\n",
    "df_train.loc[df_train['response_corporate'].isin(Europe), 'Respone_Corporate_Continent'] = \"Europe\"\n",
    "df_train.loc[df_train['response_corporate'].isin(Africa), 'Respone_Corporate_Continent'] = \"Africa\"\n",
    "df_train.loc[df_train['response_corporate'].isin(Combination), 'Respone_Corporate_Continent'] = \"Combination\"\n",
    "\n",
    "df_test.loc[df_test['response_corporate'].isin(Asia), 'Respone_Corporate_Continent'] = \"Asia\"\n",
    "df_test.loc[df_test['response_corporate'].isin(Middle_East), 'Respone_Corporate_Continent'] = \"Middle_East\"\n",
    "df_test.loc[df_test['response_corporate'].isin(China), 'Respone_Corporate_Continent'] = \"China\"\n",
    "df_test.loc[df_test['response_corporate'].isin(North_America), 'Respone_Corporate_Continent'] = \"North_America\"\n",
    "df_test.loc[df_test['response_corporate'].isin(South_America), 'Respone_Corporate_Continent'] = \"South_America\"\n",
    "df_test.loc[df_test['response_corporate'].isin(Europe), 'Respone_Corporate_Continent'] = \"Europe\"\n",
    "df_test.loc[df_test['response_corporate'].isin(Africa), 'Respone_Corporate_Continent'] = \"Africa\"\n",
    "df_test.loc[df_test['response_corporate'].isin(Combination), 'Respone_Corporate_Continent'] = \"Combination\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea36e3e2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01476d2d",
   "metadata": {},
   "source": [
    "## ***Expected_Timeline_Quantification***\n",
    "Expected_Timeline별 수치화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "fa63ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected_Timeline별 수치화\n",
    "df_train['Expected_Timeline_Quantification'] = 0\n",
    "df_test['Expected_Timeline_Quantification'] = 0\n",
    "\n",
    "df_train.loc[df_train['expected_timeline'] == 'incomplete', 'Expected_Timeline_Quantification'] = 0\n",
    "df_train.loc[df_train['expected_timeline'] == 'less than 3 months', 'Expected_Timeline_Quantification'] = 1\n",
    "df_train.loc[df_train['expected_timeline'] == '3 months ~ 6 months', 'Expected_Timeline_Quantification'] = 2\n",
    "df_train.loc[df_train['expected_timeline'] == '6 months ~ 9 months', 'Expected_Timeline_Quantification'] = 3\n",
    "df_train.loc[df_train['expected_timeline'] == '9 months ~ 1 year', 'Expected_Timeline_Quantification'] = 4\n",
    "df_train.loc[df_train['expected_timeline'] == 'more than a year', 'Expected_Timeline_Quantification'] = 5\n",
    "\n",
    "df_test.loc[df_test['expected_timeline'] == 'incomplete', 'Expected_Timeline_Quantification'] = 0\n",
    "df_test.loc[df_test['expected_timeline'] == 'less than 3 months', 'Expected_Timeline_Quantification'] = 1\n",
    "df_test.loc[df_test['expected_timeline'] == '3 months ~ 6 months', 'Expected_Timeline_Quantification'] = 2\n",
    "df_test.loc[df_test['expected_timeline'] == '6 months ~ 9 months', 'Expected_Timeline_Quantification'] = 3\n",
    "df_test.loc[df_test['expected_timeline'] == '9 months ~ 1 year', 'Expected_Timeline_Quantification'] = 4\n",
    "df_test.loc[df_test['expected_timeline'] == 'more than a year', 'Expected_Timeline_Quantification'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04ca1e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f34de3",
   "metadata": {},
   "source": [
    "## ***Corporate_Weight***\n",
    "Response_Corporate_Continent별 구매액수별 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "dddd0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response_Corporate_Continent별 구매액수별 가중치\n",
    "df_train['Corporate_Weight'] = 0.0\n",
    "df_test['Corporate_Weight'] = 0.0\n",
    "\n",
    "df_train.loc[df_train['response_corporate'].isin(Asia), 'Corporate_Weight'] = 8.8\n",
    "df_train.loc[df_train['response_corporate'].isin(Middle_East), 'Corporate_Weight'] = 0.1\n",
    "df_train.loc[df_train['response_corporate'].isin(China), 'Corporate_Weight'] = 5.4\n",
    "df_train.loc[df_train['response_corporate'].isin(North_America), 'Corporate_Weight'] = 5.7\n",
    "df_train.loc[df_train['response_corporate'].isin(South_America), 'Corporate_Weight'] = 5.7\n",
    "df_train.loc[df_train['response_corporate'].isin(Europe), 'Corporate_Weight'] = 3.2\n",
    "df_train.loc[df_train['response_corporate'].isin(Africa), 'Corporate_Weight'] = 0.1\n",
    "df_train.loc[df_train['response_corporate'].isin(Combination), 'Corporate_Weight'] = 4.1\n",
    "\n",
    "df_test.loc[df_test['response_corporate'].isin(Asia), 'Corporate_Weight'] = 8.8\n",
    "df_test.loc[df_test['response_corporate'].isin(Middle_East), 'Corporate_Weight'] = 0.1\n",
    "df_test.loc[df_test['response_corporate'].isin(China), 'Corporate_Weight'] = 5.4\n",
    "df_test.loc[df_test['response_corporate'].isin(North_America), 'Corporate_Weight'] = 5.7\n",
    "df_test.loc[df_test['response_corporate'].isin(South_America), 'Corporate_Weight'] = 5.7\n",
    "df_test.loc[df_test['response_corporate'].isin(Europe), 'Corporate_Weight'] = 3.2\n",
    "df_test.loc[df_test['response_corporate'].isin(Africa), 'Corporate_Weight'] = 0.1\n",
    "df_test.loc[df_test['response_corporate'].isin(Combination), 'Corporate_Weight'] = 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84428b8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a87a5a",
   "metadata": {},
   "source": [
    "## ***Business_Area_Main***\n",
    "Business_Area별 영업성공률에 기반한 그룹핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "627a172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Business_Area별 영업성공률에 기반한 그룹핑\n",
    "df_train['Business_Area_Main'] = 0\n",
    "df_test['Business_Area_Main'] = 0\n",
    "\n",
    "main_area = ['hospital & health care','power plant / renewable energy']\n",
    "\n",
    "df_train.loc[df_train['business_area'].isin(main_area), 'Business_Area_Main'] = 1\n",
    "df_train.loc[~df_train['business_area'].isin(main_area), 'Business_Area_Main'] = 0\n",
    "df_train.loc[df_train['business_area'] == 'Not entered', 'Business_Area_Main'] = -1\n",
    "\n",
    "df_test.loc[df_test['business_area'].isin(main_area), 'Business_Area_Main'] = 1\n",
    "df_test.loc[~df_test['business_area'].isin(main_area), 'Business_Area_Main'] = 0\n",
    "df_test.loc[df_test['business_area'] == 'Not entered', 'Business_Area_Main'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "818bd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Business_Area_Main'] = df_train['Business_Area_Main'].astype(object)\n",
    "df_test['Business_Area_Main'] = df_test['Business_Area_Main'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f34c1f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37612157",
   "metadata": {},
   "source": [
    "## ***Business_Subarea_Main***\n",
    "Business_Subarea별 영업성공률에 기반한 그룹핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "0b9aa607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Business_Subarea별 영업성공률에 기반한 그룹핑\n",
    "df_train['Business_Subarea_Main'] = 0\n",
    "df_test['Business_Subarea_Main'] = 0\n",
    "\n",
    "df_train.loc[df_train['business_subarea'] == 'Health', 'Business_Subarea_Main'] = 1\n",
    "df_train.loc[df_train['business_subarea'] != 'Health', 'Business_Subarea_Main'] = 0\n",
    "df_train.loc[df_train['business_subarea'] == 'Not entered', 'Business_Subarea_Main'] = -1\n",
    "\n",
    "df_test.loc[df_test['business_subarea'] == 'Health', 'Business_Subarea_Main'] = 1\n",
    "df_test.loc[df_test['business_subarea'] != 'Health', 'Business_Subarea_Main'] = 0\n",
    "df_test.loc[df_test['business_subarea'] == 'Not entered', 'Business_Subarea_Main'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "14a66e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Business_Subarea_Main'] = df_train['Business_Subarea_Main'].astype(object)\n",
    "df_test['Business_Subarea_Main'] = df_test['Business_Subarea_Main'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f01e80",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad375da1",
   "metadata": {},
   "source": [
    "## ***🍕추가적인 피쳐 생성🍕***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7337669a",
   "metadata": {},
   "source": [
    "## ***customer_history and historical_existing_cnt***\n",
    "customer_history가 Non    vs.    customer_history 있으면서 cnt가 0인거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "86f2db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['maybe_newbie'] = 0\n",
    "df_test['maybe_newbie'] = 0\n",
    "\n",
    "df_train['exist_0'] = 0\n",
    "df_test['exist_0'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "35f109a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['customer_history'] == 'New') | (df_train['historical_existing_cnt'] == 0), 'maybe_newbie'] = 1\n",
    "df_test.loc[(df_test['customer_history'] == 'New') | (df_test['historical_existing_cnt'] == 0), 'maybe_newbie'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "634b3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['historical_existing_cnt'] == 0), 'exist_0'] = 1\n",
    "df_test.loc[(df_test['historical_existing_cnt'] == 0), 'exist_0'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e82a726",
   "metadata": {},
   "source": [
    "## ***enterprise_country***\n",
    "enterprise와 country 묶은 카테고리컬 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "39e6cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['enterprise_country'] = df_train['customer_country'] + '_' + df_train['enterprise']\n",
    "df_test['enterprise_country'] = df_test['customer_country'] + '_' + df_test['enterprise']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9b2ba4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fc78e",
   "metadata": {},
   "source": [
    "## ***country_corp***\n",
    "country와 corporate 묶은 카테고리컬 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "9b0f2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['country_corp'] = df_train['customer_country'] + '_' + df_train['response_corporate']\n",
    "df_test['country_corp'] = df_test['customer_country'] + '_' + df_test['response_corporate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374846b8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d521a",
   "metadata": {},
   "source": [
    "## ***high_level customer_postion***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "7899d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['high_level'] = 0\n",
    "df_train.loc[df_train['customer_position']=='ceo/founder','high_level'] = 1\n",
    "df_train.loc[df_train['customer_position']=='vice president','high_level'] = 1\n",
    "df_train.loc[df_train['customer_position']=='manager','high_level']  = 1\n",
    "df_train.loc[df_train['customer_position']=='director','high_level'] = 1\n",
    "\n",
    "df_test['high_level'] = 0\n",
    "df_test.loc[df_test['customer_position']=='ceo/founder','high_level'] = 1\n",
    "df_test.loc[df_test['customer_position']=='vice president','high_level'] = 1\n",
    "df_test.loc[df_test['customer_position']=='manager','high_level']  = 1\n",
    "df_test.loc[df_test['customer_position']=='director','high_level'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a2edc5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e14e82",
   "metadata": {},
   "source": [
    "## ***business_unit_area***\n",
    "business_unit과 business_area 묶은 카테고리컬 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "b6b057fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['business_unit_area'] = df_train['business_unit'] + '_' + df_train['business_area']\n",
    "df_test['business_unit_area'] = df_test['business_unit'] + '_' + df_test['business_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9a251",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feee2b5",
   "metadata": {},
   "source": [
    "## ***corporate_unit***\n",
    "response_corporate와 business_unit 묶은 카테고리컬 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "dce1c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['corporate_unit'] = df_train['response_corporate'] + '_' + df_train['business_unit']\n",
    "df_test['corporate_unit'] = df_test['response_corporate'] + '_' + df_test['business_unit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed6c24",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf334d",
   "metadata": {},
   "source": [
    "## ***job_product*** (job + category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "4b4e4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['job_product'] = df_train['customer_job'] +'_'+ df_train['product_category']\n",
    "df_test['job_product'] = df_test['customer_job'] +'_'+ df_test['product_category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa6d5b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba7ecb",
   "metadata": {},
   "source": [
    "## ***country_corp_status 1 2***\n",
    "country와 corporate의 일치여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "6ae54af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['country_corp_status'] = 0\n",
    "df_test['country_corp_status'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "34be1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['response_corporate'].isin(['LGEKR', 'LGEAF', 'LGEEF', 'LGEEB', 'LGELA']), 'country_corp_status'] = None\n",
    "df_test.loc[df_test['response_corporate'].isin(['LGEKR', 'LGEAF', 'LGEEF', 'LGEEB', 'LGELA']), 'country_corp_status'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "9165b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGEAF_lst = ['Nigeria', 'Benin', 'Ghana', 'Congo', 'Togo', 'Mauritania', 'Senegal', 'Ivory Coast', 'Mali',\n",
    "       'Central African Republic', 'Angola', 'Sierra Leone', 'Cameroon', 'Burkina Faso', 'Gambia', 'Gabon', 'Guinea', 'Liberia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "2f39eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['customer_country'].isin(LGEAF_lst)) & (df_train['response_corporate'] == 'LGEAF'), 'country_corp_status'] = 1\n",
    "\n",
    "df_train.loc[(df_train['customer_country'] == 'India') & (df_train['response_corporate'] == 'LGEIL'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Brazil') & (df_train['response_corporate'] == 'LGESP'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'United States') & (df_train['response_corporate'] == 'LGEUS'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Mexico') & (df_train['response_corporate'] == 'LGEMS'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Philippines') & (df_train['response_corporate'] == 'LGEPH'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'United Arab Emirates') & (df_train['response_corporate'] == 'LGEGF'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Colombia') & (df_train['response_corporate'] == 'LGECB'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'United Kingdom') & (df_train['response_corporate'] == 'LGEUK'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Saudi Arabia') & (df_train['response_corporate'] == 'LGESJ'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Chile') & (df_train['response_corporate'] == 'LGECL'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Panama') & (df_train['response_corporate'] == 'LGEPS'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Italy') & (df_train['response_corporate'] == 'LGEIS'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Peru') & (df_train['response_corporate'] == 'LGEPR'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Germany') & (df_train['response_corporate'] == 'LGEDG'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Poland') & (df_train['response_corporate'] == 'LGEPL'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Egypt') & (df_train['response_corporate'] == 'LGEEG'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'VietNam') & (df_train['response_corporate'] == 'LGEVH'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Spain') & (df_train['response_corporate'] == 'LGEES'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Turkey') & (df_train['response_corporate'] == 'LGETK'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Hong Kong') & (df_train['response_corporate'] == 'LGEHK'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Australia') & (df_train['response_corporate'] == 'LGEAP'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Singapore') & (df_train['response_corporate'] == 'LGESL'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Hungary') & (df_train['response_corporate'] == 'LGEMK'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'France') & (df_train['response_corporate'] == 'LGEFS'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Indonesia') & (df_train['response_corporate'] == 'LGEIN'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Iraq') & (df_train['response_corporate'] == 'LGELF'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'South Africa') & (df_train['response_corporate'] == 'LGESA'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Canada') & (df_train['response_corporate'] == 'LGECI'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Thailand') & (df_train['response_corporate'] == 'LGETH'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Portugal') & (df_train['response_corporate'] == 'LGEPT'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Malaysia') & (df_train['response_corporate'] == 'LGEML'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Netherlands') & (df_train['response_corporate'] == 'LGEBN'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Israel') & (df_train['response_corporate'] == 'LGEYK'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'China') & (df_train['response_corporate'] == 'LGECH'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Greece') & (df_train['response_corporate'] == 'LGEHS'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Taiwan') & (df_train['response_corporate'] == 'LGETT'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Japan') & (df_train['response_corporate'] == 'LGEJP'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Algeria') & (df_train['response_corporate'] == 'LGEAS'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Sweden') & (df_train['response_corporate'] == 'LGESW'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Morocco') & (df_train['response_corporate'] == 'LGEMC'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Romania') & (df_train['response_corporate'] == 'LGERO'), 'country_corp_status'] = 1\n",
    "\n",
    "df_train['country_corp_status'] = np.where(\n",
    "    (df_train['customer_country'] == 'Argentina') & ~(df_train['response_corporate'].isin(['LGEAR', 'LGEAG'])),\n",
    "    1,\n",
    "    df_train['country_corp_status']\n",
    ")\n",
    "# df_train.loc[(df_train['customer_country'] == 'Argentina') & (df_train['response_corporate'] == 'LGEAR'), 'country_corp_status'] = 1\n",
    "# df_train.loc[(df_train['customer_country'] == 'Argentina') & (df_train['response_corporate'] == 'LGEAG'), 'country_corp_status'] = 1\n",
    "\n",
    "df_train.loc[(df_train['customer_country'] == 'Russia') & (df_train['response_corporate'] == 'LGERA'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Czech') & (df_train['response_corporate'] == 'LGECZ'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Ukraine') & (df_train['response_corporate'] == 'LGEUR'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Iran') & (df_train['response_corporate'] == 'LGEIR'), 'country_corp_status'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Portugal') & (df_train['response_corporate'] == 'LGEBT'), 'country_corp_status'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "4aa5f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[(df_test['customer_country'].isin(LGEAF_lst)) & (df_test['response_corporate'] == 'LGEAF'), 'country_corp_status'] = 1\n",
    "\n",
    "df_test.loc[(df_test['customer_country'] == 'India') & (df_test['response_corporate'] == 'LGEIL'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Brazil') & (df_test['response_corporate'] == 'LGESP'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'United States') & (df_test['response_corporate'] == 'LGEUS'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Mexico') & (df_test['response_corporate'] == 'LGEMS'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Philippines') & (df_test['response_corporate'] == 'LGEPH'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'United Arab Emirates') & (df_test['response_corporate'] == 'LGEGF'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Colombia') & (df_test['response_corporate'] == 'LGECB'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'United Kingdom') & (df_test['response_corporate'] == 'LGEUK'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Saudi Arabia') & (df_test['response_corporate'] == 'LGESJ'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Chile') & (df_test['response_corporate'] == 'LGECL'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Panama') & (df_test['response_corporate'] == 'LGEPS'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Italy') & (df_test['response_corporate'] == 'LGEIS'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Peru') & (df_test['response_corporate'] == 'LGEPR'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Germany') & (df_test['response_corporate'] == 'LGEDG'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Poland') & (df_test['response_corporate'] == 'LGEPL'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Egypt') & (df_test['response_corporate'] == 'LGEEG'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'VietNam') & (df_test['response_corporate'] == 'LGEVH'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Spain') & (df_test['response_corporate'] == 'LGEES'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Turkey') & (df_test['response_corporate'] == 'LGETK'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Hong Kong') & (df_test['response_corporate'] == 'LGEHK'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Australia') & (df_test['response_corporate'] == 'LGEAP'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Singapore') & (df_test['response_corporate'] == 'LGESL'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Hungary') & (df_test['response_corporate'] == 'LGEMK'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'France') & (df_test['response_corporate'] == 'LGEFS'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Indonesia') & (df_test['response_corporate'] == 'LGEIN'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Iraq') & (df_test['response_corporate'] == 'LGELF'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'South Africa') & (df_test['response_corporate'] == 'LGESA'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Canada') & (df_test['response_corporate'] == 'LGECI'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Thailand') & (df_test['response_corporate'] == 'LGETH'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Portugal') & (df_test['response_corporate'] == 'LGEPT'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Malaysia') & (df_test['response_corporate'] == 'LGEML'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Netherlands') & (df_test['response_corporate'] == 'LGEBN'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Israel') & (df_test['response_corporate'] == 'LGEYK'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'China') & (df_test['response_corporate'] == 'LGECH'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Greece') & (df_test['response_corporate'] == 'LGEHS'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Taiwan') & (df_test['response_corporate'] == 'LGETT'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Japan') & (df_test['response_corporate'] == 'LGEJP'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Algeria') & (df_test['response_corporate'] == 'LGEAS'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Sweden') & (df_test['response_corporate'] == 'LGESW'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Morocco') & (df_test['response_corporate'] == 'LGEMC'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Romania') & (df_test['response_corporate'] == 'LGERO'), 'country_corp_status'] = 1\n",
    "\n",
    "df_test['country_corp_status'] = np.where(\n",
    "    (df_test['customer_country'] == 'Argentina') & ~(df_test['response_corporate'].isin(['LGEAR', 'LGEAG'])),\n",
    "    1,\n",
    "    df_test['country_corp_status']\n",
    ")\n",
    "# df_test.loc[(df_test['customer_country'] == 'Argentina') & (df_test['response_corporate'] == 'LGEAR'), 'country_corp_status'] = 1\n",
    "# df_test.loc[(df_test['customer_country'] == 'Argentina') & (df_test['response_corporate'] == 'LGEAG'), 'country_corp_status'] = 1\n",
    "\n",
    "df_test.loc[(df_test['customer_country'] == 'Russia') & (df_test['response_corporate'] == 'LGERA'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Czech') & (df_test['response_corporate'] == 'LGECZ'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Ukraine') & (df_test['response_corporate'] == 'LGEUR'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Iran') & (df_test['response_corporate'] == 'LGEIR'), 'country_corp_status'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Portugal') & (df_test['response_corporate'] == 'LGEBT'), 'country_corp_status'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03bbce1",
   "metadata": {},
   "source": [
    "##### 추가생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "58ba0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['country_corp_status_1'] = 0\n",
    "df_test['country_corp_status_1'] = 0\n",
    "\n",
    "df_train['country_corp_status_2'] = 0\n",
    "df_test['country_corp_status_2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "f18c671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['response_corporate'].isin(['LGEKR', 'LGEAF', 'LGEEF', 'LGEEB', 'LGELA']), 'country_corp_status_1'] = None\n",
    "df_test.loc[df_test['response_corporate'].isin(['LGEKR', 'LGEAF', 'LGEEF', 'LGEEB', 'LGELA']), 'country_corp_status_1'] = None\n",
    "\n",
    "df_train.loc[(~df_train['customer_country'].isin(LGEAF_lst)) & (df_train['response_corporate'] == 'LGEAF'), 'country_corp_status_1'] = 1\n",
    "\n",
    "df_train.loc[(df_train['customer_country'] != 'India') & (df_train['response_corporate'] == 'LGEIL'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Brazil') & (df_train['response_corporate'] == 'LGESP'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'United States') & (df_train['response_corporate'] == 'LGEUS'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Mexico') & (df_train['response_corporate'] == 'LGEMS'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Philippines') & (df_train['response_corporate'] == 'LGEPH'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'United Arab Emirates') & (df_train['response_corporate'] == 'LGEGF'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Colombia') & (df_train['response_corporate'] == 'LGECB'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'United Kingdom') & (df_train['response_corporate'] == 'LGEUK'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Saudi Arabia') & (df_train['response_corporate'] == 'LGESJ'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Chile') & (df_train['response_corporate'] == 'LGECL'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Panama') & (df_train['response_corporate'] == 'LGEPS'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Italy') & (df_train['response_corporate'] == 'LGEIS'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Peru') & (df_train['response_corporate'] == 'LGEPR'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Germany') & (df_train['response_corporate'] == 'LGEDG'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Poland') & (df_train['response_corporate'] == 'LGEPL'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Egypt') & (df_train['response_corporate'] == 'LGEEG'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'VietNam') & (df_train['response_corporate'] == 'LGEVH'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Spain') & (df_train['response_corporate'] == 'LGEES'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Turkey') & (df_train['response_corporate'] == 'LGETK'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Hong Kong') & (df_train['response_corporate'] == 'LGEHK'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Australia') & (df_train['response_corporate'] == 'LGEAP'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Singapore') & (df_train['response_corporate'] == 'LGESL'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Hungary') & (df_train['response_corporate'] == 'LGEMK'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'France') & (df_train['response_corporate'] == 'LGEFS'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Indonesia') & (df_train['response_corporate'] == 'LGEIN'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Iraq') & (df_train['response_corporate'] == 'LGELF'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'South Africa') & (df_train['response_corporate'] == 'LGESA'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Canada') & (df_train['response_corporate'] == 'LGECI'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Thailand') & (df_train['response_corporate'] == 'LGETH'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Portugal') & (df_train['response_corporate'] == 'LGEPT'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Malaysia') & (df_train['response_corporate'] == 'LGEML'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Netherlands') & (df_train['response_corporate'] == 'LGEBN'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Israel') & (df_train['response_corporate'] == 'LGEYK'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'China') & (df_train['response_corporate'] == 'LGECH'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Greece') & (df_train['response_corporate'] == 'LGEHS'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Taiwan') & (df_train['response_corporate'] == 'LGETT'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Japan') & (df_train['response_corporate'] == 'LGEJP'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Algeria') & (df_train['response_corporate'] == 'LGEAS'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Sweden') & (df_train['response_corporate'] == 'LGESW'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Morocco') & (df_train['response_corporate'] == 'LGEMC'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Romania') & (df_train['response_corporate'] == 'LGERO'), 'country_corp_status_1'] = 1\n",
    "\n",
    "df_train['country_corp_status_1'] = np.where(\n",
    "    (df_train['customer_country'] != 'Argentina') & ~(df_train['response_corporate'].isin(['LGEAR', 'LGEAG'])),\n",
    "    1,\n",
    "    df_train['country_corp_status_1']\n",
    ")\n",
    "# df_train.loc[(df_train['customer_country'] != 'Argentina') & (df_train['response_corporate'] == 'LGEAR'), 'country_corp_status_1'] = 1\n",
    "# df_train.loc[(df_train['customer_country'] != 'Argentina') & (df_train['response_corporate'] == 'LGEAG'), 'country_corp_status_1'] = 1\n",
    "\n",
    "df_train.loc[(df_train['customer_country'] != 'Russia') & (df_train['response_corporate'] == 'LGERA'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Czech') & (df_train['response_corporate'] == 'LGECZ'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Ukraine') & (df_train['response_corporate'] == 'LGEUR'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Iran') & (df_train['response_corporate'] == 'LGEIR'), 'country_corp_status_1'] = 1\n",
    "df_train.loc[(df_train['customer_country'] != 'Portugal') & (df_train['response_corporate'] == 'LGEBT'), 'country_corp_status_1'] = 1\n",
    "\n",
    "df_test.loc[(df_test['customer_country'].isin(LGEAF_lst)) & (df_test['response_corporate'] == 'LGEAF'), 'country_corp_status_1'] = 1\n",
    "\n",
    "df_test.loc[(df_test['customer_country'] != 'India') & (df_test['response_corporate'] == 'LGEIL'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Brazil') & (df_test['response_corporate'] == 'LGESP'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'United States') & (df_test['response_corporate'] == 'LGEUS'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Mexico') & (df_test['response_corporate'] == 'LGEMS'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Philippines') & (df_test['response_corporate'] == 'LGEPH'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'United Arab Emirates') & (df_test['response_corporate'] == 'LGEGF'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Colombia') & (df_test['response_corporate'] == 'LGECB'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'United Kingdom') & (df_test['response_corporate'] == 'LGEUK'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Saudi Arabia') & (df_test['response_corporate'] == 'LGESJ'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Chile') & (df_test['response_corporate'] == 'LGECL'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Panama') & (df_test['response_corporate'] == 'LGEPS'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Italy') & (df_test['response_corporate'] == 'LGEIS'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Peru') & (df_test['response_corporate'] == 'LGEPR'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Germany') & (df_test['response_corporate'] == 'LGEDG'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Poland') & (df_test['response_corporate'] == 'LGEPL'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Egypt') & (df_test['response_corporate'] == 'LGEEG'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'VietNam') & (df_test['response_corporate'] == 'LGEVH'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Spain') & (df_test['response_corporate'] == 'LGEES'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Turkey') & (df_test['response_corporate'] == 'LGETK'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Hong Kong') & (df_test['response_corporate'] == 'LGEHK'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Australia') & (df_test['response_corporate'] == 'LGEAP'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Singapore') & (df_test['response_corporate'] == 'LGESL'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Hungary') & (df_test['response_corporate'] == 'LGEMK'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'France') & (df_test['response_corporate'] == 'LGEFS'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Indonesia') & (df_test['response_corporate'] == 'LGEIN'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Iraq') & (df_test['response_corporate'] == 'LGELF'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'South Africa') & (df_test['response_corporate'] == 'LGESA'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Canada') & (df_test['response_corporate'] == 'LGECI'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Thailand') & (df_test['response_corporate'] == 'LGETH'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Portugal') & (df_test['response_corporate'] == 'LGEPT'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Malaysia') & (df_test['response_corporate'] == 'LGEML'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Netherlands') & (df_test['response_corporate'] == 'LGEBN'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Israel') & (df_test['response_corporate'] == 'LGEYK'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'China') & (df_test['response_corporate'] == 'LGECH'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Greece') & (df_test['response_corporate'] == 'LGEHS'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Taiwan') & (df_test['response_corporate'] == 'LGETT'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Japan') & (df_test['response_corporate'] == 'LGEJP'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Algeria') & (df_test['response_corporate'] == 'LGEAS'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Sweden') & (df_test['response_corporate'] == 'LGESW'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Morocco') & (df_test['response_corporate'] == 'LGEMC'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Romania') & (df_test['response_corporate'] == 'LGERO'), 'country_corp_status_1'] = 1\n",
    "\n",
    "df_test['country_corp_status_1'] = np.where(\n",
    "    (df_test['customer_country'] != 'Argentina') & ~(df_test['response_corporate'].isin(['LGEAR', 'LGEAG'])),\n",
    "    1,\n",
    "    df_test['country_corp_status_1']\n",
    ")\n",
    "# df_test.loc[(df_test['customer_country'] != 'Argentina') & (df_test['response_corporate'] == 'LGEAR'), 'country_corp_status_1'] = 1\n",
    "# df_test.loc[(df_test['customer_country'] != 'Argentina') & (df_test['response_corporate'] == 'LGEAG'), 'country_corp_status_1'] = 1\n",
    "\n",
    "df_test.loc[(df_test['customer_country'] != 'Russia') & (df_test['response_corporate'] == 'LGERA'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Czech') & (df_test['response_corporate'] == 'LGECZ'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Ukraine') & (df_test['response_corporate'] == 'LGEUR'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Iran') & (df_test['response_corporate'] == 'LGEIR'), 'country_corp_status_1'] = 1\n",
    "df_test.loc[(df_test['customer_country'] != 'Portugal') & (df_test['response_corporate'] == 'LGEBT'), 'country_corp_status_1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "4d9a28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['response_corporate'].isin(['LGEKR', 'LGEAF', 'LGEEF', 'LGEEB', 'LGELA']), 'country_corp_status_2'] = None\n",
    "df_test.loc[df_test['response_corporate'].isin(['LGEKR', 'LGEAF', 'LGEEF', 'LGEEB', 'LGELA']), 'country_corp_status_2'] = None\n",
    "\n",
    "df_train.loc[(df_train['customer_country'].isin(LGEAF_lst)) & (df_train['response_corporate'] != 'LGEAF'), 'country_corp_status_2'] = 1\n",
    "\n",
    "df_train.loc[(df_train['customer_country'] == 'India') & (df_train['response_corporate'] != 'LGEIL'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Brazil') & (df_train['response_corporate'] != 'LGESP'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'United States') & (df_train['response_corporate'] != 'LGEUS'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Mexico') & (df_train['response_corporate'] != 'LGEMS'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Philippines') & (df_train['response_corporate'] != 'LGEPH'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'United Arab Emirates') & (df_train['response_corporate'] != 'LGEGF'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Colombia') & (df_train['response_corporate'] != 'LGECB'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'United Kingdom') & (df_train['response_corporate'] != 'LGEUK'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Saudi Arabia') & (df_train['response_corporate'] != 'LGESJ'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Chile') & (df_train['response_corporate'] != 'LGECL'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Panama') & (df_train['response_corporate'] != 'LGEPS'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Italy') & (df_train['response_corporate'] != 'LGEIS'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Peru') & (df_train['response_corporate'] != 'LGEPR'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Germany') & (df_train['response_corporate'] != 'LGEDG'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Poland') & (df_train['response_corporate'] != 'LGEPL'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Egypt') & (df_train['response_corporate'] != 'LGEEG'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'VietNam') & (df_train['response_corporate'] != 'LGEVH'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Spain') & (df_train['response_corporate'] != 'LGEES'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Turkey') & (df_train['response_corporate'] != 'LGETK'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Hong Kong') & (df_train['response_corporate'] != 'LGEHK'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Australia') & (df_train['response_corporate'] != 'LGEAP'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Singapore') & (df_train['response_corporate'] != 'LGESL'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Hungary') & (df_train['response_corporate'] != 'LGEMK'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'France') & (df_train['response_corporate'] != 'LGEFS'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Indonesia') & (df_train['response_corporate'] != 'LGEIN'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Iraq') & (df_train['response_corporate'] != 'LGELF'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'South Africa') & (df_train['response_corporate'] != 'LGESA'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Canada') & (df_train['response_corporate'] != 'LGECI'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Thailand') & (df_train['response_corporate'] != 'LGETH'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Portugal') & (df_train['response_corporate'] != 'LGEPT'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Malaysia') & (df_train['response_corporate'] != 'LGEML'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Netherlands') & (df_train['response_corporate'] != 'LGEBN'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Israel') & (df_train['response_corporate'] != 'LGEYK'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'China') & (df_train['response_corporate'] != 'LGECH'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Greece') & (df_train['response_corporate'] != 'LGEHS'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Taiwan') & (df_train['response_corporate'] != 'LGETT'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Japan') & (df_train['response_corporate'] != 'LGEJP'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Algeria') & (df_train['response_corporate'] != 'LGEAS'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Sweden') & (df_train['response_corporate'] != 'LGESW'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Morocco') & (df_train['response_corporate'] != 'LGEMC'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Romania') & (df_train['response_corporate'] != 'LGERO'), 'country_corp_status_2'] = 1\n",
    "\n",
    "df_train['country_corp_status_2'] = np.where(\n",
    "    (df_train['customer_country'] == 'Argentina') & ~(df_train['response_corporate'].isin(['LGEAR', 'LGEAG'])),\n",
    "    1,\n",
    "    df_train['country_corp_status_2']\n",
    ")\n",
    "# df_train.loc[(df_train['customer_country'] == 'Argentina') & (df_train['response_corporate'] != 'LGEAR'), 'country_corp_status_2'] = 1\n",
    "# df_train.loc[(df_train['customer_country'] == 'Argentina') & (df_train['response_corporate'] != 'LGEAG'), 'country_corp_status_2'] = 1\n",
    "\n",
    "df_train.loc[(df_train['customer_country'] == 'Russia') & (df_train['response_corporate'] != 'LGERA'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Czech') & (df_train['response_corporate'] != 'LGECZ'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Ukraine') & (df_train['response_corporate'] != 'LGEUR'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Iran') & (df_train['response_corporate'] != 'LGEIR'), 'country_corp_status_2'] = 1\n",
    "df_train.loc[(df_train['customer_country'] == 'Portugal') & (df_train['response_corporate'] != 'LGEBT'), 'country_corp_status_2'] = 1\n",
    "\n",
    "df_test.loc[(df_test['customer_country'].isin(LGEAF_lst)) & (df_test['response_corporate'] != 'LGEAF'), 'country_corp_status_2'] = 1\n",
    "\n",
    "df_test.loc[(df_test['customer_country'] == 'India') & (df_test['response_corporate'] != 'LGEIL'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Brazil') & (df_test['response_corporate'] != 'LGESP'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'United States') & (df_test['response_corporate'] != 'LGEUS'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Mexico') & (df_test['response_corporate'] != 'LGEMS'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Philippines') & (df_test['response_corporate'] != 'LGEPH'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'United Arab Emirates') & (df_test['response_corporate'] != 'LGEGF'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Colombia') & (df_test['response_corporate'] != 'LGECB'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'United Kingdom') & (df_test['response_corporate'] != 'LGEUK'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Saudi Arabia') & (df_test['response_corporate'] != 'LGESJ'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Chile') & (df_test['response_corporate'] != 'LGECL'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Panama') & (df_test['response_corporate'] != 'LGEPS'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Italy') & (df_test['response_corporate'] != 'LGEIS'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Peru') & (df_test['response_corporate'] != 'LGEPR'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Germany') & (df_test['response_corporate'] != 'LGEDG'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Poland') & (df_test['response_corporate'] != 'LGEPL'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Egypt') & (df_test['response_corporate'] != 'LGEEG'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'VietNam') & (df_test['response_corporate'] != 'LGEVH'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Spain') & (df_test['response_corporate'] != 'LGEES'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Turkey') & (df_test['response_corporate'] != 'LGETK'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Hong Kong') & (df_test['response_corporate'] != 'LGEHK'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Australia') & (df_test['response_corporate'] != 'LGEAP'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Singapore') & (df_test['response_corporate'] != 'LGESL'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Hungary') & (df_test['response_corporate'] != 'LGEMK'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'France') & (df_test['response_corporate'] != 'LGEFS'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Indonesia') & (df_test['response_corporate'] != 'LGEIN'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Iraq') & (df_test['response_corporate'] != 'LGELF'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'South Africa') & (df_test['response_corporate'] != 'LGESA'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Canada') & (df_test['response_corporate'] != 'LGECI'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Thailand') & (df_test['response_corporate'] != 'LGETH'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Portugal') & (df_test['response_corporate'] != 'LGEPT'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Malaysia') & (df_test['response_corporate'] != 'LGEML'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Netherlands') & (df_test['response_corporate'] != 'LGEBN'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Israel') & (df_test['response_corporate'] != 'LGEYK'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'China') & (df_test['response_corporate'] != 'LGECH'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Greece') & (df_test['response_corporate'] != 'LGEHS'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Taiwan') & (df_test['response_corporate'] != 'LGETT'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Japan') & (df_test['response_corporate'] != 'LGEJP'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Algeria') & (df_test['response_corporate'] != 'LGEAS'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Sweden') & (df_test['response_corporate'] != 'LGESW'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Morocco') & (df_test['response_corporate'] != 'LGEMC'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Romania') & (df_test['response_corporate'] != 'LGERO'), 'country_corp_status_2'] = 1\n",
    "\n",
    "df_test['country_corp_status_2'] = np.where(\n",
    "    (df_test['customer_country'] != 'Argentina') & ~(df_test['response_corporate'].isin(['LGEAR', 'LGEAG'])),\n",
    "    1,\n",
    "    df_test['country_corp_status_2']\n",
    ")\n",
    "# df_test.loc[(df_test['customer_country'] == 'Argentina') & (df_test['response_corporate'] != 'LGEAR'), 'country_corp_status_2'] = 1\n",
    "# df_test.loc[(df_test['customer_country'] == 'Argentina') & (df_test['response_corporate'] != 'LGEAG'), 'country_corp_status_2'] = 1\n",
    "\n",
    "df_test.loc[(df_test['customer_country'] == 'Russia') & (df_test['response_corporate'] != 'LGERA'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Czech') & (df_test['response_corporate'] != 'LGECZ'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Ukraine') & (df_test['response_corporate'] != 'LGEUR'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Iran') & (df_test['response_corporate'] != 'LGEIR'), 'country_corp_status_2'] = 1\n",
    "df_test.loc[(df_test['customer_country'] == 'Portugal') & (df_test['response_corporate'] != 'LGEBT'), 'country_corp_status_2'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1222d6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61392882",
   "metadata": {},
   "source": [
    "## ***ratio_rate*** (ver_ 피쳐)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "76bcdd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ratio_rate'] = (df_train['ver_win_ratio_per_bu'] / df_train['ver_win_rate_x']).fillna(0)\n",
    "df_test['ratio_rate'] = (df_test['ver_win_ratio_per_bu'] / df_test['ver_win_rate_x']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "5ee4282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_ratio_rate'] = np.log1p(df_train['ratio_rate'])\n",
    "df_test['log_ratio_rate'] = np.log1p(df_test['ratio_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a9fcd1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0edcb14",
   "metadata": {},
   "source": [
    "## ***수치 Feature***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "b2ec6655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['gob1'] = df_train['ratio_rate'] * df_train['com_reg_ver_win_rate']\n",
    "df_train['gob2'] = df_train['ratio_rate'] * df_train['lead_desc_length']\n",
    "df_train['gob3'] = df_train['ratio_rate'] * df_train['historical_existing_cnt']\n",
    "df_train['gob4'] = df_train['lead_desc_length'] * df_train['historical_existing_cnt']\n",
    "df_train['gob5'] = df_train['lead_desc_length'] * df_train['com_reg_ver_win_rate']\n",
    "df_train['gob6'] = df_train['historical_existing_cnt'] * df_train['com_reg_ver_win_rate']\n",
    "#df_train['gob5'] = df_train['lead_desc_length'] * df_train['com_reg_ver_win_rate']\n",
    "df_train['gob6'] = df_train['historical_existing_cnt'] * df_train['com_reg_ver_win_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "6c29ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['gob1'] = df_test['ratio_rate'] * df_test['com_reg_ver_win_rate']\n",
    "df_test['gob2'] = df_test['ratio_rate'] * df_test['lead_desc_length']\n",
    "df_test['gob3'] = df_test['ratio_rate'] * df_test['historical_existing_cnt']\n",
    "df_test['gob4'] = df_test['lead_desc_length'] * df_test['historical_existing_cnt']\n",
    "df_test['gob5'] = df_test['lead_desc_length'] * df_test['com_reg_ver_win_rate']\n",
    "df_test['gob6'] = df_test['historical_existing_cnt'] * df_test['com_reg_ver_win_rate']\n",
    "#df_test['gob5'] = df_test['lead_desc_length'] * df_test['com_reg_ver_win_rate']\n",
    "df_test['gob6'] = df_test['historical_existing_cnt'] * df_test['com_reg_ver_win_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3314a847",
   "metadata": {},
   "source": [
    "# ***Kmeans***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "932c03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치가 없고 Original 수치형 컬럼만 인덱싱하여 클러스터링 진행(K-means)\n",
    "kmeans_cols = ['bant_submit','lead_desc_length']\n",
    "kmeans_train = df_train[kmeans_cols].copy()\n",
    "kmeans_test = df_test[kmeans_cols].copy()\n",
    "\n",
    "#Elbowpoint를 기준으로 k =3으로 설정\n",
    "k = 3\n",
    "#그룹 수, random_state 설정\n",
    "model = KMeans(n_clusters=k, init='random', n_init=10, max_iter=300, random_state=42)\n",
    "\n",
    "#정규화된 데이터에 학습\n",
    "model.fit(kmeans_train)\n",
    "\n",
    "#클러스터링 결과 각 데이터가 몇 번째 그룹에 속하는지 저장\n",
    "kmeans_train['cluster_1'] = model.predict(kmeans_train)\n",
    "kmeans_test['cluster_1'] = model.predict(kmeans_test)\n",
    "\n",
    "#클러스터 할당\n",
    "df_train['cluster_1'] = kmeans_train['cluster_1'].copy()\n",
    "df_test['cluster_1'] = kmeans_test['cluster_1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "8d5749f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치가 없고 수치형 컬럼만 인덱싱하여 클러스터링 진행\n",
    "kmeans_cols = ['bant_submit_zegob','log_lead_desc_length']\n",
    "kmeans_train = df_train[kmeans_cols].copy()\n",
    "kmeans_test = df_test[kmeans_cols].copy()\n",
    "\n",
    "#Elbowpoint를 기준으로 k =3으로 설정\n",
    "k = 3\n",
    "#그룹 수, random_state 설정\n",
    "model = KMeans(n_clusters=k, init='random', n_init=10, max_iter=300, random_state=42)\n",
    "\n",
    "#정규화된 데이터에 학습\n",
    "model.fit(kmeans_train)\n",
    "\n",
    "#클러스터링 결과 각 데이터가 몇 번째 그룹에 속하는지 저장\n",
    "kmeans_train['cluster_2'] = model.predict(kmeans_train)\n",
    "kmeans_test['cluster_2'] = model.predict(kmeans_test)\n",
    "\n",
    "#클러스터 할당\n",
    "df_train['cluster_2'] = kmeans_train['cluster_2'].copy()\n",
    "df_test['cluster_2'] = kmeans_test['cluster_2'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e629216",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda3666",
   "metadata": {},
   "source": [
    "# ***Target변수 과다생성기😊😊😊😊😊***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "14f3ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56528/56528 [00:13<00:00, 4186.80it/s]\n",
      "100%|██████████| 56528/56528 [00:13<00:00, 4173.01it/s]\n",
      "100%|██████████| 56528/56528 [00:13<00:00, 4182.68it/s]\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## business_unit 넣어주기\n",
    "#######################################\n",
    "business_unit_mean = pd.pivot_table(df_train, values = 'is_converted', index = ['business_unit'], aggfunc = np.mean).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['business_unit_mean'] = df_train.progress_apply(lambda x : business_unit_mean.loc[(business_unit_mean.business_unit == x['business_unit']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "#######################################\n",
    "## business_unit 넣어주기\n",
    "#######################################\n",
    "business_unit_std = pd.pivot_table(df_train, values = 'is_converted', index = ['business_unit'], aggfunc = np.std).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['business_unit_std'] = df_train.progress_apply(lambda x : business_unit_std.loc[(business_unit_std.business_unit == x['business_unit']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "#######################################\n",
    "## business_unit 넣어주기\n",
    "#######################################\n",
    "business_unit_CV = pd.pivot_table(df_train, values = 'is_converted', index = ['business_unit'], aggfunc=lambda x : np.std(x) / 0.0001 if np.mean(x) == 0 else np.std(x) / np.mean(x)).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['business_unit_CV'] = df_train.progress_apply(lambda x : business_unit_CV.loc[(business_unit_CV.business_unit == x['business_unit']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "e79b87e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21341/21341 [00:04<00:00, 4268.77it/s]\n",
      "100%|██████████| 21341/21341 [00:04<00:00, 4281.10it/s]\n",
      "100%|██████████| 21341/21341 [00:05<00:00, 4258.34it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_test['business_unit_mean'] = df_test.progress_apply(lambda x : business_unit_mean.loc[(business_unit_mean.business_unit == x['business_unit']) ,'is_converted'].values[0], axis = 1)\n",
    "df_test['business_unit_std'] = df_test.progress_apply(lambda x : business_unit_std.loc[(business_unit_std.business_unit == x['business_unit']) ,'is_converted'].values[0], axis = 1)\n",
    "df_test['business_unit_CV'] = df_test.progress_apply(lambda x : business_unit_CV.loc[(business_unit_CV.business_unit == x['business_unit']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "fdef4b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56528/56528 [00:13<00:00, 4200.39it/s]\n",
      "100%|██████████| 56528/56528 [00:13<00:00, 4152.10it/s]\n",
      "100%|██████████| 56528/56528 [00:13<00:00, 4198.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## business_area 넣어주기\n",
    "#######################################\n",
    "business_area_mean = pd.pivot_table(df_train, values = 'is_converted', index = ['business_area'], aggfunc = np.mean).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['business_area_mean'] = df_train.progress_apply(lambda x : business_area_mean.loc[(business_area_mean.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "#######################################\n",
    "## business_area 넣어주기\n",
    "#######################################\n",
    "business_area_std = pd.pivot_table(df_train, values = 'is_converted', index = ['business_area'], aggfunc = np.std).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['business_area_std'] = df_train.progress_apply(lambda x : business_area_std.loc[(business_area_std.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "#######################################\n",
    "## business_area 넣어주기\n",
    "#######################################\n",
    "business_area_CV = pd.pivot_table(df_train, values = 'is_converted', index = ['business_area'], aggfunc=lambda x : np.std(x) / 0.0001 if np.mean(x) == 0 else np.std(x) / np.mean(x)).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['business_area_CV'] = df_train.progress_apply(lambda x : business_area_CV.loc[(business_area_CV.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "c2a11321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21341/21341 [00:05<00:00, 4229.56it/s]\n",
      "100%|██████████| 21341/21341 [00:05<00:00, 4189.65it/s]\n",
      "100%|██████████| 21341/21341 [00:04<00:00, 4305.81it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_test['business_area_mean'] = df_test.progress_apply(lambda x : business_area_mean.loc[(business_area_mean.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "df_test['business_area_std'] = df_test.progress_apply(lambda x : business_area_std.loc[(business_area_std.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "df_test['business_area_CV'] = df_test.progress_apply(lambda x : business_area_CV.loc[(business_area_CV.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "80db6a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56528/56528 [00:13<00:00, 4154.76it/s]\n",
      "100%|██████████| 56528/56528 [00:13<00:00, 4234.40it/s]\n",
      "100%|██████████| 56528/56528 [00:13<00:00, 4185.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## customer_type 넣어주기\n",
    "#######################################\n",
    "customer_type_mean = pd.pivot_table(df_train, values = 'is_converted', index = ['customer_type'], aggfunc = np.mean).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['customer_type_mean'] = df_train.progress_apply(lambda x : customer_type_mean.loc[(customer_type_mean.customer_type == x['customer_type']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "#######################################\n",
    "## customer_type 넣어주기\n",
    "#######################################\n",
    "customer_type_std = pd.pivot_table(df_train, values='is_converted', index=['customer_type'], aggfunc=lambda x: np.nanstd(x) if len(x) > 1 else 0).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['customer_type_std'] = df_train.progress_apply(lambda x : customer_type_std.loc[(customer_type_std.customer_type == x['customer_type']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "#######################################\n",
    "## customer_type 넣어주기\n",
    "#######################################\n",
    "customer_type_CV = pd.pivot_table(df_train, values = 'is_converted', index = ['customer_type'], aggfunc=lambda x : np.std(x) / 0.0001 if np.mean(x) == 0 else np.std(x) / np.mean(x)).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['customer_type_CV'] = df_train.progress_apply(lambda x : customer_type_CV.loc[(customer_type_CV.customer_type == x['customer_type']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "fc822b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21341/21341 [00:05<00:00, 4092.90it/s]\n",
      "100%|██████████| 21341/21341 [00:05<00:00, 4111.29it/s]\n",
      "100%|██████████| 21341/21341 [00:05<00:00, 4141.50it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_test['customer_type_mean'] = df_test.progress_apply(lambda x : customer_type_mean.loc[(customer_type_mean.customer_type == x['customer_type']) ,'is_converted'].values[0], axis = 1)\n",
    "df_test['customer_type_std'] = df_test.progress_apply(lambda x : customer_type_std.loc[(customer_type_std.customer_type == x['customer_type']) ,'is_converted'].values[0], axis = 1)\n",
    "df_test['customer_type_CV'] = df_test.progress_apply(lambda x : customer_type_CV.loc[(customer_type_CV.customer_type == x['customer_type']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dbbae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 41500/56528 [00:15<00:05, 2682.59it/s]"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## business_unit, business_area\n",
    "#######################################\n",
    "business_unit_business_area_mean = pd.pivot_table(df_train, values = 'is_converted', index = ['business_unit', 'business_area'], aggfunc = np.mean).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['business_unit_business_area_mean'] = df_train.progress_apply(lambda x : business_unit_business_area_mean.loc[(business_unit_business_area_mean.business_unit == x['business_unit']) & (business_unit_business_area_mean.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "#######################################\n",
    "## business_unit, business_area\n",
    "#######################################\n",
    "business_unit_business_area_std = pd.pivot_table(df_train, values = 'is_converted', index = ['business_unit', 'business_area'], aggfunc=lambda x: np.nanstd(x) if len(x) > 1 else 0).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['business_unit_business_area_std'] = df_train.progress_apply(lambda x : business_unit_business_area_std.loc[(business_unit_business_area_std.business_unit == x['business_unit']) & (business_unit_business_area_std.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "#######################################\n",
    "## business_unit, business_area\n",
    "#######################################\n",
    "business_unit_business_area_CV = pd.pivot_table(df_train, values = 'is_converted', index = ['business_unit', 'business_area'], aggfunc=lambda x : np.std(x) / 0.0001 if np.mean(x) == 0 else np.std(x) / np.mean(x)).reset_index()\n",
    "tqdm.pandas()\n",
    "df_train['business_unit_business_area_CV'] = df_train.progress_apply(lambda x : business_unit_business_area_CV.loc[(business_unit_business_area_CV.business_unit == x['business_unit']) & (business_unit_business_area_CV.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_test['business_unit_business_area_mean'] = df_test.progress_apply(lambda x : business_unit_business_area_mean.loc[(business_unit_business_area_mean.business_unit == x['business_unit']) & (business_unit_business_area_mean.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "df_test['business_unit_business_area_std'] = df_test.progress_apply(lambda x : business_unit_business_area_std.loc[(business_unit_business_area_std.business_unit == x['business_unit']) & (business_unit_business_area_std.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "df_test['business_unit_business_area_CV'] = df_test.progress_apply(lambda x : business_unit_business_area_CV.loc[(business_unit_business_area_CV.business_unit == x['business_unit']) & (business_unit_business_area_CV.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################################\n",
    "# ## customer_type, business_area\n",
    "# #######################################\n",
    "# customer_type_business_area_mean = pd.pivot_table(df_train, values = 'is_converted', index = ['customer_type', 'business_area'], aggfunc=lambda x: np.nanmean(x) if len(x) > 1 else 0).reset_index()\n",
    "# tqdm.pandas()\n",
    "# df_train['customer_type_business_area_mean'] = df_train.progress_apply(lambda x : customer_type_business_area_mean.loc[(customer_type_business_area_mean.customer_type == x['customer_type']) & (customer_type_business_area_mean.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "# #######################################\n",
    "# ## customer_type, business_area\n",
    "# #######################################\n",
    "# customer_type_business_area_std = pd.pivot_table(df_train, values = 'is_converted', index = ['customer_type', 'business_area'], aggfunc=lambda x: np.nanstd(x) if len(x) > 1 else 0).reset_index()\n",
    "# tqdm.pandas()\n",
    "# df_train['customer_type_business_area_std'] = df_train.progress_apply(lambda x : customer_type_business_area_std.loc[(customer_type_business_area_std.customer_type == x['customer_type']) & (customer_type_business_area_std.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "# #######################################\n",
    "# ## customer_type, business_area\n",
    "# #######################################\n",
    "# customer_type_business_area_CV = pd.pivot_table(df_train, values = 'is_converted', index = ['customer_type', 'business_area'], aggfunc=lambda x : np.std(x) / 0.0001 if np.mean(x) == 0 else np.std(x) / np.mean(x)).reset_index()\n",
    "# tqdm.pandas()\n",
    "# df_train['customer_type_business_area_CV'] = df_train.progress_apply(lambda x : customer_type_business_area_CV.loc[(customer_type_business_area_CV.customer_type == x['customer_type']) & (customer_type_business_area_CV.business_area == x['business_area']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "# df_test['customer_type_business_area_mean'] = df_test.progress_apply(lambda x: customer_type_business_area_mean.loc[(customer_type_business_area_mean.customer_type == x['customer_type']) & (customer_type_business_area_mean.business_area == x['business_area']) ,'is_converted'].values[0] if len(customer_type_business_area_mean.loc[(customer_type_business_area_mean.customer_type == x['customer_type']) & (customer_type_business_area_mean.business_area == x['business_area'])]) > 0 else 0, axis=1)\n",
    "# df_test['customer_type_business_area_std'] = df_test.progress_apply(lambda x : customer_type_business_area_std.loc[(customer_type_business_area_std.customer_type == x['customer_type']) & (customer_type_business_area_std.business_area == x['business_area']) ,'is_converted'].values[0] if len(customer_type_business_area_std.loc[(customer_type_business_area_std.customer_type == x['customer_type']) & (customer_type_business_area_std.business_area == x['business_area'])]) > 0 else 0, axis=1)\n",
    "# df_test['customer_type_business_area_CV'] = df_test.progress_apply(lambda x : customer_type_business_area_CV.loc[(customer_type_business_area_CV.customer_type == x['customer_type']) & (customer_type_business_area_CV.business_area == x['business_area']) ,'is_converted'].values[0] if len(customer_type_business_area_CV.loc[(customer_type_business_area_CV.customer_type == x['customer_type']) & (customer_type_business_area_CV.business_area == x['business_area'])]) > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d96969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################################\n",
    "# ## business_area, business_unit , customer_country\n",
    "# #######################################\n",
    "# business_area_business_unit_customer_country_mean = pd.pivot_table(df_train, values = 'is_converted', index = ['business_area', 'business_unit','customer_country'], aggfunc=lambda x: np.nanmean(x) if len(x) > 1 else 0).reset_index()\n",
    "# tqdm.pandas()\n",
    "# df_train['business_area_business_unit_customer_country_mean'] = df_train.progress_apply(lambda x : business_area_business_unit_customer_country_mean.loc[(business_area_business_unit_customer_country_mean.business_area == x['business_area']) & (business_area_business_unit_customer_country_mean.business_unit == x['business_unit']) & (business_area_business_unit_customer_country_mean.customer_country == x['customer_country']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "# #######################################\n",
    "# ## business_area, business_unit, customer_country\n",
    "# #######################################\n",
    "# business_area_business_unit_customer_country_std = pd.pivot_table(df_train, values = 'is_converted', index = ['business_area', 'business_unit','customer_country'], aggfunc=lambda x: np.nanstd(x) if len(x) > 1 else 0).reset_index()\n",
    "# tqdm.pandas()\n",
    "# df_train['business_area_business_unit_customer_country_std'] = df_train.progress_apply(lambda x : business_area_business_unit_customer_country_std.loc[(business_area_business_unit_customer_country_std.business_area == x['business_area']) & (business_area_business_unit_customer_country_std.business_unit == x['business_unit']) & (business_area_business_unit_customer_country_std.customer_country == x['customer_country']) ,'is_converted'].values[0], axis = 1)\n",
    "\n",
    "# #######################################\n",
    "# ## business_area, business_unit, customer_country\n",
    "# #######################################\n",
    "# business_area_business_unit_customer_country_CV = pd.pivot_table(df_train, values = 'is_converted', index = ['business_area', 'business_unit','customer_country'], aggfunc=lambda x : np.std(x) / 0.0001 if np.mean(x) == 0 else np.std(x) / np.mean(x)).reset_index()\n",
    "# tqdm.pandas()\n",
    "# df_train['business_area_business_unit_customer_country_CV'] = df_train.progress_apply(lambda x : business_area_business_unit_customer_country_CV.loc[(business_area_business_unit_customer_country_CV.business_area == x['business_area']) & (business_area_business_unit_customer_country_CV.business_unit == x['business_unit']) & (business_area_business_unit_customer_country_CV.customer_country == x['customer_country']) ,'is_converted'].values[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20506fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "# df_test['business_area_business_unit_customer_country_mean'] = df_test.progress_apply(lambda x : business_area_business_unit_customer_country_mean.loc[(business_area_business_unit_customer_country_mean.customer_country == x['customer_country']) & (business_area_business_unit_customer_country_mean.business_area == x['business_area']) & (business_area_business_unit_customer_country_mean.customer_country == x['customer_country']) ,'is_converted'].values[0] if len(business_area_business_unit_customer_country_mean.loc[(business_area_business_unit_customer_country_mean.customer_country == x['customer_country']) & (business_area_business_unit_customer_country_mean.business_area == x['business_area'])  & (business_area_business_unit_customer_country_mean.customer_country == x['customer_country'])]) > 0 else 0, axis=1)\n",
    "# df_test['business_area_business_unit_customer_country_std'] = df_test.progress_apply(lambda x : business_area_business_unit_customer_country_std.loc[(business_area_business_unit_customer_country_std.customer_country == x['customer_country']) & (business_area_business_unit_customer_country_std.business_area == x['business_area']) & (business_area_business_unit_customer_country_std.customer_country == x['customer_country']) ,'is_converted'].values[0] if len(business_area_business_unit_customer_country_std.loc[(business_area_business_unit_customer_country_std.customer_country == x['customer_country']) & (business_area_business_unit_customer_country_std.business_area == x['business_area']) & (business_area_business_unit_customer_country_std.customer_country == x['customer_country'])]) > 0 else 0, axis=1)\n",
    "# df_test['business_area_business_unit_customer_country_CV'] = df_test.progress_apply(lambda x : business_area_business_unit_customer_country_CV.loc[(business_area_business_unit_customer_country_CV.customer_country == x['customer_country']) & (business_area_business_unit_customer_country_CV.business_area == x['business_area']) & (business_area_business_unit_customer_country_CV.customer_country == x['customer_country']) ,'is_converted'].values[0] if len(business_area_business_unit_customer_country_CV.loc[(business_area_business_unit_customer_country_CV.customer_country == x['customer_country']) & (business_area_business_unit_customer_country_CV.business_area == x['business_area']) & (business_area_business_unit_customer_country_CV.customer_country == x['customer_country'])]) > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaef882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108dea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('중복 값 :',len(df_train[df_train.duplicated()]))\n",
    "df_train = df_train.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttmp = df_train.drop(columns = 'is_converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d83968",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('중복 값 :',len(ttmp[ttmp.duplicated(keep=False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(ttmp[ttmp.duplicated(keep = False)].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7873879",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd47e00",
   "metadata": {},
   "source": [
    "## 3. Encoding & Feature Drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa8ec1",
   "metadata": {},
   "source": [
    "## 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240eee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = list(df_train.select_dtypes(include='object').columns)\n",
    "object_columns.extend(list(df_train.select_dtypes(include='category').columns))\n",
    "object_columns.append('customer_idx')\n",
    "object_columns.append('lead_owner')\n",
    "object_columns.append('country_corp_status')\n",
    "object_columns.append('country_corp_status_1')\n",
    "object_columns.append('country_corp_status_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1facd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[object_columns] = df_train[object_columns].fillna('Unknown')\n",
    "df_test[object_columns] = df_test[object_columns].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = []\n",
    "\n",
    "for column in df_train.columns:\n",
    "    unique_values = df_train[column].unique()\n",
    "    if len(unique_values) == 2 and 0 in unique_values and 1 in unique_values:\n",
    "        binary_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = list(set(object_columns + binary_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe246ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns.remove('is_converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26140da",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns.remove('lead_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"범주형 데이터를 시리즈 형태로 받아 숫자형 데이터로 변환합니다.\"\"\"\n",
    "\n",
    "    my_dict = {}\n",
    "\n",
    "    # 모든 요소를 문자열로 변환\n",
    "    series = series.astype(str)\n",
    "\n",
    "    for idx, value in enumerate(sorted(series.unique())):\n",
    "        my_dict[value] = idx\n",
    "    series = series.map(my_dict)\n",
    "\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e50d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩할 칼럼들\n",
    "overlapping_features = ['business_unit','customer_history','enterprise','prefer_ver_count','prefer_ver_mean','transfer_agreement','business_area']\n",
    "label_columns = object_columns\n",
    "label_columns = [feature for feature in label_columns if feature not in overlapping_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train[label_columns], df_test[label_columns]])\n",
    "\n",
    "for col in label_columns:\n",
    "    df_all[col] = label_encoding(df_all[col])\n",
    "\n",
    "for col in label_columns:  \n",
    "    df_train[col] = df_all.iloc[: len(df_train)][col]\n",
    "    df_test[col] = df_all.iloc[len(df_train) :][col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65299917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the features to be target encoded\n",
    "features_to_encode = [\n",
    "    'bant_submit', 'business_unit', 'customer_history', 'enterprise', \n",
    "    'prefer_ver_count', 'prefer_ver_mean', 'transfer_agreement', 'ver_cus', \n",
    "    'ver_pro', 'ver_win_rate_x', 'ver_win_rate_mean_upper', \n",
    "    'ver_win_ratio_per_bu', 'business_area'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual target encoding function\n",
    "def manual_target_encode(df, features, target):\n",
    "    target_means = {}\n",
    "    for feature in features:\n",
    "        # Calculate the mean target value for each category in the feature\n",
    "        target_mean = df.groupby(feature)[target].mean()\n",
    "        # Map these mean values back to the original dataframe\n",
    "        df[f'{feature}_encoded'] = df[feature].map(target_mean)\n",
    "        # Store the means for mapping to the submission dataset\n",
    "        target_means[feature] = target_mean\n",
    "    return df, target_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb5e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply manual target encoding to the train set\n",
    "df_train, target_means = manual_target_encode(df_train, features_to_encode, 'is_converted')\n",
    "\n",
    "# Apply the means to the submission set\n",
    "for feature, means in target_means.items():\n",
    "    df_test[f'{feature}_encoded'] = df_test[feature].map(means).fillna(means.mean())\n",
    "\n",
    "# Drop the original features from both datasets\n",
    "df_train.drop(columns=features_to_encode, inplace=True)\n",
    "df_test.drop(columns=features_to_encode, inplace=True)\n",
    "\n",
    "df_train.drop(['lead_description'],axis=1,inplace=True)\n",
    "df_test.drop(['lead_description'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eaf0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = [col for col in object_columns if col not in features_to_encode]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2dfd6",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561df640",
   "metadata": {},
   "source": [
    "### ***😀CAT Boost with all***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3fcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns = ['is_converted'])\n",
    "y = df_train['is_converted'].values\n",
    "cat_features = object_columns.copy()\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat = []\n",
    "f1_scores = []\n",
    "n_split_list = [10]\n",
    "for state in [5778, 9377, 9555]:\n",
    "    for split in n_split_list:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X,y):\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            Y_train, Y_valid = y[train_index], y[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )    \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=200)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores.append(score)\n",
    "            model_cat.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores))\n",
    "\n",
    "X_without_idx = df_train.drop(columns = ['is_converted'])\n",
    "X_without_idx = X_without_idx.drop(columns = ['customer_idx'])\n",
    "y_without_idx = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_idx = object_columns.copy()\n",
    "cat_features_without_idx.remove('customer_idx')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_idx = []\n",
    "f1_scores_without_idx = []\n",
    "n_split_list_without_idx = [10]\n",
    "for state in [5778, 9377, 9555]:\n",
    "    for split in n_split_list_without_idx:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_idx,y_without_idx):\n",
    "            X_train, X_valid = X_without_idx.iloc[train_index], X_without_idx.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_idx[train_index], y_without_idx[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_idx,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_idx.append(score)\n",
    "            model_cat_without_idx.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_idx)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_idx))\n",
    "\n",
    "X_without_lead = df_train.drop(columns = ['is_converted'])\n",
    "X_without_lead = X_without_lead.drop(columns = ['lead_owner'])\n",
    "y_without_lead = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_lead = object_columns.copy()\n",
    "cat_features_without_lead.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_lead = []\n",
    "f1_scores_without_lead = []\n",
    "n_split_list_without_lead = [10]\n",
    "for state in [5778, 9377, 9555]:\n",
    "    for split in n_split_list_without_lead:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_lead,y_without_lead):\n",
    "            X_train, X_valid = X_without_lead.iloc[train_index], X_without_lead.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_lead[train_index], y_without_lead[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_lead,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_lead.append(score)\n",
    "            model_cat_without_lead.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')        \n",
    "        \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_lead)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_lead))\n",
    "\n",
    "X_without_all = df_train.drop(columns = ['is_converted'])\n",
    "X_without_all = X_without_all.drop(columns = ['customer_idx'])\n",
    "X_without_all = X_without_all.drop(columns = ['lead_owner'])\n",
    "y_without_all = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_all = object_columns.copy()\n",
    "cat_features_without_all.remove('customer_idx')\n",
    "cat_features_without_all.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_all = []\n",
    "f1_scores_without_all = []\n",
    "n_split_list_without_all = [10]\n",
    "for state in [5778, 9377, 9555]:\n",
    "    for split in n_split_list_without_all:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_all,y_without_all):\n",
    "            X_train, X_valid = X_without_all.iloc[train_index], X_without_all.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_all[train_index], y_without_all[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_all,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_all.append(score)\n",
    "            model_cat_without_all.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "                \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_all)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_all))\n",
    "\n",
    "X_test = df_test.drop(columns = ['id','is_converted'])\n",
    "\n",
    "with_all_idx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_idx_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_lead_ldx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_all_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "\n",
    "test_pred_with_all_idx = []\n",
    "test_with_all_idx = X_test.loc[with_all_idx]\n",
    "for i in range(len(model_cat)):\n",
    "    pred = model_cat[i].predict_proba(test_with_all_idx)[:,1]\n",
    "    test_pred_with_all_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_with_all_idx = np.array(test_pred_with_all_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_with_all_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_with_all_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_with_all_idx) , '/' , len(test_with_all_idx))\n",
    "\n",
    "test_pred_without_idx = []\n",
    "X_test_without_idx = X_test.drop(columns=['customer_idx'])\n",
    "test_without_idx = X_test_without_idx.loc[without_idx_ldx]\n",
    "for i in range(len(model_cat_without_idx)):\n",
    "    pred = model_cat_without_idx[i].predict_proba(test_without_idx)[:,1]\n",
    "    test_pred_without_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_idx = np.array(test_pred_without_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_idx) , '/' , len(test_without_idx))\n",
    "\n",
    "test_pred_without_lead = []\n",
    "X_test_without_lead = X_test.drop(columns=['lead_owner'])\n",
    "test_without_lead = X_test_without_lead.loc[without_lead_ldx]\n",
    "for i in range(len(model_cat_without_lead)):\n",
    "    pred = model_cat_without_lead[i].predict_proba(test_without_lead)[:,1]\n",
    "    test_pred_without_lead.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_lead = np.array(test_pred_without_lead)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_lead, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_lead = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_lead) , '/' , len(test_without_lead))\n",
    "\n",
    "test_pred_without_all = []\n",
    "X_test_without_all = X_test.drop(columns=['lead_owner'])\n",
    "X_test_without_all = X_test_without_all.drop(columns=['customer_idx'])\n",
    "test_without_all = X_test_without_all.loc[without_all_ldx]\n",
    "for i in range(len(model_cat_without_all)):\n",
    "    pred = model_cat_without_all[i].predict_proba(test_without_all)[:,1]\n",
    "    test_pred_without_all.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_all = np.array(test_pred_without_all)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_all, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_all = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_all) , '/' , len(test_without_all))\n",
    "df_sub_cat = pd.read_csv(\"submission.csv\")\n",
    "df_sub_cat.loc[with_all_idx,'is_converted'] = test_pred_final_with_all_idx\n",
    "df_sub_cat.loc[without_idx_ldx,'is_converted'] = test_pred_final_without_idx\n",
    "df_sub_cat.loc[without_lead_ldx,'is_converted'] = test_pred_final_without_lead\n",
    "df_sub_cat.loc[without_all_ldx,'is_converted'] = test_pred_final_without_all\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub['is_converted'] = df_sub_cat['is_converted'].copy()\n",
    "df_sub.to_csv(\"submission_5778_9377_9555.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns = ['is_converted'])\n",
    "y = df_train['is_converted'].values\n",
    "cat_features = object_columns.copy()\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat = []\n",
    "f1_scores = []\n",
    "n_split_list = [10]\n",
    "for state in [313, 724, 21011928]:\n",
    "    for split in n_split_list:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X,y):\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            Y_train, Y_valid = y[train_index], y[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )    \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=200)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores.append(score)\n",
    "            model_cat.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores))\n",
    "\n",
    "X_without_idx = df_train.drop(columns = ['is_converted'])\n",
    "X_without_idx = X_without_idx.drop(columns = ['customer_idx'])\n",
    "y_without_idx = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_idx = object_columns.copy()\n",
    "cat_features_without_idx.remove('customer_idx')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_idx = []\n",
    "f1_scores_without_idx = []\n",
    "n_split_list_without_idx = [10]\n",
    "for state in [313, 724, 21011928]:\n",
    "    for split in n_split_list_without_idx:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_idx,y_without_idx):\n",
    "            X_train, X_valid = X_without_idx.iloc[train_index], X_without_idx.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_idx[train_index], y_without_idx[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_idx,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_idx.append(score)\n",
    "            model_cat_without_idx.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_idx)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_idx))\n",
    "\n",
    "X_without_lead = df_train.drop(columns = ['is_converted'])\n",
    "X_without_lead = X_without_lead.drop(columns = ['lead_owner'])\n",
    "y_without_lead = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_lead = object_columns.copy()\n",
    "cat_features_without_lead.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_lead = []\n",
    "f1_scores_without_lead = []\n",
    "n_split_list_without_lead = [10]\n",
    "for state in [313, 724, 21011928]:\n",
    "    for split in n_split_list_without_lead:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_lead,y_without_lead):\n",
    "            X_train, X_valid = X_without_lead.iloc[train_index], X_without_lead.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_lead[train_index], y_without_lead[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_lead,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_lead.append(score)\n",
    "            model_cat_without_lead.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')        \n",
    "        \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_lead)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_lead))\n",
    "\n",
    "X_without_all = df_train.drop(columns = ['is_converted'])\n",
    "X_without_all = X_without_all.drop(columns = ['customer_idx'])\n",
    "X_without_all = X_without_all.drop(columns = ['lead_owner'])\n",
    "y_without_all = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_all = object_columns.copy()\n",
    "cat_features_without_all.remove('customer_idx')\n",
    "cat_features_without_all.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_all = []\n",
    "f1_scores_without_all = []\n",
    "n_split_list_without_all = [10]\n",
    "for state in [313, 724, 21011928]:\n",
    "    for split in n_split_list_without_all:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_all,y_without_all):\n",
    "            X_train, X_valid = X_without_all.iloc[train_index], X_without_all.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_all[train_index], y_without_all[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_all,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_all.append(score)\n",
    "            model_cat_without_all.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "                \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_all)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_all))\n",
    "\n",
    "X_test = df_test.drop(columns = ['id','is_converted'])\n",
    "\n",
    "with_all_idx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_idx_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_lead_ldx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_all_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "\n",
    "test_pred_with_all_idx = []\n",
    "test_with_all_idx = X_test.loc[with_all_idx]\n",
    "for i in range(len(model_cat)):\n",
    "    pred = model_cat[i].predict_proba(test_with_all_idx)[:,1]\n",
    "    test_pred_with_all_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_with_all_idx = np.array(test_pred_with_all_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_with_all_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_with_all_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_with_all_idx) , '/' , len(test_with_all_idx))\n",
    "\n",
    "test_pred_without_idx = []\n",
    "X_test_without_idx = X_test.drop(columns=['customer_idx'])\n",
    "test_without_idx = X_test_without_idx.loc[without_idx_ldx]\n",
    "for i in range(len(model_cat_without_idx)):\n",
    "    pred = model_cat_without_idx[i].predict_proba(test_without_idx)[:,1]\n",
    "    test_pred_without_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_idx = np.array(test_pred_without_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_idx) , '/' , len(test_without_idx))\n",
    "\n",
    "test_pred_without_lead = []\n",
    "X_test_without_lead = X_test.drop(columns=['lead_owner'])\n",
    "test_without_lead = X_test_without_lead.loc[without_lead_ldx]\n",
    "for i in range(len(model_cat_without_lead)):\n",
    "    pred = model_cat_without_lead[i].predict_proba(test_without_lead)[:,1]\n",
    "    test_pred_without_lead.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_lead = np.array(test_pred_without_lead)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_lead, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_lead = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_lead) , '/' , len(test_without_lead))\n",
    "\n",
    "test_pred_without_all = []\n",
    "X_test_without_all = X_test.drop(columns=['lead_owner'])\n",
    "X_test_without_all = X_test_without_all.drop(columns=['customer_idx'])\n",
    "test_without_all = X_test_without_all.loc[without_all_ldx]\n",
    "for i in range(len(model_cat_without_all)):\n",
    "    pred = model_cat_without_all[i].predict_proba(test_without_all)[:,1]\n",
    "    test_pred_without_all.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_all = np.array(test_pred_without_all)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_all, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_all = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_all) , '/' , len(test_without_all))\n",
    "df_sub_cat = pd.read_csv(\"submission.csv\")\n",
    "df_sub_cat.loc[with_all_idx,'is_converted'] = test_pred_final_with_all_idx\n",
    "df_sub_cat.loc[without_idx_ldx,'is_converted'] = test_pred_final_without_idx\n",
    "df_sub_cat.loc[without_lead_ldx,'is_converted'] = test_pred_final_without_lead\n",
    "df_sub_cat.loc[without_all_ldx,'is_converted'] = test_pred_final_without_all\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub['is_converted'] = df_sub_cat['is_converted'].copy()\n",
    "df_sub.to_csv(\"submission_313_724_21011928.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dab1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns = ['is_converted'])\n",
    "y = df_train['is_converted'].values\n",
    "cat_features = object_columns.copy()\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat = []\n",
    "f1_scores = []\n",
    "n_split_list = [10]\n",
    "for state in [0, 5, 11]:\n",
    "    for split in n_split_list:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X,y):\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            Y_train, Y_valid = y[train_index], y[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )    \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=200)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores.append(score)\n",
    "            model_cat.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores))\n",
    "\n",
    "X_without_idx = df_train.drop(columns = ['is_converted'])\n",
    "X_without_idx = X_without_idx.drop(columns = ['customer_idx'])\n",
    "y_without_idx = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_idx = object_columns.copy()\n",
    "cat_features_without_idx.remove('customer_idx')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_idx = []\n",
    "f1_scores_without_idx = []\n",
    "n_split_list_without_idx = [10]\n",
    "for state in [0, 5, 11]:\n",
    "    for split in n_split_list_without_idx:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_idx,y_without_idx):\n",
    "            X_train, X_valid = X_without_idx.iloc[train_index], X_without_idx.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_idx[train_index], y_without_idx[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_idx,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_idx.append(score)\n",
    "            model_cat_without_idx.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_idx)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_idx))\n",
    "\n",
    "X_without_lead = df_train.drop(columns = ['is_converted'])\n",
    "X_without_lead = X_without_lead.drop(columns = ['lead_owner'])\n",
    "y_without_lead = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_lead = object_columns.copy()\n",
    "cat_features_without_lead.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_lead = []\n",
    "f1_scores_without_lead = []\n",
    "n_split_list_without_lead = [10]\n",
    "for state in [0, 5, 11]:\n",
    "    for split in n_split_list_without_lead:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_lead,y_without_lead):\n",
    "            X_train, X_valid = X_without_lead.iloc[train_index], X_without_lead.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_lead[train_index], y_without_lead[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_lead,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_lead.append(score)\n",
    "            model_cat_without_lead.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')        \n",
    "        \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_lead)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_lead))\n",
    "\n",
    "X_without_all = df_train.drop(columns = ['is_converted'])\n",
    "X_without_all = X_without_all.drop(columns = ['customer_idx'])\n",
    "X_without_all = X_without_all.drop(columns = ['lead_owner'])\n",
    "y_without_all = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_all = object_columns.copy()\n",
    "cat_features_without_all.remove('customer_idx')\n",
    "cat_features_without_all.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_all = []\n",
    "f1_scores_without_all = []\n",
    "n_split_list_without_all = [10]\n",
    "for state in [0, 5, 11]:\n",
    "    for split in n_split_list_without_all:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_all,y_without_all):\n",
    "            X_train, X_valid = X_without_all.iloc[train_index], X_without_all.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_all[train_index], y_without_all[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_all,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_all.append(score)\n",
    "            model_cat_without_all.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "                \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_all)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_all))\n",
    "\n",
    "X_test = df_test.drop(columns = ['id','is_converted'])\n",
    "\n",
    "with_all_idx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_idx_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_lead_ldx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_all_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "\n",
    "test_pred_with_all_idx = []\n",
    "test_with_all_idx = X_test.loc[with_all_idx]\n",
    "for i in range(len(model_cat)):\n",
    "    pred = model_cat[i].predict_proba(test_with_all_idx)[:,1]\n",
    "    test_pred_with_all_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_with_all_idx = np.array(test_pred_with_all_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_with_all_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_with_all_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_with_all_idx) , '/' , len(test_with_all_idx))\n",
    "\n",
    "test_pred_without_idx = []\n",
    "X_test_without_idx = X_test.drop(columns=['customer_idx'])\n",
    "test_without_idx = X_test_without_idx.loc[without_idx_ldx]\n",
    "for i in range(len(model_cat_without_idx)):\n",
    "    pred = model_cat_without_idx[i].predict_proba(test_without_idx)[:,1]\n",
    "    test_pred_without_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_idx = np.array(test_pred_without_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_idx) , '/' , len(test_without_idx))\n",
    "\n",
    "test_pred_without_lead = []\n",
    "X_test_without_lead = X_test.drop(columns=['lead_owner'])\n",
    "test_without_lead = X_test_without_lead.loc[without_lead_ldx]\n",
    "for i in range(len(model_cat_without_lead)):\n",
    "    pred = model_cat_without_lead[i].predict_proba(test_without_lead)[:,1]\n",
    "    test_pred_without_lead.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_lead = np.array(test_pred_without_lead)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_lead, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_lead = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_lead) , '/' , len(test_without_lead))\n",
    "\n",
    "test_pred_without_all = []\n",
    "X_test_without_all = X_test.drop(columns=['lead_owner'])\n",
    "X_test_without_all = X_test_without_all.drop(columns=['customer_idx'])\n",
    "test_without_all = X_test_without_all.loc[without_all_ldx]\n",
    "for i in range(len(model_cat_without_all)):\n",
    "    pred = model_cat_without_all[i].predict_proba(test_without_all)[:,1]\n",
    "    test_pred_without_all.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_all = np.array(test_pred_without_all)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_all, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_all = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_all) , '/' , len(test_without_all))\n",
    "df_sub_cat = pd.read_csv(\"submission.csv\")\n",
    "df_sub_cat.loc[with_all_idx,'is_converted'] = test_pred_final_with_all_idx\n",
    "df_sub_cat.loc[without_idx_ldx,'is_converted'] = test_pred_final_without_idx\n",
    "df_sub_cat.loc[without_lead_ldx,'is_converted'] = test_pred_final_without_lead\n",
    "df_sub_cat.loc[without_all_ldx,'is_converted'] = test_pred_final_without_all\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub['is_converted'] = df_sub_cat['is_converted'].copy()\n",
    "df_sub.to_csv(\"submission_0_5_11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns = ['is_converted'])\n",
    "y = df_train['is_converted'].values\n",
    "cat_features = object_columns.copy()\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat = []\n",
    "f1_scores = []\n",
    "n_split_list = [10]\n",
    "for state in [24, 58, 66]:\n",
    "    for split in n_split_list:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X,y):\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            Y_train, Y_valid = y[train_index], y[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )    \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=200)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores.append(score)\n",
    "            model_cat.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores))\n",
    "\n",
    "X_without_idx = df_train.drop(columns = ['is_converted'])\n",
    "X_without_idx = X_without_idx.drop(columns = ['customer_idx'])\n",
    "y_without_idx = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_idx = object_columns.copy()\n",
    "cat_features_without_idx.remove('customer_idx')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_idx = []\n",
    "f1_scores_without_idx = []\n",
    "n_split_list_without_idx = [10]\n",
    "for state in [24, 58, 66]:\n",
    "    for split in n_split_list_without_idx:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_idx,y_without_idx):\n",
    "            X_train, X_valid = X_without_idx.iloc[train_index], X_without_idx.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_idx[train_index], y_without_idx[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_idx,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_idx.append(score)\n",
    "            model_cat_without_idx.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_idx)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_idx))\n",
    "\n",
    "X_without_lead = df_train.drop(columns = ['is_converted'])\n",
    "X_without_lead = X_without_lead.drop(columns = ['lead_owner'])\n",
    "y_without_lead = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_lead = object_columns.copy()\n",
    "cat_features_without_lead.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_lead = []\n",
    "f1_scores_without_lead = []\n",
    "n_split_list_without_lead = [10]\n",
    "for state in [24, 58, 66]:\n",
    "    for split in n_split_list_without_lead:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_lead,y_without_lead):\n",
    "            X_train, X_valid = X_without_lead.iloc[train_index], X_without_lead.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_lead[train_index], y_without_lead[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_lead,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_lead.append(score)\n",
    "            model_cat_without_lead.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')        \n",
    "        \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_lead)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_lead))\n",
    "\n",
    "X_without_all = df_train.drop(columns = ['is_converted'])\n",
    "X_without_all = X_without_all.drop(columns = ['customer_idx'])\n",
    "X_without_all = X_without_all.drop(columns = ['lead_owner'])\n",
    "y_without_all = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_all = object_columns.copy()\n",
    "cat_features_without_all.remove('customer_idx')\n",
    "cat_features_without_all.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_all = []\n",
    "f1_scores_without_all = []\n",
    "n_split_list_without_all = [10]\n",
    "for state in [24, 58, 66]:\n",
    "    for split in n_split_list_without_all:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_all,y_without_all):\n",
    "            X_train, X_valid = X_without_all.iloc[train_index], X_without_all.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_all[train_index], y_without_all[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_all,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.5,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_all.append(score)\n",
    "            model_cat_without_all.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "                \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_all)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_all))\n",
    "\n",
    "X_test = df_test.drop(columns = ['id','is_converted'])\n",
    "\n",
    "with_all_idx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_idx_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_lead_ldx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_all_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "\n",
    "test_pred_with_all_idx = []\n",
    "test_with_all_idx = X_test.loc[with_all_idx]\n",
    "for i in range(len(model_cat)):\n",
    "    pred = model_cat[i].predict_proba(test_with_all_idx)[:,1]\n",
    "    test_pred_with_all_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_with_all_idx = np.array(test_pred_with_all_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_with_all_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_with_all_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_with_all_idx) , '/' , len(test_with_all_idx))\n",
    "\n",
    "test_pred_without_idx = []\n",
    "X_test_without_idx = X_test.drop(columns=['customer_idx'])\n",
    "test_without_idx = X_test_without_idx.loc[without_idx_ldx]\n",
    "for i in range(len(model_cat_without_idx)):\n",
    "    pred = model_cat_without_idx[i].predict_proba(test_without_idx)[:,1]\n",
    "    test_pred_without_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_idx = np.array(test_pred_without_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_idx) , '/' , len(test_without_idx))\n",
    "\n",
    "test_pred_without_lead = []\n",
    "X_test_without_lead = X_test.drop(columns=['lead_owner'])\n",
    "test_without_lead = X_test_without_lead.loc[without_lead_ldx]\n",
    "for i in range(len(model_cat_without_lead)):\n",
    "    pred = model_cat_without_lead[i].predict_proba(test_without_lead)[:,1]\n",
    "    test_pred_without_lead.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_lead = np.array(test_pred_without_lead)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_lead, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_lead = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_lead) , '/' , len(test_without_lead))\n",
    "\n",
    "test_pred_without_all = []\n",
    "X_test_without_all = X_test.drop(columns=['lead_owner'])\n",
    "X_test_without_all = X_test_without_all.drop(columns=['customer_idx'])\n",
    "test_without_all = X_test_without_all.loc[without_all_ldx]\n",
    "for i in range(len(model_cat_without_all)):\n",
    "    pred = model_cat_without_all[i].predict_proba(test_without_all)[:,1]\n",
    "    test_pred_without_all.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_all = np.array(test_pred_without_all)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_all, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_all = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_all) , '/' , len(test_without_all))\n",
    "df_sub_cat = pd.read_csv(\"submission.csv\")\n",
    "df_sub_cat.loc[with_all_idx,'is_converted'] = test_pred_final_with_all_idx\n",
    "df_sub_cat.loc[without_idx_ldx,'is_converted'] = test_pred_final_without_idx\n",
    "df_sub_cat.loc[without_lead_ldx,'is_converted'] = test_pred_final_without_lead\n",
    "df_sub_cat.loc[without_all_ldx,'is_converted'] = test_pred_final_without_all\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub['is_converted'] = df_sub_cat['is_converted'].copy()\n",
    "df_sub.to_csv(\"submission_24_58_66.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns = ['is_converted'])\n",
    "y = df_train['is_converted'].values\n",
    "cat_features = object_columns.copy()\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat = []\n",
    "f1_scores = []\n",
    "n_split_list = [10]\n",
    "for state in [724]:\n",
    "    for split in n_split_list:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X,y):\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            Y_train, Y_valid = y[train_index], y[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   #bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )    \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=200)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores.append(score)\n",
    "            model_cat.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores))\n",
    "\n",
    "X_without_idx = df_train.drop(columns = ['is_converted'])\n",
    "X_without_idx = X_without_idx.drop(columns = ['customer_idx'])\n",
    "y_without_idx = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_idx = object_columns.copy()\n",
    "cat_features_without_idx.remove('customer_idx')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_idx = []\n",
    "f1_scores_without_idx = []\n",
    "n_split_list_without_idx = [10]\n",
    "for state in [724]:\n",
    "    for split in n_split_list_without_idx:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_idx,y_without_idx):\n",
    "            X_train, X_valid = X_without_idx.iloc[train_index], X_without_idx.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_idx[train_index], y_without_idx[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   #bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_idx,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )  \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_idx.append(score)\n",
    "            model_cat_without_idx.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_idx)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_idx))\n",
    "\n",
    "X_without_lead = df_train.drop(columns = ['is_converted'])\n",
    "X_without_lead = X_without_lead.drop(columns = ['lead_owner'])\n",
    "y_without_lead = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_lead = object_columns.copy()\n",
    "cat_features_without_lead.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_lead = []\n",
    "f1_scores_without_lead = []\n",
    "n_split_list_without_lead = [10]\n",
    "for state in [724]:\n",
    "    for split in n_split_list_without_lead:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_lead,y_without_lead):\n",
    "            X_train, X_valid = X_without_lead.iloc[train_index], X_without_lead.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_lead[train_index], y_without_lead[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   #bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_lead,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )   \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_lead.append(score)\n",
    "            model_cat_without_lead.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')        \n",
    "        \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_lead)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_lead))\n",
    "\n",
    "X_without_all = df_train.drop(columns = ['is_converted'])\n",
    "X_without_all = X_without_all.drop(columns = ['customer_idx'])\n",
    "X_without_all = X_without_all.drop(columns = ['lead_owner'])\n",
    "y_without_all = df_train['is_converted'].values\n",
    "\n",
    "cat_features_without_all = object_columns.copy()\n",
    "cat_features_without_all.remove('customer_idx')\n",
    "cat_features_without_all.remove('lead_owner')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "is_holdout = False\n",
    "\n",
    "model_cat_without_all = []\n",
    "f1_scores_without_all = []\n",
    "n_split_list_without_all = [10]\n",
    "for state in [724]:\n",
    "    for split in n_split_list_without_all:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=state)\n",
    "        for train_index, valid_index in cv.split(X_without_all,y_without_all):\n",
    "            X_train, X_valid = X_without_all.iloc[train_index], X_without_all.iloc[valid_index]\n",
    "            Y_train, Y_valid = y_without_all[train_index], y_without_all[valid_index]\n",
    "            print(\"=\"*50)\n",
    "            pos_weight = (len(Y_train)-sum(Y_train))/sum(Y_train)\n",
    "\n",
    "            model = CatBoostClassifier(iterations=1000,\n",
    "                                   random_state=state,\n",
    "                                   task_type=\"CPU\",\n",
    "                                   depth = 10,\n",
    "                                   eval_metric=\"F1\",\n",
    "                                   #class_weights = {0: (0.1), 1: (1.1)},\n",
    "                                   scale_pos_weight=pos_weight,\n",
    "                                   #bootstrap_type='Bayesian',  # Bayesian Bootstrap 사용\n",
    "                                   random_strength = 4,\n",
    "                                   cat_features=cat_features_without_all,\n",
    "                                   l2_leaf_reg = 5,\n",
    "                                   bagging_temperature = 0.7,\n",
    "                                   one_hot_max_size=8,\n",
    "                                   grow_policy='Depthwise',\n",
    "                                   learning_rate=0.05\n",
    "                                      )  \n",
    "\n",
    "            model.fit(X_train, Y_train, \n",
    "                      eval_set=[(X_valid, Y_valid)], \n",
    "                      early_stopping_rounds=200, \n",
    "                      verbose=500)\n",
    "            \n",
    "            pred = model.predict_proba(X_valid)[:,1]\n",
    "            threshold = 0.5\n",
    "\n",
    "            pred = np.where(pred >= threshold , True, False)\n",
    "            score = f1_score(Y_valid, pred, labels=[True, False])\n",
    "            print(fold_idx,\"Fold Validation F1 score :\", score)\n",
    "            f1_scores_without_all.append(score)\n",
    "            model_cat_without_all.append(model)\n",
    "            fold_idx += 1\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if is_holdout:\n",
    "                break \n",
    "    print(state,'학습 완료')\n",
    "    \n",
    "                \n",
    "print(\"Validation : F1 scores for each fold:\", f1_scores_without_all)\n",
    "print(\"Validation : F1:\", np.mean(f1_scores_without_all))\n",
    "\n",
    "X_test = df_test.drop(columns = ['id','is_converted'])\n",
    "\n",
    "with_all_idx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_idx_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_lead_ldx = X_test.loc[(X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "without_all_ldx = X_test.loc[(~X_test['customer_idx'].isin(df_train['customer_idx'].unique())) & (~X_test['lead_owner'].isin(df_train['lead_owner'].unique()))].index\n",
    "\n",
    "test_pred_with_all_idx = []\n",
    "test_with_all_idx = X_test.loc[with_all_idx]\n",
    "for i in range(len(model_cat)):\n",
    "    pred = model_cat[i].predict_proba(test_with_all_idx)[:,1]\n",
    "    test_pred_with_all_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_with_all_idx = np.array(test_pred_with_all_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_with_all_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_with_all_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_with_all_idx) , '/' , len(test_with_all_idx))\n",
    "\n",
    "test_pred_without_idx = []\n",
    "X_test_without_idx = X_test.drop(columns=['customer_idx'])\n",
    "test_without_idx = X_test_without_idx.loc[without_idx_ldx]\n",
    "for i in range(len(model_cat_without_idx)):\n",
    "    pred = model_cat_without_idx[i].predict_proba(test_without_idx)[:,1]\n",
    "    test_pred_without_idx.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_idx = np.array(test_pred_without_idx)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_idx, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_idx = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_idx) , '/' , len(test_without_idx))\n",
    "\n",
    "test_pred_without_lead = []\n",
    "X_test_without_lead = X_test.drop(columns=['lead_owner'])\n",
    "test_without_lead = X_test_without_lead.loc[without_lead_ldx]\n",
    "for i in range(len(model_cat_without_lead)):\n",
    "    pred = model_cat_without_lead[i].predict_proba(test_without_lead)[:,1]\n",
    "    test_pred_without_lead.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_lead = np.array(test_pred_without_lead)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_lead, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_lead = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_lead) , '/' , len(test_without_lead))\n",
    "\n",
    "test_pred_without_all = []\n",
    "X_test_without_all = X_test.drop(columns=['lead_owner'])\n",
    "X_test_without_all = X_test_without_all.drop(columns=['customer_idx'])\n",
    "test_without_all = X_test_without_all.loc[without_all_ldx]\n",
    "for i in range(len(model_cat_without_all)):\n",
    "    pred = model_cat_without_all[i].predict_proba(test_without_all)[:,1]\n",
    "    test_pred_without_all.append(pred)\n",
    "\n",
    "    \n",
    "test_pred_without_all = np.array(test_pred_without_all)\n",
    "\n",
    "sorted_probs = np.sort(test_pred_without_all, axis=0)\n",
    "mean_pred_probs = np.mean(sorted_probs[3:-3], axis=0)\n",
    "\n",
    "test_pred_final_without_all = mean_pred_probs >= 0.5\n",
    "    \n",
    "print(sum(test_pred_final_without_all) , '/' , len(test_without_all))\n",
    "df_sub_cat = pd.read_csv(\"submission.csv\")\n",
    "df_sub_cat.loc[with_all_idx,'is_converted'] = test_pred_final_with_all_idx\n",
    "df_sub_cat.loc[without_idx_ldx,'is_converted'] = test_pred_final_without_idx\n",
    "df_sub_cat.loc[without_lead_ldx,'is_converted'] = test_pred_final_without_lead\n",
    "df_sub_cat.loc[without_all_ldx,'is_converted'] = test_pred_final_without_all\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub['is_converted'] = df_sub_cat['is_converted'].copy()\n",
    "df_sub.to_csv(\"submission_724_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f58dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = pd.read_csv(\"submission_5778_9377_9555.csv\")\n",
    "b = pd.read_csv(\"submission_313_724_21011928.csv\")\n",
    "#c = pd.read_csv(\"submission_0_5_11.csv\")\n",
    "d = pd.read_csv(\"submission_24_58_66.csv\")\n",
    "e = pd.read_csv(\"submission_724_new.csv\")\n",
    "\n",
    "from scipy.stats import mode\n",
    "# Concatenate the 'is_converted' columns from each dataframe\n",
    "votes = pd.concat([a['is_converted'], b['is_converted'], c['is_converted'], d['is_converted'], e['is_converted']], axis=1)\n",
    "\n",
    "# Apply hard voting\n",
    "result = votes.mode(axis=1)[0]\n",
    "\n",
    "# Copy one of the original dataframes (e.g., a) and replace the 'is_converted' column with the voting result\n",
    "a_copy = a.copy()\n",
    "a_copy['is_converted'] = result\n",
    "\n",
    "a_copy.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = pd.read_csv(\"submission_5778_9377_9555.csv\")\n",
    "b = pd.read_csv(\"submission_313_724_21011928.csv\")\n",
    "#c = pd.read_csv(\"submission_0_5_11.csv\")\n",
    "d = pd.read_csv(\"submission_24_58_66.csv\")\n",
    "e = pd.read_csv(\"submission_724_new.csv\")\n",
    "\n",
    "from scipy.stats import mode\n",
    "# Concatenate the 'is_converted' columns from each dataframe\n",
    "votes = pd.concat([a['is_converted'], b['is_converted'], c['is_converted'], d['is_converted'], e['is_converted']], axis=1)\n",
    "\n",
    "# Apply hard voting\n",
    "result = votes.mode(axis=1)[0]\n",
    "\n",
    "# Copy one of the original dataframes (e.g., a) and replace the 'is_converted' column with the voting result\n",
    "a_copy = a.copy()\n",
    "a_copy['is_converted'] = result\n",
    "\n",
    "a_copy.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
